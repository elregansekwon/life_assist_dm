# user_excel_manager.py
"""
ì‚¬ìš©ìë³„ ê°œì¸ì •ë³´ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥/ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆ
"""
import os
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from collections import defaultdict
import logging
import threading
import time

logger = logging.getLogger(__name__)



import json

# 1ï¸âƒ£ í†µí•© ì‹œíŠ¸ ìŠ¤í‚¤ë§ˆ ì •ì˜
SHEET_SCHEMAS = {
    "ë¬¼ê±´ìœ„ì¹˜": ["ë‚ ì§œ", "ë¬¼ê±´ì´ë¦„", "ì¥ì†Œ", "ì„¸ë¶€ìœ„ì¹˜", "ì¶œì²˜", "ì—”í‹°í‹°íƒ€ì…"],
    "ë³µì•½ì •ë³´": ["ë‚ ì§œ", "ì•½ì´ë¦„", "ìš©ëŸ‰", "ë‹¨ìœ„", "ì‹œê°„", "ë³µìš©ë°©ë²•", "ë³µìš©ê¸°ê°„", "ì—”í‹°í‹°íƒ€ì…"],
    "ì¼ì •": ["ë‚ ì§œ", "ì œëª©", "ì‹œê°„", "ì¥ì†Œ", "ì •ë³´", "ì—”í‹°í‹°íƒ€ì…"],
    "ê°€ì¡±ê´€ê³„": ["ë‚ ì§œ", "ê´€ê³„", "ì´ë¦„", "ì •ë³´", "ì—”í‹°í‹°íƒ€ì…"],
    "ê°ì •ê¸°ë¡": ["ë‚ ì§œ", "ê°ì •", "ì •ë³´", "ì—”í‹°í‹°íƒ€ì…"],
    "ìŒì‹ê¸°ë¡": ["ë‚ ì§œ", "ë¼ë‹ˆ", "ì‹œê°„", "ë©”ë‰´", "ì—”í‹°í‹°íƒ€ì…"],
    "ì‚¬ìš©ìì •ë³´KV": ["ë‚ ì§œ", "í‚¤", "ê°’", "ì¶œì²˜", "í™•ì‹ ë„", "ì—”í‹°í‹°íƒ€ì…"],
    "ëŒ€í™”ê¸°ë¡": ["ë‚ ì§œ", "ì‹œê°„", "ëŒ€í™”ìš”ì•½"],  # ëŒ€í™” ê¸°ë¡ì€ ë³„ë„ ìŠ¤í‚¤ë§ˆ
}

# íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ì°¾ê¸°
def _get_package_dir():
    """life_assist_dm íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ë°˜í™˜"""
    current_file = Path(__file__).resolve()
    # life_assist_dm/life_assist_dm/user_excel_manager.py -> life_assist_dm
    package_dir = current_file.parent.parent
    return package_dir

class UserExcelManager:
    """ì‚¬ìš©ìë³„ ì—‘ì…€ íŒŒì¼ ê´€ë¦¬"""
    
    def __init__(self, base_dir: str = None):
        """
        Args:
            base_dir: ì—‘ì…€ íŒŒì¼ì´ ì €ì¥ë  ê¸°ë³¸ ë””ë ‰í† ë¦¬ (Noneì´ë©´ íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬/user_information)
        """
        if base_dir is None:
            # ê¸°ë³¸ê°’: íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬/user_information
            package_dir = _get_package_dir()
            self.base_dir = package_dir / "user_information"
        else:
            self.base_dir = Path(os.path.expanduser(base_dir))
        self.base_dir.mkdir(parents=True, exist_ok=True)
        logger.debug(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {self.base_dir}")
        # ë²„í¼ë§: (user_name, sheet_name) -> [records]
        self._buffered_changes = defaultdict(list)
        # âœ… flush íƒ€ì´ë° ê²½ìŸ ë°©ì§€: lockê³¼ pending í”Œë˜ê·¸
        self._flush_lock = threading.Lock()
        self._pending_flush = {}  # user_nameë³„ ì¤‘ë³µ ë°©ì§€ í”Œë˜ê·¸: {user_name: bool}
        self._flush_delay = 1.0      # flush ì§€ì—° ì‹œê°„ (ì´ˆ)
    
    # -----------------------------
    #  ì‹œíŠ¸ ë§¤í•‘ ìœ í‹¸
    # -----------------------------
    def _get_sheet_name(self, entity_type: str) -> str:
        """ì—”í‹°í‹° íƒ€ì…ì„ ì‹œíŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        mapping = {
            "ë¬¼ê±´": "ë¬¼ê±´ìœ„ì¹˜",
            "user.ë¬¼ê±´": "ë¬¼ê±´ìœ„ì¹˜",  # âœ… ì—”í‹°í‹° í‚¤ í˜•ì‹ë„ ì§€ì›
            "ì•½": "ë³µì•½ì •ë³´",
            "user.ì•½": "ë³µì•½ì •ë³´",
            "ì¼ì •": "ì¼ì •",
            "user.ì¼ì •": "ì¼ì •",
            "ì‹ì‚¬": "ìŒì‹ê¸°ë¡",
            "user.ì‹ì‚¬": "ìŒì‹ê¸°ë¡",
            "ìŒì‹": "ìŒì‹ê¸°ë¡",
            "user.ìŒì‹": "ìŒì‹ê¸°ë¡",
            "ì •ì„œ": "ê°ì •ê¸°ë¡",
            "ê°ì •": "ê°ì •ê¸°ë¡",
            "user.ê±´ê°•ìƒíƒœ": "ê°ì •ê¸°ë¡",
            "ê°€ì¡±": "ê°€ì¡±ê´€ê³„",
            "user.ê°€ì¡±": "ê°€ì¡±ê´€ê³„",
            "ì‚¬ìš©ì": "ì‚¬ìš©ìì •ë³´KV",
            "user.ì‚¬ìš©ì": "ì‚¬ìš©ìì •ë³´KV",
            "ì·¨í–¥": "ì‚¬ìš©ìì •ë³´KV",  # âœ… ì·¨í–¥/ì„ í˜¸ë„ ì‚¬ìš©ì ì •ë³´ì´ë¯€ë¡œ ì‚¬ìš©ìì •ë³´KVë¡œ ì´ë™
            "ì„ í˜¸": "ì‚¬ìš©ìì •ë³´KV",  # âœ… ì·¨í–¥/ì„ í˜¸ë„ ì‚¬ìš©ì ì •ë³´ì´ë¯€ë¡œ ì‚¬ìš©ìì •ë³´KVë¡œ ì´ë™
            "ê¸°ë…ì¼": "ì‚¬ìš©ìì •ë³´KV",  # âœ… ê¸°ë…ì¼ë„ ì‚¬ìš©ì ì •ë³´ì´ë¯€ë¡œ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥
            "ì·¨ë¯¸": "ì‚¬ìš©ìì •ë³´KV",  # âœ… ì·¨ë¯¸ë„ ì‚¬ìš©ì ì •ë³´ì´ë¯€ë¡œ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥
        }
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ì—”í‹°í‹° íƒ€ì…ë„ ëª¨ë‘ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥ (ê¸°íƒ€ ì‹œíŠ¸ ì œê±°)
        sheet_name = mapping.get(entity_type, "ì‚¬ìš©ìì •ë³´KV")
        if entity_type not in mapping:
            logger.info(f"[INFO] '{entity_type}' ì—”í‹°í‹° íƒ€ì…ì´ ë§¤í•‘ë˜ì§€ ì•Šì•„ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥")
        return sheet_name
        
    def get_user_excel_path(self, user_name: str) -> Path:
        """ì‚¬ìš©ìë³„ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        # í•œê¸€ íŒŒì¼ëª… ì§€ì›
        file_name = f"{user_name}.xlsx"
        return self.base_dir / file_name
    
    def load_user_excel(self, user_name: str) -> Optional[pd.ExcelFile]:
        """ì‚¬ìš©ì ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
        excel_path = self.get_user_excel_path(user_name)
        if not excel_path.exists():
            return None
        try:
            return pd.ExcelFile(excel_path)
        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def load_sheet_data(self, user_name: str, sheet_name: str) -> pd.DataFrame:
        """íŠ¹ì • ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ"""
        excel_file = self.load_user_excel(user_name)
        if excel_file is None:
            return pd.DataFrame()
        try:
            if sheet_name in excel_file.sheet_names:
                return pd.read_excel(excel_file, sheet_name=sheet_name)
            else:
                return pd.DataFrame()
        except Exception as e:
            logger.error(f"ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ({sheet_name}): {e}")
            return pd.DataFrame()
    
    # -----------------------------
    # ğŸ§© ì•ˆì „í•œ ë¡œë“œ í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ì •ë ¬)
    # -----------------------------
    def safe_load_sheet(self, user_name: str, sheet_name: str) -> pd.DataFrame:
        """ì—‘ì…€ ì‹œíŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ + ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ë³´ì¥"""
        try:
            df = self.load_sheet_data(user_name, sheet_name)
            schema = SHEET_SCHEMAS.get(sheet_name, [])
            if df is None or df.empty:
                return pd.DataFrame(columns=schema)
            # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
            for col in schema:
                if col not in df.columns:
                    df[col] = ""
            # ìŠ¤í‚¤ë§ˆ ìˆœì„œì— ë§ì¶° ì •ë ¬
            return df[schema]
        except Exception as e:
            logger.error(f"[ERROR] safe_load_sheet ì‹¤íŒ¨: {e}")
            schema = SHEET_SCHEMAS.get(sheet_name, [])
            return pd.DataFrame(columns=schema)
    
    def save_data_to_sheet(self, user_name: str, sheet_name: str, data: List[Dict[str, Any]], 
                           append: bool = True):
        """ì‹œíŠ¸ì— ë°ì´í„° ì €ì¥"""
        excel_path = self.get_user_excel_path(user_name)
        
        def _cleanup_lockfile(path: Path):
            """openpyxlì´ ë‚¨ê¸¸ ìˆ˜ ìˆëŠ” ì„ì‹œ .lock íŒŒì¼ì„ ì •ë¦¬í•œë‹¤."""
            try:
                lock_path = Path(str(path) + ".lock")
                if lock_path.exists():
                    lock_path.unlink(missing_ok=True)
                    logger.debug(f"[LOCK CLEANUP] Lock íŒŒì¼ ì œê±°ë¨: {lock_path}")
            except Exception as e:
                logger.warning(f"[LOCK CLEANUP ì‹¤íŒ¨] {e}")
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = []
        if excel_path.exists() and append:
            try:
                df_existing = self.load_sheet_data(user_name, sheet_name)
                existing_data = df_existing.to_dict('records')
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        if append:
            existing_data.extend(data)
        else:
            existing_data = data
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(existing_data)

        # ì‹œíŠ¸ë³„ í‘œì¤€ ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì»¬ëŸ¼ ìˆœì„œ/ì¡´ì¬ ê°•ì œ
        schema = SHEET_SCHEMAS.get(sheet_name, [])
        if schema:
            # ëˆ„ë½ ì»¬ëŸ¼ ì¶”ê°€
            for col in schema:
                if col not in df.columns:
                    df[col] = ""
            # ìŠ¤í‚¤ë§ˆ ìˆœì„œì— ë§ì¶° ì •ë ¬
            df = df[schema]
        
        # ì—‘ì…€ íŒŒì¼ ì €ì¥ (ì‹œíŠ¸ ë‹¨ìœ„ êµì²´ ì €ì¥ ìµœì í™”)
        try:
            mode = 'a' if excel_path.exists() else 'w'
            with pd.ExcelWriter(
                excel_path, engine='openpyxl', mode=mode, if_sheet_exists='replace'
            ) as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=False)
            # openpyxlì´ ë‚¨ê¸´ ì„ì‹œ ì ê¸ˆ íŒŒì¼ ì •ë¦¬
            _cleanup_lockfile(excel_path)
        except TypeError:
            # pandas/openpyxl êµ¬ë²„ì „ í˜¸í™˜: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì „ì²´ ì¬ì‘ì„±
            if excel_path.exists():
                excel_file = self.load_user_excel(user_name)
                if excel_file is None:
                    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
                else:
                    excel_data = {}
                    for sheet in excel_file.sheet_names:
                        if sheet == sheet_name:
                            excel_data[sheet] = df
                        else:
                            excel_data[sheet] = pd.read_excel(excel_file, sheet_name=sheet)
                    if sheet_name not in excel_data:
                        excel_data[sheet_name] = df
                    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
                        for sheet_name_key, df_data in excel_data.items():
                            df_data.to_excel(writer, sheet_name=sheet_name_key, index=False)
                    _cleanup_lockfile(excel_path)
            else:
                with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                _cleanup_lockfile(excel_path)
    
    # -----------------------------
    # ğŸ§© ì—”í‹°í‹° í‘œì¤€í™” í•¨ìˆ˜
    # -----------------------------
    def _convert_duration_to_date_range(self, duration_str: str) -> str:
        """ë³µìš©ê¸°ê°„ì„ ë‚ ì§œ ë²”ìœ„ë¡œ ë³€í™˜ (ì˜ˆ: "15ì¼ì¹˜" â†’ "2025-11-06~2025-11-21")"""
        if not duration_str:
            return ""
        
        import re
        from datetime import datetime, timedelta
        
        # ì´ë¯¸ ë‚ ì§œ ë²”ìœ„ í˜•ì‹ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì˜ˆ: "2025-11-06~2025-11-21")
        if "~" in duration_str or "-" in duration_str:
            # ë‚ ì§œ í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if re.match(r"\d{4}-\d{2}-\d{2}", duration_str.split("~")[0].strip()):
                return duration_str
        
        # ê¸°ê°„ ì¶”ì¶œ (ì˜ˆ: "15ì¼ì¹˜", "7ì¼ì¹˜", "2ì£¼ì¼ì¹˜", "1ê°œì›”ì¹˜")
        duration_match = re.search(r"(\d+)\s*(ì¼|ì£¼|ê°œì›”|ë…„)", duration_str)
        if not duration_match:
            # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
            return duration_str
        
        days_to_add = 0
        number = int(duration_match.group(1))
        unit = duration_match.group(2)
        
        if unit == "ì¼":
            days_to_add = number
        elif unit == "ì£¼":
            days_to_add = number * 7
        elif unit == "ê°œì›”":
            days_to_add = number * 30  # ëŒ€ëµ 30ì¼
        elif unit == "ë…„":
            days_to_add = number * 365
        
        # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì‹œì‘ì¼ë¡œ ì„¤ì •
        start_date = datetime.now()
        end_date = start_date + timedelta(days=days_to_add - 1)  # -1ì€ ì‹œì‘ì¼ í¬í•¨í•˜ì—¬ ê³„ì‚°
        
        # ë‚ ì§œ ë²”ìœ„ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        start_str = start_date.strftime("%Y-%m-%d")
        end_str = end_date.strftime("%Y-%m-%d")
        return f"{start_str}~{end_str}"
    
    def _normalize_entity(self, entity_type: str, data: dict) -> dict:
        """ì—”í‹°í‹°ë³„ í‘œì¤€ í‚¤ ì´ë¦„ê³¼ ê°’ ì •ê·œí™”"""
        norm = {}
        try:
            if entity_type in ["ë¬¼ê±´", "user.ë¬¼ê±´"]:
                # ë¬¼ê±´ì´ë¦„: ì—¬ëŸ¬ ê°€ëŠ¥í•œ í‚¤ ì´ë¦„ ì§€ì›
                norm["ë¬¼ê±´ì´ë¦„"] = data.get("ë¬¼ê±´ì´ë¦„") or data.get("ì´ë¦„", "")
                # ì¥ì†Œì™€ ì„¸ë¶€ìœ„ì¹˜ ë¶„ë¦¬ ì²˜ë¦¬
                norm["ì¥ì†Œ"] = str(data.get("ì¥ì†Œ", "")).strip()
                norm["ì„¸ë¶€ìœ„ì¹˜"] = str(data.get("ì„¸ë¶€ìœ„ì¹˜", "")).strip()
                # í•˜ìœ„ í˜¸í™˜ì„±: "ìœ„ì¹˜" í•„ë“œê°€ ìˆìœ¼ë©´ ì¥ì†Œì™€ ì„¸ë¶€ìœ„ì¹˜ë¡œ ë¶„ë¦¬ ì‹œë„
                if not norm["ì¥ì†Œ"] and not norm["ì„¸ë¶€ìœ„ì¹˜"]:
                    location = str(data.get("ìœ„ì¹˜", "")).strip()
                    if location:
                        # ìœ„ì¹˜ì—ì„œ ì¥ì†Œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸´ í‚¤ì›Œë“œë¶€í„° ì²´í¬í•˜ì—¬ "ë‚´ ë°©", "ì•ˆë°©" ê°™ì€ ë³µí•© í‚¤ì›Œë“œ ìš°ì„  ì²˜ë¦¬)
                        import re
                        # "ë‚´ ë°©", "ë‚´ë°©" ê°™ì€ ë³µí•© íŒ¨í„´ì„ ë¨¼ì € ì²´í¬
                        if "ë‚´ ë°©" in location or "ë‚´ë°©" in location:
                            # "ë‚´ ë°© ì•ˆì—" â†’ ì¥ì†Œ="ë‚´ ë°©", ì„¸ë¶€ìœ„ì¹˜="ì•ˆì—"
                            # "ë‚´ ë°© ì•ˆ" â†’ ì¥ì†Œ="ë‚´ ë°©", ì„¸ë¶€ìœ„ì¹˜="ì•ˆ"
                            if location.startswith("ë‚´ ë°©") or location.startswith("ë‚´ë°©"):
                                # "ë‚´ ë°© ì•ˆì—" â†’ "ì•ˆì—" ì¶”ì¶œ
                                remaining = location.replace("ë‚´ ë°©", "").replace("ë‚´ë°©", "").strip()
                                norm["ì¥ì†Œ"] = "ë‚´ ë°©" if "ë‚´ ë°©" in location else "ë‚´ë°©"
                                norm["ì„¸ë¶€ìœ„ì¹˜"] = remaining
                            else:
                                # "ë‚´ ë°©"ì´ ì¤‘ê°„ì— ìˆëŠ” ê²½ìš°
                                norm["ì¥ì†Œ"] = "ë‚´ ë°©" if "ë‚´ ë°©" in location else "ë‚´ë°©"
                                norm["ì„¸ë¶€ìœ„ì¹˜"] = location.replace("ë‚´ ë°©", "").replace("ë‚´ë°©", "").strip()
                        else:
                            # ì¼ë°˜ ì¥ì†Œ í‚¤ì›Œë“œ ì²´í¬ (ê¸´ í‚¤ì›Œë“œë¶€í„°)
                            room_keywords = ["ì•ˆë°©", "ë‹¤ìš©ë„ì‹¤", "í™”ì¥ì‹¤", "ì£¼ë°©", "ê±°ì‹¤", "ì¹¨ì‹¤", "í˜„ê´€", "ë² ë€ë‹¤", "ë°©"]
                            room_keywords_sorted = sorted(room_keywords, key=len, reverse=True)
                            for room in room_keywords_sorted:
                                if room in location:
                                    norm["ì¥ì†Œ"] = room
                                    norm["ì„¸ë¶€ìœ„ì¹˜"] = location.replace(room, "").strip()
                                    break
                        if not norm["ì¥ì†Œ"]:
                            # ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ë¥¼ ì„¸ë¶€ìœ„ì¹˜ë¡œ
                            norm["ì„¸ë¶€ìœ„ì¹˜"] = location
                # ì¶œì²˜: ì¶”ì¶œë°©ë²• ë˜ëŠ” ì¶œì²˜ í•„ë“œ ì‚¬ìš©
                norm["ì¶œì²˜"] = data.get("ì¶œì²˜") or data.get("ì¶”ì¶œë°©ë²•", "ì‚¬ìš©ì ë°œí™”")
                # ì—”í‹°í‹°íƒ€ì…ì€ ë‚˜ì¤‘ì— ì¶”ê°€ë¨
            elif entity_type in ["ì•½", "user.ì•½"]:
                # ì•½ í•„ë“œëª… í†µì¼: "ì•½ëª…" â†’ "ì•½ì´ë¦„"ìœ¼ë¡œ ì •ê·œí™”
                norm["ì•½ì´ë¦„"] = data.get("ì•½ì´ë¦„") or data.get("ì•½ëª…") or data.get("ì´ë¦„", "")
                # ìš©ëŸ‰ê³¼ ë‹¨ìœ„ë¥¼ ë³„ë„ë¡œ ì €ì¥ (ì—‘ì…€ ì»¬ëŸ¼ì´ ë¶„ë¦¬ë˜ì–´ ìˆìŒ)
                dose = str(data.get("ìš©ëŸ‰", "")).strip()
                unit = str(data.get("ë‹¨ìœ„", "")).strip()
                norm["ìš©ëŸ‰"] = dose if dose else ""
                norm["ë‹¨ìœ„"] = unit if unit else ""
                # ë³µìš©ì‹œê°„: ì‹œê°„ëŒ€ ë˜ëŠ” ì‹œê°„ í•„ë“œ ì‚¬ìš©
                norm["ì‹œê°„"] = data.get("ì‹œê°„ëŒ€") or data.get("ì‹œê°„") or data.get("ë³µìš©ì‹œê°„", "")
                # âœ… ë³µìš©ì—¬ë¶€ í•„ë“œ ì œê±° (ëŒ€í™”ê¸°ë¡ ì°¸ê³ ë¡œ ë³€ê²½)
                # âœ… ë³µìš©ë°©ë²• í•„ë“œ ì¶”ê°€ (ì‹í›„ 30ë¶„, ê³µë³µì— ë“±)
                norm["ë³µìš©ë°©ë²•"] = data.get("ë³µìš©ë°©ë²•") or data.get("ë©”ëª¨") or ""
                # âœ… ë³µìš©ê¸°ê°„ í•„ë“œ ì¶”ê°€ (ê¸°ê°„ì„ ë‚ ì§œ ë²”ìœ„ë¡œ ë³€í™˜)
                ë³µìš©ê¸°ê°„_ì›ë³¸ = data.get("ë³µìš©ê¸°ê°„") or ""
                if ë³µìš©ê¸°ê°„_ì›ë³¸:
                    # "15ì¼ì¹˜" ê°™ì€ ê¸°ê°„ í‘œí˜„ì„ ë‚ ì§œ ë²”ìœ„ë¡œ ë³€í™˜
                    norm["ë³µìš©ê¸°ê°„"] = self._convert_duration_to_date_range(ë³µìš©ê¸°ê°„_ì›ë³¸)
                else:
                    norm["ë³µìš©ê¸°ê°„"] = ""
            elif entity_type == "ì¼ì •":
                norm["ì œëª©"] = data.get("ì œëª©", "")
                # ë‚ ì§œ ì •ê·œí™” (ì–´ì œ/ì˜¤ëŠ˜/ë‚´ì¼ ë“± â†’ YYYY-MM-DD)
                # support_chains.pyì—ì„œ ì´ë¯¸ ì •ê·œí™”ëœ ê²½ìš°ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„œë„ ì •ê·œí™”í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
                date_value = data.get("ë‚ ì§œ", "")
                if date_value:
                    try:
                        from life_assist_dm.life_assist_dm.support_chains import _normalize_date_to_iso
                        date_str = str(date_value).strip()
                        if date_str and date_str.lower() not in ("nan", "none", ""):
                            norm["ë‚ ì§œ"] = _normalize_date_to_iso(date_str)
                        else:
                            norm["ë‚ ì§œ"] = ""
                    except Exception as e:
                        logger.warning(f"ì¼ì • ë‚ ì§œ ì •ê·œí™” ì‹¤íŒ¨: {e}, ì›ë³¸ ê°’ ì‚¬ìš©: {date_value}")
                        norm["ë‚ ì§œ"] = str(date_value) if date_value else ""
                else:
                    norm["ë‚ ì§œ"] = ""
                norm["ì‹œê°„"] = data.get("ì‹œê°„", "")
                norm["ì¥ì†Œ"] = data.get("ì¥ì†Œ", "")
                norm["ì •ë³´"] = data.get("ì •ë³´", "")
            elif entity_type in ["ì‹ì‚¬", "ìŒì‹"]:
                norm["ë¼ë‹ˆ"] = data.get("ë¼ë‹ˆ", "")
                norm["ì‹œê°„"] = data.get("ì‹œê°„", "") or data.get("ì‹œê°„ëŒ€", "")
                if isinstance(data.get("ë©”ë‰´"), list):
                    norm["ë©”ë‰´"] = ", ".join(str(m) for m in data["ë©”ë‰´"])
                else:
                    norm["ë©”ë‰´"] = str(data.get("ë©”ë‰´", "")).strip()
                # ë‚ ì§œ ì •ê·œí™” (ì–´ì œ/ì˜¤ëŠ˜/ë‚´ì¼ ë“± â†’ YYYY-MM-DD)
                # ì¼ì •ê³¼ ë™ì¼í•˜ê²Œ í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜ëœ ë‚ ì§œ ì €ì¥
                date_value = data.get("ë‚ ì§œ", "")
                if date_value:
                    try:
                        from life_assist_dm.life_assist_dm.support_chains import _normalize_date_to_iso
                        date_str = str(date_value).strip()
                        if date_str and date_str.lower() not in ("nan", "none", ""):
                            norm["ë‚ ì§œ"] = _normalize_date_to_iso(date_str)
                        else:
                            # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •
                            norm["ë‚ ì§œ"] = datetime.now().strftime("%Y-%m-%d")
                    except Exception as e:
                        logger.warning(f"ë‚ ì§œ ì •ê·œí™” ì‹¤íŒ¨: {e}, ì›ë³¸ ê°’ ì‚¬ìš©: {date_value}")
                        norm["ë‚ ì§œ"] = str(date_value) if date_value else ""
                else:
                    # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •
                    norm["ë‚ ì§œ"] = datetime.now().strftime("%Y-%m-%d")
            elif entity_type == "ì •ì„œ" or entity_type == "ê°ì •":
                norm["ê°ì •"] = data.get("ê°ì •") or data.get("ìƒíƒœ") or data.get("ì¦ìƒ", "")
                norm["ì •ë³´"] = data.get("ì •ë³´", "") or data.get("ì›ë¬¸", "")
            elif entity_type == "ê°€ì¡±":
                norm["ê´€ê³„"] = data.get("ê´€ê³„", "")
                norm["ì´ë¦„"] = data.get("ì´ë¦„", "")
                norm["ì •ë³´"] = data.get("ì •ë³´", "")
            elif entity_type in ["ì·¨í–¥", "ì„ í˜¸", "ê¸°ë…ì¼", "ì·¨ë¯¸"]:
                # ì´ íƒ€ì…ë“¤ì€ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥ë˜ë¯€ë¡œ ì •ê·œí™” ë¶ˆí•„ìš” (íŠ¹ë³„ ì²˜ë¦¬ë¨)
                # í•˜ì§€ë§Œ fallbackì„ ìœ„í•´ ê¸°ë³¸ ì²˜ë¦¬
                norm["ë‚´ìš©"] = data.get("ë‚´ìš©") or json.dumps(data, ensure_ascii=False)
                norm["ì •ë³´"] = data.get("ì •ë³´") or entity_type
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ë„ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥ë˜ë¯€ë¡œ ì •ê·œí™” ë¶ˆí•„ìš” (íŠ¹ë³„ ì²˜ë¦¬ë¨)
                norm["ë‚´ìš©"] = json.dumps(data, ensure_ascii=False)
                norm["ì •ë³´"] = ""
        except Exception as e:
            logger.warning(f"ì—”í‹°í‹° ì •ê·œí™” ì¤‘ ì˜¤ë¥˜: {e}")
            norm["ë‚´ìš©"] = json.dumps(data, ensure_ascii=False)
            norm["ì •ë³´"] = ""
        return norm
    
    def save_entity_data(self, user_name: str, entity_type: str, data: Dict[str, Any]):
        """ì•ˆì „í•œ ì—”í‹°í‹° ì €ì¥ (ì •ê·œí™” + ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ë³´ì¥)"""
        # ì‚¬ìš©ì ì´ë¦„ ìœ íš¨ì„± ê²€ì¦
        if not user_name or not str(user_name).strip() or user_name == "ì‚¬ìš©ì":
            logger.warning(f"[WARN] ì˜ëª»ëœ ì‚¬ìš©ìëª…ìœ¼ë¡œ ì €ì¥ ì‹œë„: {user_name}")
            return
        
        try:
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            sheet_name = self._get_sheet_name(entity_type)
            
            # ì‚¬ìš©ì ê´€ë ¨ ì—”í‹°í‹°ëŠ” ëª¨ë‘ íŠ¹ë³„ ì²˜ë¦¬ (KV ì‹œíŠ¸ ì €ì¥)
            # ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´, ì·¨í–¥/ì„ í˜¸, ê¸°ë…ì¼, ì·¨ë¯¸ ë“± ëª¨ë“  ì‚¬ìš©ì ì •ë³´
            # ë§¤í•‘ë˜ì§€ ì•Šì€ ì—”í‹°í‹° íƒ€ì…ë„ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥ (ê¸°íƒ€ ì‹œíŠ¸ ì œê±°)
            non_user_entity_types = ["ë¬¼ê±´", "ì•½", "ì¼ì •", "ì‹ì‚¬", "ìŒì‹", "ì •ì„œ", "ê°ì •", "ê°€ì¡±", "user.ë¬¼ê±´", "user.ì•½", "user.ì¼ì •", "user.ì‹ì‚¬", "user.ìŒì‹", "user.ê±´ê°•ìƒíƒœ", "user.ê°€ì¡±"]
            if entity_type not in non_user_entity_types:
                try:
                    from .dialog_manager.config.config_loader import get_excel_sheets
                    sheets = get_excel_sheets()
                    kv_sheet = sheets.get("user_info_kv", "ì‚¬ìš©ìì •ë³´KV")
                    
                    # ì‚¬ìš©ì ì •ë³´ ì •ê·œí™”
                    normalized_user = {}
                    import re
                    
                    if entity_type == "ì‚¬ìš©ì":
                        # ë‚˜ì´: ìˆ«ì ì¶”ì¶œ í›„ 'ì‚´' ì ‘ë¯¸ì‚¬ í‘œì¤€í™”
                        if "ë‚˜ì´" in data and data["ë‚˜ì´"]:
                            m = re.search(r"(\d+)", str(data["ë‚˜ì´"]))
                            if m:
                                normalized_user["ë‚˜ì´"] = f"{m.group(1)}ì‚´"
                        # í•™êµ: ë°œí™” ì „ì²˜ë¦¬ í›„ '...í•™êµ'ë§Œ ì¶”ì¶œ
                        if "í•™êµ" in data and data["í•™êµ"]:
                            raw_school = str(data["í•™êµ"]).strip()
                            raw_school = re.sub(r"^(?:ë‚˜ëŠ”|ë‚œ|ì €ëŠ”)\s*", "", raw_school)
                            raw_school = re.sub(r"\s*(?:ì—\s*ë‹¤ë…€.*|ë‹¤ë…€.*)$", "", raw_school)
                            m = re.search(r"([ê°€-í£A-Za-z\s]+?(?:ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ì´ˆë“±í•™êµ|í•™êµ))", raw_school)
                            if m:
                                normalized_user["í•™êµ"] = m.group(1).strip()
                        # ì´ë¦„/ë³„ì¹­/ì§ì—…/ì·¨ë¯¸/íšŒì‚¬/ì¸í„´ì€ ê·¸ëŒ€ë¡œ
                        for k in ["ì´ë¦„", "ë³„ì¹­", "ì§ì—…", "ì·¨ë¯¸", "íšŒì‚¬", "ì¸í„´"]:
                            if k in data and data[k]:
                                normalized_user[k] = data[k]
                    elif entity_type in ["ì·¨í–¥", "ì„ í˜¸"]:
                        # ì·¨í–¥/ì„ í˜¸ëŠ” "ë‚´ìš©" í•„ë“œë¥¼ "ì·¨í–¥" í‚¤ë¡œ ì €ì¥
                        content = data.get("ë‚´ìš©", "") or data.get("ê°’", "") or json.dumps(data, ensure_ascii=False)
                        if content:
                            normalized_user["ì·¨í–¥"] = content
                    elif entity_type == "ê¸°ë…ì¼":
                        # ê¸°ë…ì¼ì€ "ì œëª©"ê³¼ "ë‚ ì§œ"ë¥¼ í‚¤-ê°’ìœ¼ë¡œ ì €ì¥
                        if "ì œëª©" in data and data["ì œëª©"]:
                            normalized_user["ê¸°ë…ì¼"] = f"{data.get('ì œëª©', '')} ({data.get('ë‚ ì§œ', '')})"
                        elif "ë‚ ì§œ" in data and data["ë‚ ì§œ"]:
                            normalized_user["ê¸°ë…ì¼"] = data.get("ë‚ ì§œ", "")
                    elif entity_type == "ì·¨ë¯¸":
                        # ì·¨ë¯¸ëŠ” "ì´ë¦„" í•„ë“œë¥¼ "ì·¨ë¯¸" í‚¤ë¡œ ì €ì¥
                        hobby = data.get("ì´ë¦„", "") or data.get("ì·¨ë¯¸", "") or ""
                        if hobby:
                            normalized_user["ì·¨ë¯¸"] = hobby
                    else:
                        # ê¸°íƒ€ ë§¤í•‘ë˜ì§€ ì•Šì€ ì—”í‹°í‹° íƒ€ì…ì€ JSONìœ¼ë¡œ ì €ì¥
                        import json
                        entity_json = json.dumps(data, ensure_ascii=False)
                        normalized_user[entity_type] = entity_json
                    
                    # KV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    kv_rows = []
                    if entity_type == "ì‚¬ìš©ì":
                        for k in ["ì´ë¦„", "ë³„ì¹­", "ë‚˜ì´", "í•™êµ", "ì§ì—…", "ì·¨ë¯¸", "íšŒì‚¬", "ì¸í„´"]:
                            if k in normalized_user and str(normalized_user[k]).strip() != "":
                                kv_rows.append({
                                    "ë‚ ì§œ": now,
                                    "í‚¤": k,
                                    "ê°’": normalized_user[k],
                                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                                    "í™•ì‹ ë„": "",
                                    "ì—”í‹°í‹°íƒ€ì…": entity_type,
                                })
                    else:
                        # ì·¨í–¥/ì„ í˜¸/ê¸°ë…ì¼/ì·¨ë¯¸/ê¸°íƒ€ ëª¨ë“  ì‚¬ìš©ì ì •ë³´ë¥¼ í‚¤-ê°’ìœ¼ë¡œ ì €ì¥
                        for k, v in normalized_user.items():
                            if v and str(v).strip() != "":
                                kv_rows.append({
                                    "ë‚ ì§œ": now,
                                    "í‚¤": k,
                                    "ê°’": v,
                                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                                    "í™•ì‹ ë„": "",
                                    "ì—”í‹°í‹°íƒ€ì…": entity_type,
                                })
                    if kv_rows:
                        # ë²„í¼ì— ì¶”ê°€
                        self._buffered_changes[(user_name, kv_sheet)].extend(kv_rows)
                        logger.info(f"[BUFFER] {user_name}:{kv_sheet} ì—”í‹°í‹° ë²„í¼ë§ë¨ ({entity_type})")
                except Exception as e:
                    # í…ŒìŠ¤íŠ¸/ë‹¨ë… ì‹¤í–‰ í˜¸í™˜: ìƒëŒ€ ì„í¬íŠ¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‹œíŠ¸ëª… ì‚¬ìš©
                    logger.error(f"[ERROR] ì‚¬ìš©ìì •ë³´KV ì €ì¥ ì‹¤íŒ¨: {e}")
                    try:
                        kv_sheet = "ì‚¬ìš©ìì •ë³´KV"
                        now_local = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        kv_rows = []
                        for k in ["ì´ë¦„", "ë‚˜ì´", "í•™êµ", "ì§ì—…", "ì·¨ë¯¸", "íšŒì‚¬", "ì¸í„´"]:
                            if k in data and str(data[k]).strip() != "":
                                kv_rows.append({
                                    "ë‚ ì§œ": now_local,
                                    "í‚¤": k,
                                    "ê°’": data[k],
                                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                                    "í™•ì‹ ë„": "",
                                    "ì—”í‹°í‹°íƒ€ì…": entity_type,
                                })
                        if kv_rows:
                            self._buffered_changes[(user_name, kv_sheet)].extend(kv_rows)
                            logger.info(f"[BUFFER] {user_name}:{kv_sheet} ì—”í‹°í‹° ë²„í¼ë§ë¨ ({entity_type})")
                    except Exception:
                        pass
                return
            
            # 1ï¸âƒ£ ë°ì´í„° ì •ê·œí™”
            normalized = self._normalize_entity(entity_type, data)
            # ë‚ ì§œëŠ” _normalize_entityì—ì„œ ì´ë¯¸ ì •ê·œí™”ë˜ì—ˆìœ¼ë¯€ë¡œ, ë¹ˆ ê°’ë§Œ ì²´í¬
            date_value = normalized.get("ë‚ ì§œ", "")
            if not date_value or str(date_value).strip() == "" or str(date_value).lower() in ("nan", "none"):
                normalized["ë‚ ì§œ"] = now.split()[0]  # ë‚ ì§œë§Œ (YYYY-MM-DD)
            else:
                normalized["ë‚ ì§œ"] = str(date_value).strip()
            normalized["ì—”í‹°í‹°íƒ€ì…"] = entity_type
            
            # 2ï¸âƒ£ ìŠ¤í‚¤ë§ˆ ê°•ì œ ì •ë ¬
            schema = SHEET_SCHEMAS.get(sheet_name, SHEET_SCHEMAS["ì‚¬ìš©ìì •ë³´KV"])
            for col in schema:
                if col not in normalized:
                    normalized[col] = ""
            
            # âœ… ë””ë²„ê¹…: normalized ë”•ì…”ë„ˆë¦¬ í™•ì¸
            if entity_type in ["ë¬¼ê±´", "user.ë¬¼ê±´"]:
                logger.debug(f"[SAVE DEBUG] ë¬¼ê±´ ì €ì¥ - normalized: {normalized}")
                logger.debug(f"[SAVE DEBUG] ë¬¼ê±´ ì €ì¥ - schema: {schema}")
            
            record = {k: str(normalized[k]) if normalized[k] is not None else "" for k in schema}
            
            # âœ… ë””ë²„ê¹…: record ë”•ì…”ë„ˆë¦¬ í™•ì¸
            if entity_type in ["ë¬¼ê±´", "user.ë¬¼ê±´"]:
                logger.debug(f"[SAVE DEBUG] ë¬¼ê±´ ì €ì¥ - record: {record}")
            
            # 3ï¸âƒ£ ë²„í¼ì— ì¶”ê°€ (ì¦‰ì‹œ ì €ì¥í•˜ì§€ ì•ŠìŒ)
            buffer_key = (user_name, sheet_name)
            self._buffered_changes[buffer_key].append(record)
            # âœ… ë””ë²„ê¹…: ë²„í¼ë§ ì§í›„ ìƒíƒœ í™•ì¸
            logger.info(f"[BUFFER] {user_name}:{sheet_name} ì—”í‹°í‹° ë²„í¼ë§ë¨ ({entity_type})")
            logger.debug(f"[BUFFER DEBUG] ë²„í¼ë§ ì§í›„ - ë²„í¼ í‚¤: {buffer_key}, ë ˆì½”ë“œ ìˆ˜: {len(self._buffered_changes[buffer_key])}")
            
        except Exception as e:
            logger.error(f"[ERROR] save_entity_data ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
    
    def save_conversation_summary(self, user_name: str, summary: str, 
                                 timestamp: Optional[str] = None):
        """ëŒ€í™” ìš”ì•½ ì €ì¥"""
        if timestamp is None:
            now = datetime.now()
            timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
        
        # ëŒ€í™” ê¸°ë¡ì€ ë²„í¼ë§ ë°©ì‹ìœ¼ë¡œ ì €ì¥
        record = {
            "ë‚ ì§œ": timestamp.split()[0],  # ë‚ ì§œë§Œ
            "ì‹œê°„": timestamp.split()[1] if len(timestamp.split()) > 1 else "",  # ì‹œê°„ë§Œ
            "ëŒ€í™”ìš”ì•½": summary,
            "ì—”í‹°í‹°íƒ€ì…": "ëŒ€í™”ê¸°ë¡"
        }
        
        # ë²„í¼ì— ì¶”ê°€ (ì¦‰ì‹œ ì €ì¥í•˜ì§€ ì•ŠìŒ)
        key = (user_name, "ëŒ€í™”ê¸°ë¡")
        self._buffered_changes[key].append(record)
        logger.info(f"[BUFFER] ëŒ€í™” ìš”ì•½ ë²„í¼ë§ë¨: {user_name}")

        #  ì¡°ê±´ë¶€ ë°°ì¹˜ flush: ëŒ€í™”ìš”ì•½ì´ 3ê±´ ì´ìƒ ëˆ„ì ë˜ë©´ ì¼ê´„ ì €ì¥
        #  request_flush() ì‚¬ìš©í•˜ì—¬ ì§€ì—° ë³‘í•© ì²˜ë¦¬
        try:
            if len(self._buffered_changes.get(key, [])) >= 3:
                self.request_flush(user_name)
                logger.info(f"[FLUSH] ëŒ€í™”ìš”ì•½ ëˆ„ì  3íšŒ â†’ Excel ë™ê¸°í™” ì˜ˆì•½ ({user_name})")
            else:
                logger.debug(f"[BUFFER] ëŒ€í™”ìš”ì•½ ëˆ„ì  {len(self._buffered_changes.get(key, []))}íšŒ (ë¯¸flush)")
        except Exception:
            pass
    
    # ì œê±°ë¨: SQLite ë™ê¸°í™”ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    
    def initialize_user_excel(self, user_name: str):
        """ìƒˆ ì‚¬ìš©ì ì—‘ì…€ íŒŒì¼ ì´ˆê¸°í™” (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)"""
        excel_path = self.get_user_excel_path(user_name)
        
        # SHEET_SCHEMAS ê¸°ë°˜ìœ¼ë¡œ ì´ˆê¸°í™”
        with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
            for sheet_name, columns in SHEET_SCHEMAS.items():
                df = pd.DataFrame(columns=columns)
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        logger.info(f"ì‚¬ìš©ì ì—‘ì…€ íŒŒì¼ ì´ˆê¸°í™” ì™„ë£Œ: {user_name}")
    
    def user_exists(self, user_name: str) -> bool:
        """ì‚¬ìš©ì íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return self.get_user_excel_path(user_name).exists()

    def cleanup_all_locks(self):
        """ì‚¬ìš©ì ì •ë³´ ë””ë ‰í„°ë¦¬ ë‚´ ì”ì¡´ .xlsx.lock íŒŒì¼ ì¼ê´„ ì •ë¦¬"""
        try:
            for lockfile in self.base_dir.glob("*.xlsx.lock"):
                try:
                    lockfile.unlink(missing_ok=True)
                    logger.debug(f"[LOCK CLEANUP] ì„¸ì…˜ ì¢…ë£Œ ì „ ì œê±°ë¨: {lockfile}")
                except Exception as e:
                    logger.warning(f"[LOCK CLEANUP ì‹¤íŒ¨] {e}")
        except Exception as e:
            logger.warning(f"[LOCK CLEANUP ìŠ¤ìº” ì‹¤íŒ¨] {e}")
    
    # -----------------------------
    # ğŸ§© flush ë©”ì„œë“œ (ë²„í¼ â†’ Excel ë°˜ì˜)
    # -----------------------------
    def request_flush(self, user_name: str, delay: float = None):
        """
        flush_to_excel()ì„ ë°”ë¡œ ì‹¤í–‰í•˜ì§€ ì•Šê³ , ì•½ê°„ ì§€ì—°ì‹œì¼œ
        ë™ì‹œì— ì—¬ëŸ¬ ìš”ì²­ì´ ë“¤ì–´ì˜¬ ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ê²Œ ë³‘í•©í•œë‹¤.
        
        Args:
            user_name: ì‚¬ìš©ì ì´ë¦„
            delay: ì§€ì—° ì‹œê°„ (ì´ˆ), Noneì´ë©´ ê¸°ë³¸ê°’(self._flush_delay) ì‚¬ìš©
        """
        if delay is None:
            delay = self._flush_delay
        
        # ì´ë¯¸ ì˜ˆì•½ëœ flushê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ (user_nameë³„ë¡œ ê´€ë¦¬)
        if self._pending_flush.get(user_name, False):
            logger.debug(f"[FLUSH REQUEST] {user_name} - ì´ë¯¸ ì˜ˆì•½ëœ flush ìˆìŒ - ë³‘í•©ë¨")
            return
        
        self._pending_flush[user_name] = True
        logger.debug(f"[FLUSH REQUEST] {user_name} - flush ì˜ˆì•½ë¨ - {delay:.1f}ì´ˆ í›„ ì‹¤í–‰ ì˜ˆì •")
        
        def _delayed_flush():
            try:
                time.sleep(delay)
                with self._flush_lock:
                    logger.debug(f"[FLUSH THREAD] {user_name} - ì‹¤í–‰ ì‹œì‘")
                    self.flush_to_excel(user_name)
            except Exception as e:
                logger.error(f"[FLUSH THREAD ERROR] {user_name} - {e}")
                import traceback
                logger.error(traceback.format_exc())
            finally:
                self._pending_flush[user_name] = False
                logger.debug(f"[FLUSH THREAD] {user_name} - ì‹¤í–‰ ì™„ë£Œ")
        
        threading.Thread(target=_delayed_flush, daemon=True).start()
    
    def flush_to_excel(self, user_name: str):
        """ë²„í¼ ë‚´ìš©ì„ ì—‘ì…€ë¡œ ë™ê¸°í™”"""
        excel_path = self.get_user_excel_path(user_name)
        
        try:
            # âœ… ë””ë²„ê¹…: flush ì‹œì‘ ì‹œì  ë²„í¼ ìƒíƒœ í™•ì¸
            logger.info(f"[FLUSH DEBUG] flush ì‹œì‘ - ì „ì²´ ë²„í¼ í‚¤: {list(self._buffered_changes.keys())}")
            
            # ë²„í¼ì—ì„œ í•´ë‹¹ ì‚¬ìš©ì ë°ì´í„°ë§Œ ì¶”ì¶œ
            user_buffers = {k: v for k, v in self._buffered_changes.items() if k[0] == user_name}
            
            # âœ… ë””ë²„ê¹…: ì‚¬ìš©ìë³„ ë²„í¼ ìƒíƒœ í™•ì¸
            logger.info(f"[FLUSH DEBUG] {user_name} ë²„í¼ ìƒíƒœ: {[(k, len(v)) for k, v in user_buffers.items()]}")
            
            if not user_buffers:
                logger.debug(f"[FLUSH] {user_name} ë²„í¼ê°€ ë¹„ì–´ìˆìŒ")
                return
            
            # ê¸°ì¡´ ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”
            excel_file = self.load_user_excel(user_name)
            excel_data = {}
            
            if excel_file:
                # ê¸°ì¡´ ì‹œíŠ¸ë“¤ ë¡œë“œ
                for sheet in excel_file.sheet_names:
                    excel_data[sheet] = self.safe_load_sheet(user_name, sheet)
            else:
                # ìƒˆ íŒŒì¼ ì´ˆê¸°í™” (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)
                for sheet_name in SHEET_SCHEMAS.keys():
                    excel_data[sheet_name] = pd.DataFrame(columns=SHEET_SCHEMAS[sheet_name])
            
            # ë²„í¼ ë°ì´í„°ë¥¼ ê° ì‹œíŠ¸ì— ì¶”ê°€
            for (uname, sheet_name), records in user_buffers.items():
                # âœ… ë””ë²„ê¹…: ê° ì‹œíŠ¸ë³„ ì²˜ë¦¬ ì‹œì‘
                logger.debug(f"[FLUSH DEBUG] ì²˜ë¦¬ ì¤‘: ì‹œíŠ¸={sheet_name}, ë ˆì½”ë“œ ìˆ˜={len(records) if records else 0}")
                
                if not records:
                    logger.debug(f"[FLUSH DEBUG] ê±´ë„ˆëœ€: ì‹œíŠ¸={sheet_name} (ë ˆì½”ë“œ ì—†ìŒ)")
                    continue
                
                # DataFrame ìƒì„± ë° ìŠ¤í‚¤ë§ˆ ì •ë ¬
                try:
                    schema = SHEET_SCHEMAS.get(sheet_name, SHEET_SCHEMAS["ì‚¬ìš©ìì •ë³´KV"])
                    # âœ… ìŠ¤í‚¤ë§ˆ ìˆœì„œëŒ€ë¡œ ë ˆì½”ë“œ ì¬ì •ë ¬ (ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥)
                    ordered_records = []
                    for record in records:
                        ordered_record = {col: str(record.get(col, "")).strip() if record.get(col) is not None else "" for col in schema}
                        ordered_records.append(ordered_record)
                    
                    df_new = pd.DataFrame(ordered_records, columns=schema)
                    
                    # âœ… ë””ë²„ê¹…: ë¬¼ê±´ìœ„ì¹˜ ì‹œíŠ¸ ì €ì¥ ì‹œ í™•ì¸
                    if sheet_name == "ë¬¼ê±´ìœ„ì¹˜":
                        logger.debug(f"[FLUSH DEBUG] ë¬¼ê±´ìœ„ì¹˜ DataFrame:\n{df_new.head()}")
                        logger.debug(f"[FLUSH DEBUG] ë¬¼ê±´ìœ„ì¹˜ ì»¬ëŸ¼ ìˆœì„œ: {list(df_new.columns)}")
                except Exception as e:
                    logger.error(f"[FLUSH ERROR] DataFrame ìƒì„± ì‹¤íŒ¨: ì‹œíŠ¸={sheet_name}, ì˜¤ë¥˜={e}, ë ˆì½”ë“œ={records}")
                    import traceback
                    logger.error(traceback.format_exc())
                    continue
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                if sheet_name in excel_data:
                    df_existing = excel_data[sheet_name]
                    df_all = pd.concat([df_existing, df_new], ignore_index=True)
                else:
                    df_all = df_new

                # âœ… ë³µì•½ì •ë³´ ì‹œíŠ¸ëŠ” ì•½ëª…+ì‹œê°„+ë°©ë²•+ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ë™ì¼í•œ ë³µìš© ì •ë³´ëŠ” í•œ ë²ˆë§Œ ì €ì¥)
                if sheet_name == "ë³µì•½ì •ë³´" and not df_all.empty:
                    try:
                        # ì¤‘ë³µ ê¸°ì¤€: ì•½ì´ë¦„ + ì‹œê°„ + ë³µìš©ë°©ë²• + ë³µìš©ê¸°ê°„ì´ ëª¨ë‘ ë™ì¼í•œ ê²½ìš°
                        if all(col in df_all.columns for col in ["ì•½ì´ë¦„", "ì‹œê°„", "ë³µìš©ë°©ë²•", "ë³µìš©ê¸°ê°„"]):
                            # âœ… ë°ì´í„° ì •ê·œí™”: None/NaN â†’ ë¹ˆ ë¬¸ìì—´, ê³µë°± ì œê±°
                            for col in ["ì•½ì´ë¦„", "ì‹œê°„", "ë³µìš©ë°©ë²•", "ë³µìš©ê¸°ê°„"]:
                                df_all[col] = df_all[col].fillna("").astype(str).str.strip()
                            
                            # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ í›„ ì¤‘ë³µ ì œê±° (ìµœì‹ ê°’ ìœ ì§€)
                            df_all = df_all.sort_values("ë‚ ì§œ", na_position='last')
                            
                            # âœ… ë””ë²„ê¹…: ì¤‘ë³µ ì œê±° ì „ ë°ì´í„° í™•ì¸
                            logger.debug(f"[DUPLICATE CHECK] ë³µì•½ì •ë³´ ì¤‘ë³µ ì œê±° ì „: {len(df_all)}ê°œ ë ˆì½”ë“œ")
                            logger.debug(f"[DUPLICATE CHECK] ìƒ˜í”Œ ë°ì´í„°:\n{df_all[['ì•½ì´ë¦„', 'ì‹œê°„', 'ë³µìš©ë°©ë²•', 'ë³µìš©ê¸°ê°„']].head()}")
                            
                            # ì¤‘ë³µ ì œê±°: ì•½ì´ë¦„, ì‹œê°„, ë³µìš©ë°©ë²•, ë³µìš©ê¸°ê°„ì´ ëª¨ë‘ ë™ì¼í•œ ê²½ìš°
                            df_all = df_all.drop_duplicates(
                                subset=["ì•½ì´ë¦„", "ì‹œê°„", "ë³µìš©ë°©ë²•", "ë³µìš©ê¸°ê°„"],
                                keep="last"  # ìµœì‹ ê°’ ìœ ì§€
                            )
                            
                            logger.debug(f"[DUPLICATE CHECK] ë³µì•½ì •ë³´ ì¤‘ë³µ ì œê±° í›„: {len(df_all)}ê°œ ë ˆì½”ë“œ")
                            logger.debug(f"[FLUSH] ë³µì•½ì •ë³´ ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(df_new)}ê°œ ì¶”ê°€ â†’ {len(df_all)}ê°œ ìµœì¢…")
                    except Exception as e:
                        logger.warning(f"[FLUSH WARN] ë³µì•½ì •ë³´ ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())

                # âœ… ì‚¬ìš©ìì •ë³´KVëŠ” í‚¤ ê¸°ì¤€ ìµœì‹ ê°’ìœ¼ë¡œ update (ì¤‘ë³µ ì œê±°)
                if sheet_name == "ì‚¬ìš©ìì •ë³´KV" and not df_all.empty:
                    try:
                        # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ í›„ ê°™ì€ í‚¤ëŠ” ë§ˆì§€ë§‰(ìµœì‹ )ë§Œ ìœ ì§€
                        if "ë‚ ì§œ" in df_all.columns and "í‚¤" in df_all.columns:
                            df_all = df_all.sort_values("ë‚ ì§œ").drop_duplicates(subset=["í‚¤"], keep="last")
                    except Exception as _:
                        pass
                
                excel_data[sheet_name] = df_all
                # ì‹œíŠ¸ë³„ ì €ì¥ ë¡œê·¸ë¥¼ ì¼ê´€ë˜ê²Œ ë‚¨ê¹€ (ê°ì •ê¸°ë¡ í¬í•¨)
                logger.info(f"[FLUSH] {user_name}:{sheet_name} â†’ {len(df_new)}ê°œ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
            
            # ì „ì²´ ì—‘ì…€ íŒŒì¼ ì €ì¥
            with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
                for sheet_name, df_data in excel_data.items():
                    df_data.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ë²„í¼ì—ì„œ í•´ë‹¹ ì‚¬ìš©ì ë°ì´í„° ì œê±°
            keys_to_remove = [k for k in self._buffered_changes.keys() if k[0] == user_name]
            for k in keys_to_remove:
                del self._buffered_changes[k]
            
            # âœ… ë””ë²„ê¹…: flush ì™„ë£Œ í›„ ë²„í¼ ìƒíƒœ í™•ì¸
            remaining_buffers = [k for k in self._buffered_changes.keys() if k[0] == user_name]
            logger.info(f"[FLUSH SUMMARY] {user_name} ë²„í¼ ìƒíƒœ: {remaining_buffers if remaining_buffers else 'ë¹„ì–´ìˆìŒ'}")
            logger.info(f"[FLUSH] {user_name} ë²„í¼ â†’ ì—‘ì…€ ë™ê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"[ERROR] flush_to_excel ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())

    # -----------------------------
    # í¸ì˜ ì €ì¥ í•¨ìˆ˜ (ì—”í‹°í‹° ë‹¨ìœ„)
    # -----------------------------
    def save_entity(self, user_name: str, entity_type: str, entity_data: Dict[str, Any]):
        """ì—”í‹°í‹° ë‹¨ìœ„ ì €ì¥: íƒ€ì…â†’ì‹œíŠ¸ ë§¤í•‘ ë° ì •ê·œí™” í¬í•¨ (save_entity_data ë˜í¼)"""
        try:
            self.save_entity_data(user_name, entity_type, entity_data)
            logger.info(f"[BUFFER] {user_name}:{self._get_sheet_name(entity_type)} ì—”í‹°í‹° ë²„í¼ë§ë¨ ({entity_type})")
        except Exception as e:
            logger.error(f"[ERROR] save_entity ì‹¤íŒ¨: {e}")

from __future__ import annotations
# ğŸ”§ LangChain DeprecationWarning ì–µì œ
import warnings
try:
    from langchain_core._api import LangChainDeprecationWarning
    warnings.filterwarnings("ignore", category=LangChainDeprecationWarning)
except Exception:
    pass
from typing import Dict, Any, List, Tuple, Optional, Union
from dataclasses import dataclass
from pathlib import Path
import os
import sqlite3
import json
import hashlib
from datetime import datetime, timedelta
import re
import dateparser
import numpy as np
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# LangChain imports
from langchain.schema import HumanMessage, AIMessage
from langchain_core.runnables import Runnable
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from sqlalchemy import create_engine, text

# Confidence threshold ìƒìˆ˜ (task_classifier.pyì™€ ì¼ê´€ì„± ìœ ì§€)
CONFIDENCE_THRESHOLD = 0.6

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables.config import RunnableConfig
from langchain_community.chat_message_histories import SQLChatMessageHistory
from langchain.schema import StrOutputParser, Document
from langchain_core.output_parsers import JsonOutputParser

from .task_classifier import classify_hybrid, ClassificationResult
from .support_chains import build_emotional_reply, handle_physical_task, handle_pending_answer
from life_assist_dm.life_assist_dm.llm.gpt_utils import get_llm, get_embedding
import pandas as pd


@dataclass
class MemoryConfig:
    """ë©”ëª¨ë¦¬ ë™ì‘ ì„¤ì •ê°’"""
    sqlite_path: str = "~/.life_assist_dm/history.sqlite"
    chroma_dir: str = "~/.life_assist_dm/chroma"
    summary_enabled: bool = True
    retriever_search_k: int = 5
    buffer_window: int = 3
    auto_export_enabled: bool = True
    export_dir: str = "conversation_extract"


# ìµœì†Œ normalization dict (ë™ì˜ì–´ í†µì¼ìš©)
NORMALIZE_KEYS = {
    "ì—„ë§ˆ": "ì–´ë¨¸ë‹ˆ",
    "ì•„ë¹ ": "ì•„ë²„ì§€",
    "í•¸ë“œí°": "íœ´ëŒ€í°",
    "í•¸í°": "íœ´ëŒ€í°",
}

# ë¶ˆìš©ì–´ (ì¡°ì‚¬ëŠ” _normalize_locationì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì œì™¸)
STOPWORDS = {
    "í•œ", "ë²ˆ", "ì¯¤", "ì‹œì¯¤", "ì‹í›„ì—", "ì‹ì „ì—", "ë°˜ì¯¤", "ì‹œ",
    "ë§Œ", "ë„", "ë§Œí¼", "ì •ë„", "ì¯¤", "ê°€ëŸ‰", "ì•½", "ëŒ€ëµ"
}

# ì´ë¦„ ì¶”ì¶œ ê¸ˆì§€ ë‹¨ì–´ (ë‹¨ì–´ ë‹¨ìœ„ ë§¤ì¹­ë§Œ ì ìš©)
NAME_BLACKLIST = {
    "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ê·¸ì œ", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ë°¤", "ë‚®",
    "ê·¸ëƒ¥", "ê·¸ë˜", "ì‘", "ë„¤", "ì•„ë‹ˆ", "ë§ì•„", "ì¢‹ì•„", "ì‹«ì–´",
    "ë¨¹ì—ˆ", "ë¨¹ì–´", "ë§ˆì…”", "ë§ˆì…¨", "ê°”", "ì™”", "ìˆ", "ì—†",
    "í–ˆ", "í–ˆì–´", "í• ", "í• ê²Œ", "í• ë˜", "í•˜ê³ ", "í•´ì„œ",
    "ê·¸", "ì´", "ì €", "ë‚´", "ë„¤", "ìš°ë¦¬", "ë„ˆ", "ë‚˜", "ì €í¬",
    "ë­ë¼ê³ ", "ëˆ„êµ¬ê²Œ", "ë­ê²Œ", "ë­”ê°€", "ë­”ì§€", "ë­ì§€", "ë­ì•¼",
    "ëˆ„êµ¬ì•¼", "ëˆ„êµ¬ì§€", "ëˆ„êµ¬ì¸ì§€", "ëˆ„êµ¬ì¸ê°€", "ëˆ„êµ¬ì¸ê°€ìš”"
}

# ì•½ ê´€ë ¨ í‚¤ì›Œë“œ (ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ê³µí†µ ìƒìˆ˜)
MEDICINE_KEYWORDS = [
    "ì•Œì•½", "ì²˜ë°©", "ë³µìš©", "ë³µìš©ë²•", "ë³µìš©ì‹œê°„", "ì‹í›„", "ì‹ì „", "ê³µë³µ",
    "ë¹„íƒ€ë¯¼", "ì˜ì–‘ì œ", "ì˜¤ë©”ê°€3", "ì˜¤ë©”ê°€ 3", "ì² ë¶„ì œ", "í”„ë¡œí‹´", "ë³´ì¶©ì œ",
    "ìœ ì‚°ê· ", "í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤", "ë§ˆê·¸ë„¤ìŠ˜", "ì¹¼ìŠ˜", "ì•„ì—°", "ì—½ì‚°"
]

# ì•½ íŒ¨í„´ (ì •ê·œì‹)
COMMON_MED_PATTERNS = [
    r"(ë¹„íƒ€ë¯¼\s*[A-Z]?\d*)", r"(ì˜¤ë©”ê°€\s*3)", r"(ì˜¤ë©”ê°€3)", r"(ì² ë¶„ì œ)", r"(í”„ë¡œí‹´)",
    r"(ë³´ì¶©ì œ)", r"(ì˜ì–‘ì œ)", r"(ìœ ì‚°ê· )", r"(ìœ ì‚°ê· ì œ)", r"(í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤)",
    r"(ë§ˆê·¸ë„¤ìŠ˜)", r"(ì¹¼ìŠ˜)", r"(ì•„ì—°)", r"(ì—½ì‚°)", r"([ê°€-í£A-Za-z]+)\s*(?:ì„|ë¥¼)?\s*ë¨¹"
]

# ë³µìš© ë°©ë²• íŒ¨í„´ (ì •ê·œì‹)
METHOD_PATTERNS = [
    r"ì‹í›„\s*(\d+)\s*ë¶„", r"ì‹í›„\s*(\d+)ë¶„", r"ì‹ì „", r"ê³µë³µ", r"ì‹ì‚¬\s*í›„", r"ì‹ì‚¬\s*ì „"
]

# ì‹œê°„ëŒ€ í‚¤ì›Œë“œ ë§¤í•‘
TIME_OF_DAY_KEYWORDS = {
    "ì•„ì¹¨": ["ì•„ì¹¨", "ì¡°ì‹", "morning", "breakfast", "ê¸°ìƒ", "ì¼ì–´ë‚˜ìë§ˆì", "ì¼ì–´ë‚˜ì ë§ˆì", "ê¸°ìƒ í›„", "ê¸°ìƒ ì‹œ"],
    "ì ì‹¬": ["ì ì‹¬", "ì¤‘ì‹", "lunch"],
    "ì €ë…": ["ì €ë…", "ì„ì‹", "dinner", "evening"]
}

# ë³µìš© ë°©ë²• í‚¤ì›Œë“œ ë§¤í•‘
MEDICATION_METHOD_KEYWORDS = {
    "ê³µë³µ": ["ê³µë³µ", "ê³µë³µì—"],
    "ì‹ì „": ["ì‹ì „", "ì‹ì „ì—"],
    "ì‹í›„": ["ì‹í›„", "ì‹í›„ì—"]
}

# í•œê¸€ ìˆ«ì ë³€í™˜ ë”•ì…”ë„ˆë¦¬ (ë¬¸ìì—´ ë³€í™˜ìš©)
KOREAN_NUMBERS_STR = {
    "í•œ": "1", "ë‘": "2", "ì„¸": "3", "ë„¤": "4", "ë‹¤ì„¯": "5",
    "ì—¬ì„¯": "6", "ì¼ê³±": "7", "ì—¬ëŸ": "8", "ì•„í™‰": "9", "ì—´": "10"
}

# í•œê¸€ ìˆ«ì ë³€í™˜ ë”•ì…”ë„ˆë¦¬ (ì •ìˆ˜ ë³€í™˜ìš©)
KOREAN_NUMBERS_INT = {
    "í•œ": 1, "ë‘": 2, "ì„¸": 3, "ë„¤": 4, "ë‹¤ì„¯": 5,
    "ì—¬ì„¯": 6, "ì¼ê³±": 7, "ì—¬ëŸ": 8, "ì•„í™‰": 9, "ì—´": 10
}


class LifeAssistMemory:
    """ìƒí™œ ì§€ì› ë©”ëª¨ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, cfg: MemoryConfig, session_id: str = "default", debug: bool = False):
        self.cfg = cfg
        self.session_id = session_id
        
        # ë¡œê¹… ì„¤ì •
        if debug:
            logging.basicConfig(level=logging.DEBUG)
        else:
            logging.basicConfig(level=logging.INFO)
        
        # ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ (ì´ì „ ëŒ€í™”ì—ì„œ ì‹œê°„ ì •ë³´ ì—°ê²°ìš©)
        self.time_context = {}  # {session_id: {"last_time": "7ì‹œë°˜", "last_meal": "ì ì‹¬"}}
        
        # ê°ì • ìƒíƒœ ì¶”ì  (ì¼ê´€ì„± ìˆëŠ” ì‘ë‹µì„ ìœ„í•´)
        self.emotional_state = {}  # {session_id: {"mood": "negative", "intensity": 0.8, "last_emotional_turn": 3}}
        
        # ë¬¼ë¦¬ì  ì‘ì—… ì¬ì§ˆë¬¸ ìƒíƒœ ê´€ë¦¬ (pending_questionìœ¼ë¡œ í†µí•©ë¨)
        
        # ì‚¬ìš©ì ì´ë¦„ ì„¸ì…˜ë³„ ì¶”ì 
        self.user_names = {}  # {session_id: user_name}
        
        # LLM ì´ˆê¸°í™”
        from life_assist_dm.life_assist_dm.llm.gpt_utils import get_llm, get_embedding
        self.llm = get_llm()
        self.debug = debug

        # ê²½ë¡œ ì¤€ë¹„
        self.sqlite_path = str(Path(os.path.expanduser(cfg.sqlite_path)))
        Path(self.sqlite_path).parent.mkdir(parents=True, exist_ok=True)

        # ì—‘ì…€ ì „ìš©ìœ¼ë¡œ ë³€ê²½ - VectorStore ì œê±°
        self.vectorstore = None
        self.vector_store = None
        self.retriever = None
        
        # Excel ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (ë²„í¼ë§ êµ¬ì¡°)
        from .user_excel_manager import UserExcelManager
        self.excel_manager = UserExcelManager()
        
        # ì„ë² ë”© ê¸°ë°˜ ìºì‹œ ì‹œìŠ¤í…œ
        self.classification_cache = {}  # {text: ClassificationResult}
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)
        self.cache_embeddings = None
        self.cache_texts = []
        self.similarity_threshold = 0.95  # ìœ ì‚¬ë„ ì„ê³„ê°’ 
        
        # ë‚ ì§œ ì •ê·œí™” ìºì‹œ ì‹œìŠ¤í…œ
        self.date_cache = {}  # {date_str: normalized_date}
        self.max_date_cache_size = 1000  # ìµœëŒ€ ìºì‹œ í¬ê¸°

        # ì—”í‹°í‹° ì¶”ì¶œ ì²´ì¸
        self.entity_chain = self._build_entity_chain()

        # LCEL ì²´ì¸ ì´ˆê¸°í™” (SQLite ë°±ì—”ë“œ ì‚¬ìš©)
        from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory
        from langchain_community.chat_message_histories import SQLChatMessageHistory
        
        # SQLite ë°±ì—”ë“œ ì„¤ì •
        engine = create_engine(f"sqlite:///{self.sqlite_path}")
        self._ensure_message_table_exists(engine)
        
        # SQLite ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.conversation_memory = ConversationBufferMemory(
            memory_key="history",
            return_messages=True,
            chat_memory=SQLChatMessageHistory(
                session_id="default_session",
                connection=engine
            )
        )
        
        # ìš”ì•½ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (ConversationSummaryBufferMemory)
        from life_assist_dm.life_assist_dm.llm.gpt_utils import get_llm, get_embedding
        llm = get_llm()
        self.summary_memory = ConversationSummaryBufferMemory(
            llm=llm,
            max_token_limit=1000,
            return_messages=True,
            memory_key="summary_history"
        )

        # ìƒíƒœ ê´€ë¦¬
        self.pending_context: Dict[str, str] = {}
        self.asked_pending: Dict[str, str] = {}
        self.pending_question: Dict[str, dict] = {}  # ì¬ì§ˆë¬¸ ìƒíƒœ ê´€ë¦¬
        self.current_question: Dict[str, str] = {}  # í˜„ì¬ ì¬ì§ˆë¬¸ ì €ì¥
        self._init_sqlite()

    # SQLite í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ ë°ì´í„° ë³´ì¡´)
    def _init_sqlite(self):
        # ì œê±°ë¨: SQLite ë¹„ì‚¬ìš© ë¡œê·¸
        conn = sqlite3.connect(self.sqlite_path)
        c = conn.cursor()
        
        # ê¸°ì¡´ ê¸°ë¡ ë³´ì¡´í•˜ë©° í…Œì´ë¸” ìƒì„±
        c.execute(
            "CREATE TABLE IF NOT EXISTS conversation_summary ("
            "id INTEGER PRIMARY KEY AUTOINCREMENT, "
            "session_id TEXT, "
            "summary TEXT, "
            "entity_type TEXT, "
            "content TEXT, "
            "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, "
            "updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)"
        )
        
        # ëŒ€í™” ìš”ì•½ ì „ìš© í…Œì´ë¸” ìƒì„±
        c.execute(
            "CREATE TABLE IF NOT EXISTS conversation_summaries ("
            "id INTEGER PRIMARY KEY AUTOINCREMENT, "
            "session_id TEXT NOT NULL, "
            "summary_text TEXT NOT NULL, "
            "token_count INTEGER, "
            "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, "
            "updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)"
        )
        
        # ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ í…Œì´ë¸” ìƒì„±
        c.execute(
            "CREATE TABLE IF NOT EXISTS conversation_history ("
            "id INTEGER PRIMARY KEY AUTOINCREMENT, "
            "session_id TEXT NOT NULL, "
            "message_type TEXT NOT NULL, "  # 'human' or 'ai'
            "message_content TEXT NOT NULL, "
            "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)"
        )
        
        # updated_at ìë™ ê°±ì‹  íŠ¸ë¦¬ê±° ì¶”ê°€
        c.execute(
            "CREATE TRIGGER IF NOT EXISTS trg_update_summary "
            "AFTER UPDATE ON conversation_summary "
            "BEGIN "
            "UPDATE conversation_summary SET updated_at = CURRENT_TIMESTAMP "
            "WHERE id = NEW.id; "
            "END;"
        )
        
        # message_store í…Œì´ë¸” ìƒì„± (SQLChatMessageHistory í˜¸í™˜)
        c.execute(
            "CREATE TABLE IF NOT EXISTS message_store ("
            "id INTEGER PRIMARY KEY AUTOINCREMENT, "
            "session_id TEXT, "
            "role TEXT, "
            "content TEXT, "
            "message TEXT, "
            "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)"
        )
        
        # created_at ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
        except sqlite3.OperationalError:
            # ì´ë¯¸ created_at ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë¬´ì‹œ
            pass
        
        # ì„¸ì…˜ë³„ ì¸ë±ìŠ¤ ìƒì„±
        c.execute("CREATE INDEX IF NOT EXISTS idx_session_id ON conversation_summary(session_id)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_message_session_id ON message_store(session_id)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_summaries_session_id ON conversation_summaries(session_id)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_history_session_id ON conversation_history(session_id)")
        
        # message ì»¬ëŸ¼ ì¶”ê°€ (SQLiteëŠ” DROP COLUMNì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ contentëŠ” ìœ ì§€)
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN message TEXT")
        except sqlite3.OperationalError:
            # ì´ë¯¸ message ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë¬´ì‹œ
            pass
        
        # role ì»¬ëŸ¼ ì¶”ê°€ (LangChain SQLChatMessageHistory í˜¸í™˜)
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN role TEXT")
        except sqlite3.OperationalError:
            # ì´ë¯¸ role ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë¬´ì‹œ
            pass
        
        # ì¶”ê°€ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ (LangChain í˜¸í™˜ì„±)
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN name TEXT")
        except sqlite3.OperationalError:
            pass
        
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN tool_calls_json TEXT")
        except sqlite3.OperationalError:
            pass
        
        try:
            c.execute("ALTER TABLE message_store ADD COLUMN additional_kwargs TEXT")
        except sqlite3.OperationalError:
            pass
        
        conn.commit()
        conn.close()
        # ì œê±°ë¨: SQLite ë¹„ì‚¬ìš© ë¡œê·¸

# _load_session_context í•¨ìˆ˜ ì œê±°ë¨ - load_previous_session_dataë¡œ í†µí•©

    def _get_user_entities_from_excel(self) -> List[str]:
        """Excel ìºì‹œ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ê´€ë ¨ ì—”í‹°í‹° ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        entities = []
        try:
            session_id = "default_session"
            if hasattr(self, "excel_cache"):
                sess = self.excel_cache.get(session_id, {})
                # ì‚¬ìš©ì ì´ë¦„
                user = sess.get("ì‚¬ìš©ì", [])
                if user and user[0].get("ì´ë¦„"):
                    entities.append(f"ì‚¬ìš©ì ì´ë¦„: {user[0]['ì´ë¦„']}")
                # ë¬¼ê±´ ìœ„ì¹˜
                items = sess.get("ë¬¼ê±´", [])
                for it in items:
                    if it.get("ì´ë¦„") and it.get("ìœ„ì¹˜"):
                        entities.append(f"{it['ì´ë¦„']}: {it['ìœ„ì¹˜']}")
        except Exception as e:
            print(f"[ERROR] ì—”í‹°í‹° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return entities

    

    def get_location(self, target: str, return_dict: bool = False) -> Optional[Union[str, dict]]:
        """íŠ¹ì • ë¬¼ê±´ì˜ ì €ì¥ëœ ìœ„ì¹˜ ì¡°íšŒ (ì„¸ì…˜ ìºì‹œ â†’ ì—‘ì…€). VectorStore ë¯¸ì‚¬ìš©.
        
        Args:
            target: ë¬¼ê±´ ì´ë¦„
            return_dict: Trueë©´ dict í˜•íƒœë¡œ ë°˜í™˜ (ì¥ì†Œ, ì„¸ë¶€ìœ„ì¹˜ ë¶„ë¦¬), Falseë©´ ë¬¸ìì—´ ë°˜í™˜
        """
        try:
            session_id = "default_session"
            # 1) ì„¸ì…˜ ìºì‹œ
            if hasattr(self, 'excel_cache'):
                items = self.excel_cache.get(session_id, {}).get("ë¬¼ê±´", [])
                for it in reversed(items):
                    if it.get("ì´ë¦„") == target:
                        if return_dict:
                            place = it.get("ì¥ì†Œ", "")
                            sub_location = it.get("ì„¸ë¶€ìœ„ì¹˜", "")
                            if place or sub_location:
                                return {"ì¥ì†Œ": place, "ì„¸ë¶€ìœ„ì¹˜": sub_location}
                        elif it.get("ìœ„ì¹˜"):
                            return it.get("ìœ„ì¹˜")
            # 2) ì—‘ì…€
            user_name = self.user_names.get(session_id)
            if not user_name:
                return None
            df = self.excel_manager.load_sheet_data(user_name, "ë¬¼ê±´ìœ„ì¹˜")
            if df is not None and not df.empty:
                for _, row in df.iloc[::-1].iterrows():
                    name_v = row.get("ë¬¼ê±´ì´ë¦„", None) or row.get("ì´ë¦„", "")
                    if str(name_v) == target:
                        if return_dict:
                            place = str(row.get("ì¥ì†Œ", "") or "").strip()
                            sub_location = str(row.get("ì„¸ë¶€ìœ„ì¹˜", "") or "").strip()
                            # nan, None í•„í„°ë§
                            if place.lower() in ['nan', 'none', '']:
                                place = ''
                            if sub_location.lower() in ['nan', 'none', '']:
                                sub_location = ''
                            if place or sub_location:
                                return {"ì¥ì†Œ": place, "ì„¸ë¶€ìœ„ì¹˜": sub_location}
                        else:
                            loc_v = row.get("ìœ„ì¹˜", "")
                            if str(loc_v).strip() != "":
                                return str(loc_v).strip()
                            # ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ ì¥ì†Œì™€ ì„¸ë¶€ìœ„ì¹˜ë¥¼ ì¡°í•©
                            place = str(row.get("ì¥ì†Œ", "") or "").strip()
                            sub_location = str(row.get("ì„¸ë¶€ìœ„ì¹˜", "") or "").strip()
                            # nan, None í•„í„°ë§
                            if place.lower() in ['nan', 'none', '']:
                                place = ''
                            if sub_location.lower() in ['nan', 'none', '']:
                                sub_location = ''
                            if place and sub_location:
                                return f"{place} {sub_location}"
                            elif place:
                                return place
                            elif sub_location:
                                return sub_location
            return None
        except Exception as e:
            print(f"[ERROR] get_location ì‹¤íŒ¨: {e}")
            return None

    def save_location(self, item_name: str, location: str, overwrite: bool = True) -> None:
        """ë¬¼ê±´ ìœ„ì¹˜ë¥¼ ì—‘ì…€ì— ì €ì¥í•˜ê³  ì„¸ì…˜ ìºì‹œì— ë°˜ì˜."""
        try:
            session_id = "default_session"
            user_name = self.user_names.get(session_id)
            if not user_name:
                return
            self.excel_manager.save_entity_data(user_name, "ë¬¼ê±´", {"ë¬¼ê±´ì´ë¦„": item_name, "ìœ„ì¹˜": location})
            # ìºì‹œì— ë°˜ì˜
            if not hasattr(self, 'excel_cache'):
                self.excel_cache = {}
            session_cache = self.excel_cache.setdefault(session_id, {})
            items = session_cache.setdefault("ë¬¼ê±´", [])
            if overwrite:
                # ê¸°ì¡´ ë™ì¼ ì´ë¦„ ì œê±° í›„ ì¶”ê°€
                items = [it for it in items if it.get("ì´ë¦„") != item_name]
                session_cache["ë¬¼ê±´"] = items
            items.append({"ì´ë¦„": item_name, "ìœ„ì¹˜": location})
        except Exception as e:
            print(f"[ERROR] save_location ì‹¤íŒ¨: {e}")

    def _build_context_for_llm(self, user_input: str, session_id: str) -> str:
        """LLM ì‘ë‹µ ìƒì„±ì„ ìœ„í•œ í†µí•© ë§¥ë½ êµ¬ì„± (ì—‘ì…€ ìºì‹œ + ëŒ€í™” íˆìŠ¤í† ë¦¬)."""
        try:
            context_parts = []
            
            # 1. LCEL Chainì—ì„œ í˜„ì¬ ì„¸ì…˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë”©
            try:
                mem_vars = self.conversation_memory.load_memory_variables({})
                history = mem_vars.get("history", "")
                if history:
                    context_parts.append(f"[í˜„ì¬ ì„¸ì…˜ ëŒ€í™” íˆìŠ¤í† ë¦¬]\n{history}")
            except Exception as e:
                print(f"[WARN] LCEL Chain íˆìŠ¤í† ë¦¬ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 2. ì—‘ì…€ ìºì‹œì—ì„œ ìµœê·¼ ì €ì¥ ì •ë³´ êµ¬ì„±
            try:
                if hasattr(self, 'excel_cache'):
                    sess = session_id or "default_session"
                    user_data = self.excel_cache.get(sess, {})
                    items = user_data.get("ë¬¼ê±´", [])
                    if items:
                        lines = [f"- {it.get('ì´ë¦„')}: {it.get('ìœ„ì¹˜')}" for it in items[-5:]]
                        context_parts.append("[ì €ì¥ëœ ë¬¼ê±´ ìœ„ì¹˜]\n" + "\n".join(lines))
            except Exception as e:
                print(f"[WARN] ì—‘ì…€ ìºì‹œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì‹¤íŒ¨: {e}")
            
            # 3. ë§¥ë½ í†µí•©
            if context_parts:
                return "\n\n".join(context_parts) + "\n\n"
            else:
                return ""
                
        except Exception as e:
            print(f"[ERROR] ë§¥ë½ êµ¬ì„± ì‹¤íŒ¨: {e}")
            return ""

    def end_session(self, session_id: str) -> str:
        """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì „ì²´ ëŒ€í™” ìš”ì•½ ìƒì„± ë° ì €ì¥"""
        try:
            print(f"[DEBUG] ì„¸ì…˜ ì¢…ë£Œ: {session_id}")
            
            # í˜„ì¬ ëŒ€í™” ë©”ëª¨ë¦¬ì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
            messages = self.conversation_memory.chat_memory.messages
            
            if len(messages) < 2:  # ìµœì†Œ 1ë²ˆì˜ ëŒ€í™” (human + ai)
                print(f"[DEBUG] ìš”ì•½í•  ëŒ€í™”ê°€ ë¶€ì¡±í•¨: {len(messages)}ê°œ ë©”ì‹œì§€")
                return ""
            
            # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = ""
            for msg in messages:
                if hasattr(msg, 'content'):
                    role = "ì‚¬ìš©ì" if msg.__class__.__name__ == "HumanMessage" else "AI"
                    conversation_text += f"{role}: {msg.content}\n"
            
            # ìš”ì•½ ìƒì„±
            from life_assist_dm.life_assist_dm.llm.gpt_utils import get_llm, get_embedding
            llm = get_llm()
            
            summary_prompt = f"""
            ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ì •ë³´(ì´ë¦„, ìœ„ì¹˜, ì¼ì • ë“±)ì™€ ì¤‘ìš”í•œ ëŒ€í™” ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
            
            ëŒ€í™” ë‚´ìš©:
            {conversation_text}                            
            ìš”ì•½:
            """
            
            summary = llm.invoke(summary_prompt).content.strip()
            
            # SQLiteì— ìš”ì•½ ì €ì¥
            conn = sqlite3.connect(self.sqlite_path)
            cursor = conn.cursor()
            
            cursor.execute(
                "INSERT INTO conversation_summaries (session_id, summary_text, token_count) VALUES (?, ?, ?)",
                (session_id, summary, len(summary.split()))
            )
            
            conn.commit()
            conn.close()
            
            print(f"[DEBUG] ì„¸ì…˜ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary[:50]}...")
            
            # ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (ë‹¤ìŒ ì„¸ì…˜ì„ ìœ„í•´)
            self.conversation_memory.clear()
            
            return summary
            
        except Exception as e:
            print(f"[ERROR] ì„¸ì…˜ ì¢…ë£Œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""


    # ì œê±°: SQLite ë¹„ì‚¬ìš© ì •ì±…ì— ë”°ë¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ í•¨ìˆ˜ ì‚­ì œ

    def load_user_data_from_excel(self, user_name: str, session_id: str):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ì‚¬ìš©ì ë°ì´í„° ë¡œë”© (SQLite/VectorStore ëŒ€ì‹ )"""
        try:
            print(f"[DEBUG] ì—‘ì…€ì—ì„œ ì‚¬ìš©ì ë°ì´í„° ë¡œë”© ì‹œì‘: {user_name}")
            
            if not self.excel_manager.user_exists(user_name):
                print(f"[DEBUG] ì‚¬ìš©ì ì—‘ì…€ íŒŒì¼ ì—†ìŒ: {user_name}")
                return
            
            # ì—‘ì…€ì—ì„œ ê° ì‹œíŠ¸ ë°ì´í„° ë¡œë”©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì„ì‹œ ì €ì¥
            sheets_data = {}
            
            # ë¬¼ê±´ ìœ„ì¹˜ ë¡œë”©
            df_items = self.excel_manager.load_sheet_data(user_name, "ë¬¼ê±´ìœ„ì¹˜")
            if not df_items.empty:
                items = []
                for _, row in df_items.iterrows():
                    # ê³¼ê±° ë°ì´í„° í˜¸í™˜: 'ë¬¼ê±´ì´ë¦„' ìš°ì„ , ì—†ìœ¼ë©´ 'ì´ë¦„' ì‚¬ìš©
                    name_val = row.get("ë¬¼ê±´ì´ë¦„", None)
                    if name_val is None or name_val == "":
                        name_val = row.get("ì´ë¦„", "")
                    loc_val = row.get("ìœ„ì¹˜", "")
                    try:
                        import pandas as pd
                        if pd.isna(name_val):
                            name_val = ""
                        if pd.isna(loc_val):
                            loc_val = ""
                    except Exception:
                        pass
                    items.append({
                        "ì´ë¦„": name_val,
                        "ìœ„ì¹˜": loc_val
                    })
                sheets_data["ë¬¼ê±´"] = items
                print(f"[DEBUG] ë¬¼ê±´ ìœ„ì¹˜ {len(items)}ê°œ ë¡œë”©")
            
            # ê°€ì¡± ê´€ê³„ ë¡œë”©
            df_family = self.excel_manager.load_sheet_data(user_name, "ê°€ì¡±ê´€ê³„")
            if not df_family.empty:
                family = []
                for _, row in df_family.iterrows():
                    family.append({
                        "ê´€ê³„": row.get("ê´€ê³„", ""),
                        "ì´ë¦„": row.get("ì´ë¦„", ""),
                        "ì •ë³´": row.get("ì •ë³´", "")
                    })
                sheets_data["ê°€ì¡±"] = family
                print(f"[DEBUG] ê°€ì¡± ê´€ê³„ {len(family)}ê°œ ë¡œë”©")
            
            # ì¼ì • ë¡œë”©
            df_schedule = self.excel_manager.load_sheet_data(user_name, "ì¼ì •")
            if not df_schedule.empty:
                schedules = []
                for _, row in df_schedule.iterrows():
                    schedules.append({
                        "ì œëª©": row.get("ì¼ì •ë‚´ìš©", ""),
                        "ë‚ ì§œ": row.get("ë‚ ì§œ", ""),
                        "ì‹œê°„": row.get("ì‹œê°„", ""),
                        "ì¥ì†Œ": row.get("ì¥ì†Œ", "")
                    })
                sheets_data["ì¼ì •"] = schedules
                print(f"[DEBUG] ì¼ì • {len(schedules)}ê°œ ë¡œë”©")
            
            # ëŒ€í™” ê¸°ë¡ ë¡œë”© (ìµœê·¼ 10ê°œ) ë° LCEL ë©”ëª¨ë¦¬ì— ì¶”ê°€
            df_conversations = self.excel_manager.load_sheet_data(user_name, "ëŒ€í™”ê¸°ë¡")
            if not df_conversations.empty:
                # ìµœê·¼ 10ê°œ ë¡œë”© (ë” ë§ì€ ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•´)
                recent_conversations = df_conversations.tail(10)
                conversations = []
                
                # LCEL ë©”ëª¨ë¦¬ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€
                try:
                    # ê¸°ì¡´ ì„¸ì…˜ ë©”ëª¨ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                    chat_memory = self.conversation_memory.chat_memory
                    
                    # ê¸°ì¡´ ë©”ì‹œì§€ê°€ ì—†ì„ ë•Œë§Œ ì—‘ì…€ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                    existing_messages = chat_memory.messages
                    if not existing_messages or len(existing_messages) == 0:
                        print(f"[DEBUG] ê¸°ì¡´ ë©”ì‹œì§€ ì—†ìŒ - ì—‘ì…€ ëŒ€í™” ê¸°ë¡ì„ LCEL ë©”ëª¨ë¦¬ì— ë¡œë”©")
                        
                        for _, row in recent_conversations.iterrows():
                            conv_summary = row.get("ëŒ€í™”ìš”ì•½", "")
                            if not conv_summary or str(conv_summary).strip() == "":
                                continue
                            
                            conv_text = str(conv_summary).strip()
                            conversations.append({
                                "ë‚ ì§œ": row.get("ë‚ ì§œ", ""),
                                "ì‹œê°„": row.get("ì‹œê°„", ""),
                                "ëŒ€í™”ìš”ì•½": conv_text
                            })
                            
                            # ëŒ€í™” ìš”ì•½ íŒŒì‹±: "Q: ì§ˆë¬¸ | A: ë‹µë³€" í˜•ì‹
                            question = None
                            answer = None
                            
                            # 1. "Q: ì§ˆë¬¸ | A: ë‹µë³€" í˜•ì‹ ì²˜ë¦¬
                            if "Q:" in conv_text and "A:" in conv_text:
                                # " | A:" íŒ¨í„´ìœ¼ë¡œ split
                                if " | A:" in conv_text:
                                    parts = conv_text.split(" | A:", 1)
                                    if len(parts) == 2:
                                        question = parts[0].replace("Q:", "").strip()
                                        answer = parts[1].strip()
                                else:
                                    # "A:" ê¸°ì¤€ìœ¼ë¡œ split (ëŒ€ì²´ ë°©ë²•)
                                    parts = conv_text.split("A:", 1)
                                    if len(parts) == 2:
                                        question = parts[0].replace("Q:", "").strip()
                                        answer = parts[1].strip()
                            
                            # 2. "ì§ˆë¬¸ | ë‹µë³€" í˜•ì‹ ì²˜ë¦¬ (Q: A: ì—†ì´)
                            elif "|" in conv_text and not question:
                                parts = conv_text.split("|", 1)
                                if len(parts) == 2:
                                    question = parts[0].strip()
                                    answer = parts[1].strip()
                            
                            # 3. íŒŒì‹±ëœ ì§ˆë¬¸/ë‹µë³€ì„ ë©”ëª¨ë¦¬ì— ì¶”ê°€
                            if question and answer:
                                chat_memory.add_user_message(question)
                                chat_memory.add_ai_message(answer)
                            elif question:
                                # ì§ˆë¬¸ë§Œ ìˆëŠ” ê²½ìš°
                                chat_memory.add_user_message(question)
                            elif answer:
                                # ë‹µë³€ë§Œ ìˆëŠ” ê²½ìš° (ì¼ë°˜ì ì´ì§€ ì•Šì§€ë§Œ)
                                chat_memory.add_ai_message(answer)
                            else:
                                # ë‹¨ìˆœ í…ìŠ¤íŠ¸ì¸ ê²½ìš° - ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ê°„ì£¼
                                # (ì‹œìŠ¤í…œ ë©”ì‹œì§€ë‚˜ ìš”ì•½ ë“±ì€ ê±´ë„ˆë›°ê¸°)
                                if conv_text:
                                    # ë„ˆë¬´ ì§§ê±°ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ê°™ì€ ê²ƒì€ ê±´ë„ˆë›°ê¸°
                                    skip_keywords = ["ì„¸ì…˜", "íƒ€ì„ì•„ì›ƒ", "ì¢…ë£Œ", "ì´ˆê¸°í™”"]
                                    if len(conv_text) > 5 and not any(kw in conv_text for kw in skip_keywords):
                                        chat_memory.add_user_message(conv_text)
                        
                        print(f"[DEBUG] LCEL ë©”ëª¨ë¦¬ì— ëŒ€í™” ê¸°ë¡ {len(conversations)}ê°œ ì¶”ê°€ ì™„ë£Œ")
                    else:
                        print(f"[DEBUG] ê¸°ì¡´ ë©”ì‹œì§€ ì¡´ì¬ ({len(existing_messages)}ê°œ) - ì—‘ì…€ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ ê±´ë„ˆëœ€")
                        
                        # ìºì‹œìš©ìœ¼ë¡œë§Œ ì €ì¥
                        for _, row in recent_conversations.iterrows():
                            conversations.append({
                                "ë‚ ì§œ": row.get("ë‚ ì§œ", ""),
                                "ì‹œê°„": row.get("ì‹œê°„", ""),
                                "ëŒ€í™”ìš”ì•½": row.get("ëŒ€í™”ìš”ì•½", "")
                            })
                except Exception as e:
                    print(f"[ERROR] LCEL ë©”ëª¨ë¦¬ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€ ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
                    # ì‹¤íŒ¨í•´ë„ ìºì‹œëŠ” ì €ì¥
                    for _, row in recent_conversations.iterrows():
                        conversations.append({
                            "ë‚ ì§œ": row.get("ë‚ ì§œ", ""),
                            "ì‹œê°„": row.get("ì‹œê°„", ""),
                            "ëŒ€í™”ìš”ì•½": row.get("ëŒ€í™”ìš”ì•½", "")
                        })
                
                sheets_data["ëŒ€í™”"] = conversations
                print(f"[DEBUG] ëŒ€í™” ê¸°ë¡ {len(conversations)}ê°œ ë¡œë”© (ìºì‹œ)")

            # ì‚¬ìš©ì ê°œì¸ì •ë³´ ë¡œë”©: ì‚¬ìš©ìì •ë³´KVì—ì„œ ìµœì‹ ê°’ ê³„ì‚°
            from .dialog_manager.config.config_loader import get_excel_sheets
            sheets = get_excel_sheets()
            df_userkv = self.excel_manager.load_sheet_data(user_name, sheets.get("user_info_kv", "ì‚¬ìš©ìì •ë³´KV"))
            if not df_userkv.empty:
                latest_map = {}
                try:
                    # ìµœê·¼ í–‰ì´ ê°€ì¥ ì•„ë˜ë¼ê³  ê°€ì •í•˜ê³  ì—­ìˆœìœ¼ë¡œ ìŠ¤ìº”í•˜ì—¬ ìµœì´ˆ ë§¤ì¹­ì„ ìµœì‹ ìœ¼ë¡œ ì‚¬ìš©
                    for _, row in df_userkv.iloc[::-1].iterrows():
                        key = str(row.get("í‚¤", "")).strip()
                        if not key:
                            continue
                        val = row.get("ê°’", "")
                        sval = str(val).strip()
                        if sval.lower() in ("nan", "none"):
                            continue
                        if key and key not in latest_map and sval != "":
                            latest_map[key] = sval
                    user_row = {
                        "ì´ë¦„": latest_map.get("ì´ë¦„", ""),
                        "ë‚˜ì´": latest_map.get("ë‚˜ì´", ""),
                        "í•™êµ": latest_map.get("í•™êµ", ""),
                        "ì§ì—…": latest_map.get("ì§ì—…", ""),
                        "ì·¨ë¯¸": latest_map.get("ì·¨ë¯¸", ""),
                        "ë‚ ì§œ": df_userkv.iloc[-1].get("ë‚ ì§œ", "")
                    }
                    sheets_data["ì‚¬ìš©ì"] = [user_row]
                    print(f"[DEBUG] ì‚¬ìš©ìì •ë³´(KV) ë¡œë”© ì™„ë£Œ: keys={list(k for k,v in latest_map.items() if v)}")
                except Exception as e:
                    print(f"[ERROR] ì‚¬ìš©ìì •ë³´KV ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ì„¸ì…˜ë³„ ì„ì‹œ ì €ì¥ì†Œì— ì €ì¥
            if not hasattr(self, 'excel_cache'):
                self.excel_cache = {}
            self.excel_cache[session_id] = sheets_data
            
            print(f"[DEBUG] ì—‘ì…€ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {user_name}")
            
        except Exception as e:
            print(f"[ERROR] ì—‘ì…€ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def get_excel_data(self, session_id: str, data_type: str):
        """ì—‘ì…€ì—ì„œ ë¡œë”©ëœ ë°ì´í„° ì¡°íšŒ"""
        if not hasattr(self, 'excel_cache'):
            return []
        
        session_data = self.excel_cache.get(session_id, {})
        return session_data.get(data_type, [])

    def handle_duplicate_answer(self, user_input: str, pending_data: dict) -> dict:
        """
        ì¤‘ë³µ ì—”í‹°í‹° ì¬ì§ˆë¬¸ì— ëŒ€í•œ ì‚¬ìš©ì ì‘ë‹µ ì²˜ë¦¬ (ì—‘ì…€ ì „ìš© ë‹¨ìˆœí™”)
        """
        text = (user_input or "").strip().lower()
        
        # ê¸ì • í‚¤ì›Œë“œ (ì €ì¥)
        positive = ["ì‘", "ì–´", "ê·¸ë˜", "ë§ì•„", "ë°”ê¿”", "ì—…ë°ì´íŠ¸", "ë®ì–´", "ìƒˆë¡œ", "ë‹¤ì‹œ", "ì €ì¥í•´", "ì¢‹ì•„", "ë„¤", "ì˜ˆ", "ì¶”ê°€", "í•¨ê»˜", "ê°™ì´", "ë‘˜ë‹¤", "ë˜", "ìƒˆë¡œìš´", "ë”", "ê·¸ë¦¬ê³ ", "ë˜í•œ"]
        # ë¶€ì • í‚¤ì›Œë“œ (ì·¨ì†Œ)
        negative = ["ì•„ë‹ˆ", "ì•„ëƒ", "ì•„ë‹Œ", "ê·¸ëƒ¥", "ë†”ë‘¬", "ìœ ì§€", "ê·¸ëŒ€ë¡œ", "ì•ˆë¼", "ì‹«ì–´", "ì•„ë‹ˆìš”", "ì•„ë‹ˆì•¼", "ì·¨ì†Œ"]
        
        # ë¶€ì • ì‘ë‹µ â†’ ì·¨ì†Œ
        if any(k in text for k in negative):
            return {
                "success": True,
                "duplicate": False,
                "message": "ì•Œê² ì–´ìš”. ì €ì¥í•˜ì§€ ì•Šì„ê²Œìš”."
            }
        
        # ê¸ì • ì‘ë‹µ â†’ ì—‘ì…€ì— ì €ì¥
        if any(k in text for k in positive):
            entity_type = pending_data.get("entity_type")
            new_data = pending_data.get("new_data", {})
            session_id = pending_data.get("session_id")
            
            try:
                user_name = self.user_names.get(session_id or "default")
                if user_name and user_name != "ì‚¬ìš©ì":
                    self.excel_manager.save_entity_data(user_name, entity_type, new_data)
                    
                    return {
                        "success": True,
                        "duplicate": False,
                        "message": f"ë„¤, '{pending_data.get('new', 'ì •ë³´')}'ë¥¼ ì €ì¥í–ˆì–´ìš”."
                    }
                else:
                    return {
                        "success": False,
                        "duplicate": False,
                        "message": "ì‚¬ìš©ì ì •ë³´ê°€ ì—†ì–´ì„œ ì €ì¥í•  ìˆ˜ ì—†ì–´ìš”."
                    }
            except Exception as e:
                print(f"[ERROR] ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
                return {
                    "success": False,
                    "duplicate": False,
                    "message": "ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
                }
        
        # ëª¨í˜¸í•œ ì‘ë‹µ â†’ ì¬ì§ˆë¬¸
        return {
            "success": False,
            "duplicate": True,
            "message": "ì €ì¥í• ê¹Œìš”, ì•„ë‹ˆë©´ ì·¨ì†Œí• ê¹Œìš”? (ì˜ˆ/ì•„ë‹ˆì˜¤)"
        }

    def _check_duplicate_entity(self, entity_type: str, new_data: dict, session_id: str = None) -> dict:
        """ì—‘ì…€ ê¸°ë°˜ ì¤‘ë³µ ì—”í‹°í‹° í™•ì¸."""
        try:
            user_name = self.user_names.get((session_id or "default_session"))
            if not user_name:
                return {"is_duplicate": False}

            # ì‚¬ìš©ì ì´ë¦„
            if entity_type == "ì‚¬ìš©ì" and new_data.get("ì´ë¦„"):
                from .dialog_manager.config.config_loader import get_excel_sheets
                sheets = get_excel_sheets()
                df_kv = self.excel_manager.load_sheet_data(user_name, sheets.get("user_info_kv", "ì‚¬ìš©ìì •ë³´KV"))
                if df_kv is not None and not df_kv.empty:
                    for _, row in df_kv.iloc[::-1].iterrows():
                        if str(row.get("í‚¤", "")).strip() == "ì´ë¦„":
                            existing = str(row.get("ê°’", "")).strip()
                            if existing:
                                if existing == str(new_data.get("ì´ë¦„")):
                                    return {"is_duplicate": True, "message": f"ì´ë¯¸ '{existing}'ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤."}
                                else:
                                    return {"is_duplicate": True, "message": f"ì´ë¯¸ '{existing}'ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆì–´ìš”. '{new_data.get('ì´ë¦„')}'ë¡œ ë°”ê¿€ê¹Œìš”?"}
                            break
                return {"is_duplicate": False}

            # ë¬¼ê±´
            if entity_type == "ë¬¼ê±´":
                df = self.excel_manager.load_sheet_data(user_name, "ë¬¼ê±´ìœ„ì¹˜")
                if df is not None and not df.empty:
                    new_name = new_data.get("ì´ë¦„") or new_data.get("ë¬¼ê±´ì´ë¦„")
                    new_loc = str(new_data.get("ìœ„ì¹˜", "")).strip()
                    for _, row in df.iterrows():
                        name_v = str(row.get("ë¬¼ê±´ì´ë¦„", "")).strip() or str(row.get("ì´ë¦„", "")).strip()
                        loc_v = str(row.get("ìœ„ì¹˜", "")).strip()
                        if name_v and name_v == new_name:
                            if loc_v == new_loc:
                                return {"is_duplicate": True, "message": f"ì´ë¯¸ '{name_v}'ì´(ê°€) '{loc_v}'ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤."}
                            else:
                                return {"is_duplicate": True, "message": f"'{name_v}'ì´(ê°€) ì´ë¯¸ '{loc_v}'ì— ì €ì¥ë˜ì–´ ìˆì–´ìš”. '{new_loc}'ë¡œ ë°”ê¿€ê¹Œìš”?"}
            return {"is_duplicate": False}
        except Exception as e:
            print(f"[ERROR] ì—‘ì…€ ê¸°ë°˜ ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {"is_duplicate": False}

    def _delete_existing_entity(self, entity_type: str, existing_value: str):
        """ì—‘ì…€ ê¸°ë°˜ ì—”í‹°í‹° ì‚­ì œ."""
        try:
            user_name = self.user_names.get("default_session")
            if not user_name:
                return
            if entity_type == "ë¬¼ê±´":
                df = self.excel_manager.load_sheet_data(user_name, "ë¬¼ê±´ìœ„ì¹˜")
                if df is not None and not df.empty:
                    # ì‚­ì œëœ ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥ (ê¸°ì¡´ í–‰ì„ ì œì™¸í•˜ê³  ìƒˆë¡œ ì €ì¥)
                    filtered_records = []
                    for _, row in df.iterrows():
                        if str(row.get("ë¬¼ê±´ì´ë¦„", "")) != str(existing_value):
                            filtered_records.append(row.to_dict())
                    # ë²„í¼ì— ì €ì¥ í›„ flush í•„ìš” (ì¦‰ì‹œ ë°˜ì˜)
                    if filtered_records:
                        for record in filtered_records:
                            self.excel_manager.save_entity_data(user_name, "ë¬¼ê±´", record)
                        # âœ… request_flush() ì‚¬ìš©í•˜ì—¬ ì§€ì—° ë³‘í•© ì²˜ë¦¬ (race condition ë°©ì§€)
                        self.excel_manager.request_flush(user_name)
        except Exception as e:
            print(f"[WARN] ì—‘ì…€ ì—”í‹°í‹° ì‚­ì œ ì‹¤íŒ¨: {e}")

    def _check_missing_fields(self, entity_type: str, data: dict) -> dict:
        """
        í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ëˆ„ë½ ì‹œ ì¬ì§ˆë¬¸ ë©”ì‹œì§€ ë°˜í™˜
        """
        required_fields = {
            "user.ì•½": ["ì•½ëª…"],  
            "user.ì‹ì‚¬": ["ë¼ë‹ˆ"],
            "user.ì¼ì •": ["ë‚ ì§œ", "ì‹œê°„", "ì œëª©"],
            "user.ì‚¬ìš©ì": ["ì´ë¦„"]
        }

        missing = []
        for field in required_fields.get(entity_type, []):
            if not data.get(field):
                missing.append(field)

        if missing:
            return {
                "has_missing": True,
                "message": f"{entity_type} ì—”í‹°í‹° ì €ì¥ì— í•„ìš”í•œ ì •ë³´({', '.join(missing)})ê°€ ë¹ ì¡ŒìŠµë‹ˆë‹¤. ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
                "missing_fields": missing
            }

        return {"has_missing": False}

    def _extract_medicine_entities(self, text: str) -> list:
        """
        ì•½ëª… + ìš©ëŸ‰ + ë‹¨ìœ„ ì¶”ì¶œ (ë‹¤ì¤‘ ì•½ë„ ì§€ì›)
        ì˜ˆ) "ì•„ìŠ¤í”¼ë¦° 2ì•Œ, ë¹„íƒ€ë¯¼ 1ì•Œ" â†’ [{"ì´ë¦„":"ì•„ìŠ¤í”¼ë¦°","ìš©ëŸ‰":"2","ë‹¨ìœ„":"ì•Œ"}, ...]
        ì˜ˆ) "ë‚˜ëŠ” ì•„ì¹¨ë§ˆë‹¤ ë¹„íƒ€ë¯¼ ë¨¹ì–´" â†’ [{"ì´ë¦„":"ë¹„íƒ€ë¯¼","ìš©ëŸ‰":"","ë‹¨ìœ„":""}]
        âœ… ê°œì„ : "~ì•½" íŒ¨í„´(ë¹„ì—¼ì•½, í˜ˆì••ì•½ ë“±)ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ
        """
        medicines = []
        
        
        med_match = re.search(r"([ê°€-í£A-Za-z]+ì•½)", text)
        if med_match:
            med_name = med_match.group(1)
            dose_match = re.search(rf"{re.escape(med_name)}.*?(\d+)\s*(ì•Œ|ì •|ìº¡ìŠ|í¬|mg|ml|ë³‘)(?:ì”©)?(?!\s*(?:ë¶„|ì‹œê°„|ì‹œ))", text)
            
            if dose_match:
                # âœ… ë§¤ì¹­ëœ ìˆ«ì ì•ì˜ í…ìŠ¤íŠ¸ í™•ì¸
                match_pos = dose_match.start()
                number_pos = text.find(dose_match.group(1), match_pos)
                before_number = text[:number_pos]
                
                # âœ… "ì‹í›„/ì‹ì „/ê³µë³µ + ìˆ«ì + ë¶„/ì‹œê°„" íŒ¨í„´ì´ ì•ì— ìˆìœ¼ë©´ ìš©ëŸ‰ì´ ì•„ë‹˜
                # ì˜ˆ: "ê·¼ìœ¡í†µì•½ ì‹í›„ 30ë¶„" â†’ "30"ì€ ìš©ëŸ‰ì´ ì•„ë‹˜
                if re.search(r"(ì‹í›„|ì‹ì „|ê³µë³µ|ì‹ì‚¬\s*(?:ì „|í›„))\s*\d+\s*(?:ë¶„|ì‹œê°„|ì‹œ)", before_number + dose_match.group(0)):
                    # "ì‹í›„ 30ë¶„" ê°™ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ìš©ëŸ‰ì´ ì•„ë‹˜
                    medicines.append({
                        "ì´ë¦„": med_name,
                        "ìš©ëŸ‰": "",
                        "ë‹¨ìœ„": ""
                    })
                else:
                    # ì‹¤ì œ ìš©ëŸ‰ì¸ ê²½ìš°
                    medicines.append({
                        "ì´ë¦„": med_name,
                        "ìš©ëŸ‰": dose_match.group(1).strip(),
                        "ë‹¨ìœ„": dose_match.group(2)
                    })
            else:
                # âœ… í•œê¸€ ìˆ«ì íŒ¨í„´: "í•œ ì•Œ", "ë‘ ì•Œ", "ì„¸ ì•Œ" ë“±
                # "ë²ˆ", "íšŒ"ëŠ” ë¹ˆë„ ë‹¨ìœ„ì´ë¯€ë¡œ ìš©ëŸ‰ ë‹¨ìœ„ê°€ ì•„ë‹˜
                korean_dose_match = re.search(rf"{re.escape(med_name)}.*?({'|'.join(KOREAN_NUMBERS_STR.keys())})\s*(ì•Œ|ì •|ìº¡ìŠ|í¬|ë³‘)?", text)
                if korean_dose_match:
                    korean_num = korean_dose_match.group(1)
                    unit = korean_dose_match.group(2) if korean_dose_match.group(2) else "ì•Œ"
                    medicines.append({
                        "ì´ë¦„": med_name,
                        "ìš©ëŸ‰": KOREAN_NUMBERS_STR.get(korean_num, "1"),
                        "ë‹¨ìœ„": unit
                    })
                else:
                    medicines.append({
                        "ì´ë¦„": med_name,
                        "ìš©ëŸ‰": "",
                        "ë‹¨ìœ„": ""
                    })
        else:
            # "ì•½ëª… + ì•½" íŒ¨í„´ (ë§ˆê·¸ë„¤ìŠ˜ ì•½, ì¹¼ìŠ˜ ì•½ ë“±) - ê³µë°± í¬í•¨
            med_match = re.search(r"([ê°€-í£A-Za-z]+)\s+ì•½", text)
            if med_match:
                med_name = med_match.group(1).strip()
                medicines.append({
                    "ì´ë¦„": med_name,
                    "ìš©ëŸ‰": "",
                    "ë‹¨ìœ„": ""
                })
            else:
                # âœ… ìš°ì„ ìˆœìœ„ 2: "ì•½ëª… + ìˆ«ì + ë‹¨ìœ„" íŒ¨í„´
                # âœ… "ë²ˆ", "íšŒ"ëŠ” ë¹ˆë„ ë‹¨ìœ„ì´ë¯€ë¡œ ìš©ëŸ‰ ë‹¨ìœ„ê°€ ì•„ë‹˜
                pattern = r"([ê°€-í£A-Za-z]+)\s*(\d+)\s*(ì•Œ|ì •|ìº¡ìŠ|í¬|mg|ml|ë³‘)?"
                matches = re.findall(pattern, text)

                for match in matches:
                    name, dose, unit = match
                    # ìˆ«ì ë‹¨ìœ„(í•˜ë£¨, ì‹í›„ ë“±)ê°€ ì•„ë‹Œ ì‹¤ì œ ì•½ëª…ì¸ì§€ í™•ì¸
                    if name not in ["í•˜ë£¨", "ì‹í›„", "ì‹ì „", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]:
                        medicines.append({
                            "ì´ë¦„": name.strip(),
                            "ìš©ëŸ‰": dose.strip(),
                            "ë‹¨ìœ„": unit if unit else "ì•Œ"   # ê¸°ë³¸ ë‹¨ìœ„
                        })
                
                if not medicines:
                    for pattern in COMMON_MED_PATTERNS:
                        med_match = re.search(pattern, text, re.IGNORECASE)
                        if med_match:
                            med_name = med_match.group(1).strip()
                            med_name = med_name.replace("ì„", "").replace("ë¥¼", "").strip()
                            medicines.append({
                                "ì´ë¦„": med_name,
                                "ìš©ëŸ‰": "",
                                "ë‹¨ìœ„": ""
                            })
                            break

        return medicines

    def _extract_meal_entity(self, text: str) -> dict:
        """
        ë¼ë‹ˆ/ë‚ ì§œ/ë©”ë‰´ ì¶”ì¶œ
        ì˜ˆ) "ì˜¤ëŠ˜ ì•„ì¹¨ì— ê¹€ì¹˜ì°Œê°œ ë¨¹ì—ˆì–´" â†’ {"ë‚ ì§œ":"2025-10-01","ë¼ë‹ˆ":"ì•„ì¹¨","ë©”ë‰´":["ê¹€ì¹˜ì°Œê°œ"]}
        """
        # import reëŠ” ì „ì—­ì—ì„œ ì´ë¯¸ importë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì œê±°
        from datetime import datetime, timedelta
        
        meal = {"ë‚ ì§œ": None, "ë¼ë‹ˆ": None, "ë©”ë‰´": []}

        
        try:
            has_med_keyword = any(keyword in text for keyword in MEDICINE_KEYWORDS)
            # "ì•½" í‚¤ì›Œë“œ ì²´í¬ (ë‹¨, "ì•½ì†"ì€ ì œì™¸ - ì•½ì†ì€ ì¼ì •)
            if not has_med_keyword and "ì•½" in text and "ì•½ì†" not in text:
                # "~ì•½" íŒ¨í„´ (í˜ˆì••ì•½, ê°ê¸°ì•½ ë“±) ë˜ëŠ” "ì•½ ë¨¹" íŒ¨í„´ ì²´í¬
                if re.search(r"[ê°€-í£A-Za-z]+ì•½|ì•½\s*[ë¨¹ë“œ]", text):
                    has_med_keyword = True
            # "~ì•½" íŒ¨í„´ ì²´í¬ (ì•ˆì „í•˜ê²Œ - ê¸¸ì´ ì œí•œ, "ì•½ì†" ì œì™¸)
            if not has_med_keyword and len(text) < 200:
                if re.search(r"[ê°€-í£A-Za-z]+ì•½(?!ì†)", text):
                    has_med_keyword = True
            if has_med_keyword:
                return meal  # ë¹ˆ ì‹ì‚¬ ì—”í‹°í‹° ë°˜í™˜
        except Exception as e:
            print(f"[WARN] ì•½ í‚¤ì›Œë“œ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # ë¼ë‹ˆ íŒ¨í„´
        for time_key, keywords in TIME_OF_DAY_KEYWORDS.items():
            if any(k in text for k in keywords):
                meal["ë¼ë‹ˆ"] = time_key
                break

        # ë‚ ì§œ ì¶”ì¶œ (ì˜ˆ: ì˜¤ëŠ˜/ë‚´ì¼/ì–´ì œ/ìš”ì¼)
        if "ì–´ì œ" in text:
            meal["ë‚ ì§œ"] = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        elif "ì˜¤ëŠ˜" in text:
            meal["ë‚ ì§œ"] = datetime.now().strftime("%Y-%m-%d")
        elif "ë‚´ì¼" in text:
            meal["ë‚ ì§œ"] = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
        elif "ëª¨ë ˆ" in text:
            meal["ë‚ ì§œ"] = (datetime.now() + timedelta(days=2)).strftime("%Y-%m-%d")
        # TODO: "ëª©ìš”ì¼" ê°™ì€ ìš”ì¼ íŒŒì‹±ë„ ì¶”ê°€ ê°€ëŠ¥

        # ìŒì‹ ì¶”ì¶œ (ë‹¨ìˆœíˆ "ë¨¹ì—ˆì–´/ë¨¹ìŒ" ì•ë’¤ ëª…ì‚¬ ì¶”ì¶œ)
        food_pattern = r"(?:\s|^)([ê°€-í£A-Za-z]+)\s*(ë¨¹ì—ˆ|ë¨¹ìŒ|ë¨¹ë‹¤|ë¨¹ì„)"
        matches = re.findall(food_pattern, text)
        if matches:
            meal["ë©”ë‰´"] = [m[0] for m in matches]

        return meal

    def extract_with_fallback(self, text: str, entity_type: str):
        """
        ê·œì¹™ ê¸°ë°˜ â†’ ì‹¤íŒ¨ ì‹œ LLM ë³´ì™„ ì¶”ì¶œ
        """
        if entity_type == "ì•½":
            meds = self._extract_medicine_entities(text)
            if meds:
                return meds
        elif entity_type == "ì‹ì‚¬":
            meal = self._extract_meal_entity(text)
            if meal.get("ë¼ë‹ˆ") or meal.get("ë©”ë‰´"):
                return meal

        # ê·œì¹™ ê¸°ë°˜ ì‹¤íŒ¨ â†’ LLM ì¶”ì¶œê¸°ë¡œ fallback
        try:
            # ê¸°ì¡´ LLM ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì—”í‹°í‹° ì¶”ì¶œ
            if hasattr(self, 'llm_chain') and self.llm_chain:
                result = self.llm_chain.invoke({"input": text, "entity_type": entity_type})
                return result
            else:
                print(f"[WARN] LLM ì²´ì¸ì´ ì—†ì–´ì„œ fallback ë¶ˆê°€: {entity_type}")
                return None
        except Exception as e:
            print(f"[WARN] LLM fallback ì‹¤íŒ¨: {e}")
            return None

    def _get_recent_conversation_summary(self, session_id: str) -> str:
        """SQLiteì—ì„œ ìµœê·¼ ëŒ€í™” ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            conn = sqlite3.connect(self.sqlite_path)
            c = conn.cursor()
            
            # ìµœê·¼ 3ê°œì˜ ëŒ€í™” ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸°
            c.execute("""
                SELECT summary FROM conversation_summary 
                WHERE session_id = ? 
                ORDER BY created_at DESC 
                LIMIT 3
            """, (session_id,))
            
            summaries = c.fetchall()
            conn.close()
            
            if summaries:
                # ìš”ì•½ë“¤ì„ ì‹œê°„ìˆœìœ¼ë¡œ ê²°í•©
                recent_summaries = [summary[0] for summary in reversed(summaries)]
                return "\n".join(recent_summaries)
            else:
                return ""
                
        except Exception as e:
            print(f"[ERROR] ëŒ€í™” ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return ""

    def _convert_conversation_history_to_string(self, conversation_history) -> str:
        """LCEL conversation_historyë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê¸¸ì´ ì œí•œ ì ìš©)"""
        if isinstance(conversation_history, str):
            # ë¬¸ìì—´ì¸ ê²½ìš° ê¸¸ì´ ì œí•œ (ìµœëŒ€ 2000ì)
            if len(conversation_history) > 2000:
                return conversation_history[-2000:] + "..."
            return conversation_history
        elif isinstance(conversation_history, list):
            # ë©”ì‹œì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜ (ìµœëŒ€ 10ê°œ ë©”ì‹œì§€)
            history_text = ""
            recent_messages = conversation_history[-10:]  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
            for msg in recent_messages:
                if hasattr(msg, 'content'):
                    history_text += f"{msg.content}\n"
                else:
                    history_text += f"{str(msg)}\n"
            
            # ì „ì²´ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 2000ì)
            if len(history_text) > 2000:
                return history_text[-2000:] + "..."
            return history_text.strip()
        else:
            return str(conversation_history) if conversation_history else ""

    def _get_current_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().isoformat()

# _get_similar_cached_result í•¨ìˆ˜ ì œê±°ë¨ - _get_cached_classificationìœ¼ë¡œ í†µí•©

# _update_classification_cache í•¨ìˆ˜ ì œê±°ë¨ - _add_to_cacheë¡œ í†µí•©

    def save_entity_to_vectorstore(self, entity_type: str, data: dict, session_id: str = None) -> dict:
        """
        ì—”í‹°í‹°ë¥¼ VectorStoreì™€ SQLiteì— ì €ì¥ (ì¤‘ë³µ ê²€ì¦ í¬í•¨)
        - ì¤‘ë³µì´ ìˆìœ¼ë©´ ì €ì¥í•˜ì§€ ì•Šê³ , ì¬ì§ˆë¬¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜
        - ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ë©´ {"success": True, "message": "..."} ë°˜í™˜
        """
        import json
        from datetime import datetime
        
        try:
            # ---------- 1. ì¤‘ë³µ ì²´í¬ ----------
            print(f"[DEBUG] ì¤‘ë³µ í™•ì¸ ì‹œì‘: entity_type={entity_type}, data={data}")
            duplicate_info = self._check_duplicate_entity(entity_type, data, session_id)
            print(f"[DEBUG] ì¤‘ë³µ í™•ì¸ ê²°ê³¼: {duplicate_info}")

            if duplicate_info.get("is_duplicate"):
                # ì¤‘ë³µì´ ìˆìœ¼ë©´ ì €ì¥ ì¤‘ë‹¨ â†’ ìƒìœ„ ì²´ì¸ì—ì„œ ì¬ì§ˆë¬¸ ë°œí™”
                return {
                    "success": False,
                    "duplicate": True,
                    "existing": duplicate_info.get("existing"),
                    "new": duplicate_info.get("new"),
                    "message": duplicate_info.get("message"),
                    "pending_data": {
                        "entity_type": entity_type,
                        "new_data": data,
                        "existing": duplicate_info.get("existing"),
                        "new": duplicate_info.get("new"),
                        "session_id": session_id
                    }
                }

            # ---------- 2. ì‹¤ì œ ì €ì¥ ----------
            # í†µì¼ëœ í¬ë§·ìœ¼ë¡œ ë³€í™˜
            if entity_type == "ë¬¼ê±´":
                doc = {
                    "type": "ë¬¼ê±´",
                    "ì´ë¦„": data.get("ì´ë¦„"),
                    "ìœ„ì¹˜": data.get("ìœ„ì¹˜"),
                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                    "session_id": session_id or "default",
                    "timestamp": datetime.now().isoformat()
                }
            elif entity_type == "ê°ì •" or entity_type == "ì •ì„œ":
                doc = {
                    "type": "ì •ì„œ",
                    "ê°ì •": data.get("ìƒíƒœ") or data.get("ê°ì •") or data.get("ì¦ìƒ"),
                    "ê°•ë„": data.get("ê°•ë„") or data.get("ì •ë„", "ë³´í†µ"),
                    "ë‚ ì§œ": data.get("ë‚ ì§œ", datetime.now().strftime("%Y-%m-%d")),
                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                    "session_id": session_id or "default",
                    "timestamp": datetime.now().isoformat()
                }
            elif entity_type == "ì‚¬ìš©ì":
                doc = {
                    "type": "ì‚¬ìš©ì",
                    "ì´ë¦„": data.get("ì´ë¦„"),
                    "í™•ì¸ë¨": data.get("í™•ì¸ë¨", True),
                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                    "session_id": session_id or "default",
                    "timestamp": datetime.now().isoformat()
                }
            elif entity_type == "ì¼ì •":
                doc = {
                    "type": "ì¼ì •",
                    "ì œëª©": data.get("ì œëª©"),
                    "ë‚ ì§œ": data.get("ë‚ ì§œ"),
                    "ì‹œê°„": data.get("ì‹œê°„"),
                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                    "session_id": session_id or "default",
                    "timestamp": datetime.now().isoformat()
                }
            else:
                doc = {
                    "type": entity_type,
                    **data,
                    "ì¶œì²˜": "ì‚¬ìš©ì ë°œí™”",
                    "session_id": session_id or "default",
                    "timestamp": datetime.now().isoformat()
                }
            
            # ì—‘ì…€ íŒŒì¼ì—ë§Œ ì €ì¥ (VectorStore/SQLite ì œê±°)
            try:
                user_name = self.user_names.get(session_id or "default")
                
                # ì‚¬ìš©ì ì´ë¦„ ìœ íš¨ì„± ê²€ì¦
                if user_name and user_name != "ì‚¬ìš©ì" and len(user_name.strip()) > 0:
                    # ì €ì¥ ì „ ì¶”ê°€ ê²€ì¦
                    import re
                    if not re.match(r'^[ê°€-í£A-Za-z0-9\s]+$', user_name) or len(user_name) > 20:
                        print(f"[WARNING] ìœ íš¨í•˜ì§€ ì•Šì€ ì‚¬ìš©ì ì´ë¦„: {user_name}")
                        user_name = None
                
                if user_name and user_name != "ì‚¬ìš©ì":
                    # ë²„í¼ë§ ì €ì¥ (ì¦‰ì‹œ ì €ì¥í•˜ì§€ ì•ŠìŒ)
                    self.excel_manager.save_entity_data(user_name, entity_type, data)
                    print(f"[DEBUG] ì—”í‹°í‹° ë²„í¼ë§ ì™„ë£Œ: {user_name} - {entity_type}")
                else:
                    print(f"[WARNING] ì‚¬ìš©ì ì´ë¦„ ì—†ìŒ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ - ì—”í‹°í‹° ì €ì¥ ê±´ë„ˆëœ€")
            except Exception as excel_error:
                print(f"[WARNING] ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {excel_error}")
                
                return {
                    "success": True,
                    "duplicate": False,
                    "message": f"{entity_type} ì—”í‹°í‹°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
                }
            except Exception as e:
                print(f"[ERROR] save_entity_to_vectorstore ì‹¤íŒ¨: {e}")
                return {
                    "success": False,
                    "duplicate": False,
                    "message": "ì—”í‹°í‹° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
                }
        except Exception as e:
            print(f"[ERROR] save_entity_to_vectorstore ì „ì²´ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "duplicate": False,
                "message": "ì—”í‹°í‹° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
            }

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ (SQLChatMessageHistory ì‚¬ìš©)
    def _history(self, session_id: str) -> SQLChatMessageHistory:
        # Deprecation warning ë°©ì§€ë¥¼ ìœ„í•´ connection ì‚¬ìš©
        engine = create_engine(f"sqlite:///{self.sqlite_path}")
        
        self._ensure_message_table_exists(engine)
        
        return SQLChatMessageHistory(
            session_id=session_id,
            connection=engine
        )
    
    def _ensure_message_table_exists(self, engine):
        """message_store í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë³´ì¥"""
        with engine.connect() as conn:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS message_store (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    role TEXT,
                    content TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """))
            conn.commit()

    # ìµœê·¼ ìš”ì•½ ê°€ì ¸ì˜¤ê¸° (1ê°œë§Œ)
    def _get_recent_summaries(self, session_id: str, limit: int = 3) -> List[str]:
        """ìµœê·¼ nê°œì˜ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°"""
        conn = sqlite3.connect(self.sqlite_path)
        c = conn.cursor()
        c.execute(
            "SELECT summary FROM conversation_summary "
            "WHERE session_id=? ORDER BY updated_at DESC LIMIT ?",
            (session_id, limit),
        )
        rows = c.fetchall()
        conn.close()
        return [row[0] for row in rows] if rows else []

    # ì•ˆì „í•œ JSON íŒŒì‹±
    def _safe_parse_json(self, text: Any) -> Dict[str, Any]:
        if isinstance(text, dict):
            return text
        if text is None:
            return {}
        s = str(text).strip()
        try:
            return json.loads(s)
        except Exception:
            pass
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                return json.loads(s[start:end + 1])
            except Exception:
                return {}
        return {}

    # ë‚ ì§œ/ì‹œê°„ ì •ê·œí™” (ì¶”ì¸¡ ê¸ˆì§€ â†’ ì‹œê°„ None ì²˜ë¦¬)
    def _normalize_datetime(self, text: str) -> Dict[str, Optional[str]]:
        if not text:
            return {"ë‚ ì§œ": None, "ì‹œê°„": None, "ì‹ì „í›„": None}

        t = re.sub(r"(ì¯¤|ê²½|ì•½)", "", str(text).strip())
        rel_date = None

        if "ê·¸ì œ" in t:
            rel_date = (datetime.now() - timedelta(days=2))
        elif "ì–´ì œ" in t:
            rel_date = (datetime.now() - timedelta(days=1))
        elif "ë‚´ì¼" in t:
            rel_date = (datetime.now() + timedelta(days=1))
        elif "ëª¨ë ˆ" in t:
            rel_date = (datetime.now() + timedelta(days=2))
        elif "ì˜¤ëŠ˜" in t:
            rel_date = datetime.now()

        # ì˜¤ì „/ì˜¤í›„ ì‹œê° (ìˆ«ìë¡œ ëª…ì‹œëœ ê²½ìš°ë§Œ)
        m = re.search(r"(ì˜¤ì „|ì˜¤í›„|ì €ë…|ë°¤)?\s*(\d{1,2})\s*ì‹œ(?:\s*(ë°˜|(\d{1,2})\s*ë¶„))?", t)
        if m:
            part = m.group(1)
            hour = int(m.group(2))
            mm = 30 if (m.group(3) == "ë°˜") else (int(m.group(4)) if m.group(4) else 0)

            if part in ("ì˜¤í›„", "ì €ë…") and hour < 12:
                hour += 12
            elif part == "ë°¤" and hour < 12:
                hour += 12
            elif part == "ì˜¤ì „" and hour == 12:
                hour = 0

            return {
                "ë‚ ì§œ": (rel_date or datetime.now()).strftime("%Y-%m-%d"),
                "ì‹œê°„": f"{hour:02d}:{mm:02d}:00",
                "ì‹ì „í›„": None
            }

        return {
            "ë‚ ì§œ": rel_date.strftime("%Y-%m-%d") if rel_date else None,
            "ì‹œê°„": None,
            "ì‹ì „í›„": None
        }

    # ì—”í‹°í‹° ì¶”ì¶œ LLM ì²´ì¸
    def _build_entity_chain(self) -> Runnable:
        parser = JsonOutputParser()
        fmt = parser.get_format_instructions()
        prompt = ChatPromptTemplate.from_template(
            (
                "ë‹¹ì‹ ì€ ì—”í‹°í‹° ì¶”ì¶œê¸°ì…ë‹ˆë‹¤.\n"
                "ì•„ë˜ 'ì‚¬ìš©ì ë°œí™”'ì—ì„œ ì–¸ê¸‰ëœ ì‚¬ì‹¤ë§Œì„ ë‹¨ì¼ JSON ê°ì²´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
                "**ì—”í‹°í‹° ì¶”ì¶œê¸° ì—­í• :**\n"
                "1. ê°€ëŠ¥í•œ í•œ ì—”í‹°í‹° JSONìœ¼ë¡œ ì™„ì„±í•´ë¼.\n"
                "2. ë§Œì•½ í•„ìˆ˜ ì •ë³´ê°€ ë¹ ì¡Œê±°ë‚˜ ì• ë§¤í•˜ë©´, JSON ëŒ€ì‹  'ì§ˆë¬¸' í‚¤ë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©ìì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ì„ ìƒì„±í•´ë¼.\n\n"
                "ì¤‘ìš” ê·œì¹™:\n"
                "1) ë°œí™”ì— ì§ì ‘ ë“±ì¥í•˜ì§€ ì•Šì€ ë‚ ì§œ/ì‹œê°„/ì¥ì†Œ/ì´ë¦„/ìˆ˜ì¹˜ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ìƒëµí•˜ê±°ë‚˜ nullë¡œ ë‘¡ë‹ˆë‹¤.\n"
                "2) ì—”í‹°í‹° í‚¤ëŠ” ì•„ë˜ í—ˆìš© ì—”í‹°í‹° ì¤‘ì—ì„œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
                "3) JSON ì™¸ í…ìŠ¤íŠ¸ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ {{}} ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
                "4) í•„ìˆ˜ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°: {{\"ì§ˆë¬¸\": \"êµ¬ì²´ì ì¸ ì§ˆë¬¸ ë‚´ìš©\"}} í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n"
                "5) ì•½ ë³µìš© ì •ë³´(ë³µìš© íšŸìˆ˜, ì‹œê°„, ë°©ë²•)ëŠ” ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ê²½ìš°ì—ë§Œ ì¶”ì¶œí•˜ê³ , ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”!\n"
                "6) 'í˜ˆì••ì•½ì´ë‘ ë¹„ì—¼ì•½ì„ ë°›ì•„ì™”ì–´' â†’ ë³µìš© ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ë³µìš© í•„ë“œë¥¼ ìƒëµí•˜ì„¸ìš”!\n\n"
                "í—ˆìš© ì—”í‹°í‹° ìœ í˜•: [\"ì‚¬ìš©ì\",\"ì•½\",\"ì‹ì‚¬\",\"ê°€ì¡±\",\"ë¬¼ê±´\",\"ì¼ì •\",\"ê¸°ë…ì¼\",\"ì·¨ë¯¸\",\"ì·¨í–¥\",\"ê±´ê°•ìƒíƒœ\"]\n"
                "**ìƒˆë¡œìš´ ê´€ê³„ë‚˜ ì—”í‹°í‹° íƒ€ì…ì´ í•„ìš”í•˜ë©´ ììœ ë¡­ê²Œ ìƒì„±í•˜ì„¸ìš”!**\n"
                "- ì˜ˆ: \"ë‚¨ìì¹œêµ¬\", \"ì—¬ìì¹œêµ¬\", \"ë™ë£Œ\", \"ì„ ìƒë‹˜\", \"ì¹œêµ¬\", \"ì´ì›ƒ\" ë“±\n"
                "- ìƒˆë¡œìš´ ê´€ê³„ ì—”í‹°í‹°ëŠ” ê´€ê³„ì™€ ì´ë¦„ í•„ë“œë¥¼ í¬í•¨í•˜ì—¬ ì €ì¥\n"
                "- ê¸°ì¡´ ê°€ì¡± ì—”í‹°í‹°ëŠ” ê´€ê³„ì™€ ì´ë¦„ í•„ë“œë¥¼ í¬í•¨í•˜ì—¬ ì €ì¥\n\n"
                "**ì—”í‹°í‹° íƒ€ì… ìƒì„± ê·œì¹™ (ì¤‘ìš”!):**\n"
                "- \"ë‚¨ìì¹œêµ¬\", \"ì—¬ìì¹œêµ¬\" â†’ user.ë‚¨ìì¹œêµ¬, user.ì—¬ìì¹œêµ¬\n"
                "- \"ì´ëª¨\", \"ê³ ëª¨\", \"ì‚¼ì´Œ\", \"ì™¸ì‚¼ì´Œ\" â†’ user.ê°€ì¡±\n"
                "- \"ë™ë£Œ\", \"ì„ ìƒë‹˜\", \"ì¹œêµ¬\" â†’ user.ë™ë£Œ, user.ì„ ìƒë‹˜, user.ì¹œêµ¬\n"
                "- **ì ˆëŒ€ user.user.xxx í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ**\n"
                "- **ì˜¬ë°”ë¥¸ í˜•ì‹: user.ë‚¨ìì¹œêµ¬, user.ê°€ì¡±, user.ë™ë£Œ**\n"
                "- **ì˜ëª»ëœ í˜•ì‹: user.user.ë‚¨ìì¹œêµ¬, user.user.ê°€ì¡±, user.user.ë™ë£Œ**\n\n"
                "**ì˜ˆì‹œ:**\n"
                "- \"ë‚´ ë‚¨ìì¹œêµ¬ ì´ë¦„ì€ ì•ˆê±´í˜¸ì•¼\" â†’ user.ë‚¨ìì¹œêµ¬ ì—”í‹°í‹°ë¡œ ìƒì„±\n"
                "- \"ìš°ë¦¬ ì´ëª¨ ì´ë¦„ì€ ì†¡í˜œêµì•¼\" â†’ user.ê°€ì¡± ì—”í‹°í‹°ë¡œ ìƒì„±\n"
                "- \"ìš°ë¦¬ ë™ë£Œ ê¹€ì² ìˆ˜ì•¼\" â†’ user.ë™ë£Œ ì—”í‹°í‹°ë¡œ ìƒì„±\n\n"
                "ì¤‘ìš”: ì•½ê³¼ ì‹ì‚¬ë¥¼ êµ¬ë¶„í•˜ì„¸ìš”!\n"
                "- ì•½: í˜ˆì••ì•½, ë¹„ì—¼ì•½, ê°ê¸°ì•½, ì•„ìŠ¤í”¼ë¦°, íƒ€ì´ë ˆë†€, ìœ ì‚°ê· , ìœ ì‚°ê· ì œ, í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤ ë“± ì˜ì•½í’ˆ ë³µìš©\n"
                "- ì‹ì‚¬: í–„ë²„ê±°, ê¹€ì¹˜ì°Œê°œ, ë¶ˆê³ ê¸°, ë¼ë©´, ë°¥, ë¹µ, ê³¼ì¼ ë“± ìŒì‹ ì„­ì·¨\n"
                "- 'ì•½ ë¨¹ì—ˆì–´', 'í˜ˆì••ì•½ ë¨¹ì—ˆì–´', 'ë¹„ì—¼ì•½ ë¨¹ì—ˆì–´' ë“±ì€ ì•½ ë³µìš©ì´ì§€ ì‹ì‚¬ê°€ ì•„ë‹™ë‹ˆë‹¤!\n"
                "- ì•½ëª…(ì•½ìœ¼ë¡œ ëë‚˜ëŠ” ë‹¨ì–´)ì´ í¬í•¨ëœ ë¬¸ì¥ì€ ë¬´ì¡°ê±´ ì•½ ì—”í‹°í‹°ë¡œë§Œ ì¶”ì¶œí•˜ì„¸ìš”!\n"
                "- ì•½ì„ ì‹ì‚¬ë¡œ ì°©ê°í•˜ì§€ ë§ˆì„¸ìš”! ì•½ì€ ì•½ ì—”í‹°í‹°ë¡œë§Œ ì²˜ë¦¬í•˜ì„¸ìš”!\n"
                "- 'ë‚˜ëŠ” í˜ˆì••ì•½ì„ ë¨¹ì–´' â†’ user.ì•½ ì—”í‹°í‹° (ì ˆëŒ€ user.ì‹ì‚¬ ì•„ë‹˜!)\n"
                "- 'ë‚˜ëŠ” í–„ë²„ê±°ë¥¼ ë¨¹ì—ˆì–´' â†’ user.ì‹ì‚¬ ì—”í‹°í‹°\n\n"
                "**ì•½ëª… ì¶”ì¶œ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**\n"
                "- ì•½ëª…ì€ ë°œí™”ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì•½ì˜ ì´ë¦„ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”!\n"
                "- 'ìœ ì‚°ê· ì„ ë¨¹ì–´ì•¼í•´' â†’ ì•½ëª…: 'ìœ ì‚°ê· ' (ì ˆëŒ€ 'ì¼ì–´ë‚˜ìë§ˆì', 'ì•„ì¹¨' ë“±ì´ ì•½ëª…ì´ ì•„ë‹˜!)\n"
                "- 'í˜ˆì••ì•½ì„ ë¨¹ì—ˆì–´' â†’ ì•½ëª…: 'í˜ˆì••ì•½'\n"
                "- 'ë¹„ì—¼ì•½ì„ ë³µìš©í–ˆì–´' â†’ ì•½ëª…: 'ë¹„ì—¼ì•½'\n"
                "- 'ë¶ˆë©´ì¦ì•½ì„ ë¨¹ì–´ì•¼í•´' â†’ ì•½ëª…: 'ë¶ˆë©´ì¦ì•½'\n"
                "- **ì ˆëŒ€ ê¸ˆì§€**: ì‹œê°„ í‘œí˜„('ì•„ì¹¨', 'ì¼ì–´ë‚˜ìë§ˆì', 'ê¸°ìƒ'), ë³µìš© ë°©ë²•('ê³µë³µ', 'ì‹í›„'), ë³µìš© íšŸìˆ˜('í•˜ë£¨ 3ë²ˆ') ë“±ì„ ì•½ëª…ìœ¼ë¡œ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”!\n"
                "- **ì ˆëŒ€ ê¸ˆì§€**: 'ì¼ì–´ë‚˜ìë§ˆì'ëŠ” ì•½ëª…ì´ ì•„ë‹ˆë¼ ë³µìš© ì‹œê°„ í‘œí˜„ì…ë‹ˆë‹¤! ì‹¤ì œ ì•½ëª…ì„ ì°¾ì•„ì£¼ì„¸ìš”!\n\n"
                "**ì•½ ë³µìš© ì‹œê°„ ì¶”ì¶œ ê·œì¹™ (ì¤‘ìš”!):**\n"
                "- 'ì•„ì¹¨ì—', 'ì•„ì¹¨ìœ¼ë¡œ', 'ê¸°ìƒ ì‹œ', 'ì¼ì–´ë‚˜ìë§ˆì', 'ì¼ì–´ë‚˜ì ë§ˆì', 'ê¸°ìƒ í›„' â†’ ì‹œê°„ëŒ€: 'ì•„ì¹¨' ë˜ëŠ” ë³µìš©: [{{\"ì›ë¬¸\": \"ì•„ì¹¨\"}}]\n"
                "- 'ì ì‹¬ì—', 'ì ì‹¬ìœ¼ë¡œ' â†’ ì‹œê°„ëŒ€: 'ì ì‹¬' ë˜ëŠ” ë³µìš©: [{{\"ì›ë¬¸\": \"ì ì‹¬\"}}]\n"
                "- 'ì €ë…ì—', 'ì €ë…ìœ¼ë¡œ' â†’ ì‹œê°„ëŒ€: 'ì €ë…' ë˜ëŠ” ë³µìš©: [{{\"ì›ë¬¸\": \"ì €ë…\"}}]\n"
                "- 'ê³µë³µì—', 'ì‹ì „ì—' â†’ ë³µìš©ë°©ë²•: 'ê³µë³µ' ë˜ëŠ” 'ì‹ì „'\n"
                "- 'ì‹í›„ì—', 'ì‹í›„ 30ë¶„' â†’ ë³µìš©ë°©ë²•: 'ì‹í›„ 30ë¶„' (ì •í™•í•œ ì‹œê°„ì´ ìˆìœ¼ë©´ í¬í•¨)\n"
                "- 'í•˜ë£¨ 3ë²ˆ' â†’ ë³µìš©: [{{\"ì›ë¬¸\": \"í•˜ë£¨ 3ë²ˆ\"}}] (ì‹œê°„ëŒ€ëŠ” ìƒëµ ê°€ëŠ¥)\n"
                "- **ì˜ˆì‹œ**: 'ìœ ì‚°ê· ì„ ì•„ì¹¨ì— ì¼ì–´ë‚˜ìë§ˆì 1ì•Œ ê³µë³µì— ë¨¹ì–´ì•¼í•´' â†’ ì•½ëª…: 'ìœ ì‚°ê· ', ìš©ëŸ‰: '1', ë‹¨ìœ„: 'ì•Œ', ì‹œê°„ëŒ€: 'ì•„ì¹¨', ë³µìš©ë°©ë²•: 'ê³µë³µ'\n\n"
                "ì‹ì‚¬ ë¼ë‹ˆ ì¶”ì¶œ ê·œì¹™ (ì¤‘ìš”!):\n"
                "- 'ì•„ì¹¨ì—', 'ì•„ì¹¨ìœ¼ë¡œ' â†’ ë¼ë‹ˆ: 'ì•„ì¹¨'\n"
                "- 'ì ì‹¬ì—', 'ì ì‹¬ìœ¼ë¡œ' â†’ ë¼ë‹ˆ: 'ì ì‹¬'\n"
                "- 'ì €ë…ì—', 'ì €ë…ìœ¼ë¡œ' â†’ ë¼ë‹ˆ: 'ì €ë…'\n"
                "- ì‹œê°„ìœ¼ë¡œ ë¼ë‹ˆ ì¶”ë¡ : 6-11ì‹œ â†’ ì•„ì¹¨, 11-15ì‹œ â†’ ì ì‹¬, 15-22ì‹œ â†’ ì €ë…\n"
                "- ëª…ì‹œì ìœ¼ë¡œ ë¼ë‹ˆê°€ ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ ë¼ë‹ˆ í•„ë“œë¥¼ nullë¡œ ë‘ì„¸ìš”!\n"
                "- 'ì•„ì¹¨ì— ë°¥ ë¨¹ì—ˆì–´' â†’ ë¼ë‹ˆ: 'ì•„ì¹¨' (ì ˆëŒ€ 'ì €ë…'ì´ ì•„ë‹˜!)\n\n"
                "**ì‚¬ìš©ì ì´ë¦„ ë° ë³„ëª… ì¶”ì¶œ ê·œì¹™ (ì¤‘ìš”!):**\n"
                "- 'ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼' â†’ {{\"user.ì‚¬ìš©ì\": [{{\"ì´ë¦„\": \"í™ê¸¸ë™\"}}]}}\n"
                "- 'ë‚´ ë³„ëª…ì€ ì‚¬ìœ ë¦¬ì•¼' â†’ {{\"user.ì‚¬ìš©ì\": [{{\"ë³„ëª…\": \"ì‚¬ìœ ë¦¬\"}}]}}\n"
                "- 'ë‚´ ë³„ëª…ì€ ì‚¬ìœ ë¦¬ë¼ê³  í•´' â†’ {{\"user.ì‚¬ìš©ì\": [{{\"ë³„ëª…\": \"ì‚¬ìœ ë¦¬\"}}]}}\n"
                "- 'í¸í•˜ê²Œ ì„œì—°ì´ë¼ê³  ë¶ˆëŸ¬' â†’ {{\"user.ì‚¬ìš©ì\": [{{\"ë³„ëª…\": \"ì„œì—°\"}}]}}\n"
                "- 'ë‚˜ëŠ” í™ê¸¸ë™ì´ê³ , í¸í•˜ê²Œ ê¸¸ë™ì´ë¼ê³  ë¶ˆëŸ¬ë„ ë¼' â†’ {{\"user.ì‚¬ìš©ì\": [{{\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ë³„ëª…\": \"ê¸¸ë™\"}}]}}\n"
                "- ë³„ëª…ì€ 'ë³„ëª…', 'ë³„ì¹­', 'alias' ì¤‘ í•˜ë‚˜ì˜ í‚¤ë¡œ ì €ì¥ ê°€ëŠ¥\n"
                "- 'ë‚´ ë³„ëª…ì€', 'ë³„ëª…ì€', 'ë³„ì¹­ì€', 'í¸í•˜ê²Œ ~ë¼ê³  ë¶ˆëŸ¬' ë“±ì˜ íŒ¨í„´ì„ ëª¨ë‘ ì¸ì‹í•´ì•¼ í•¨\n\n"
                "í•„ë“œ ì˜ˆì‹œ:\n"
                "- ì‚¬ìš©ì: {{\"ì´ë¦„\": \"í™ê¸¸ë™\"}} ë˜ëŠ” {{\"ë³„ëª…\": \"ì‚¬ìœ ë¦¬\"}} ë˜ëŠ” {{\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ë³„ëª…\": \"ê¸¸ë™\"}}\n"
                "- ì¼ì •: {{\"ì œëª©\": \"ë³‘ì› ì˜ˆì•½\", \"ë‚ ì§œ\": \"ë‚´ì¼\", \"ì‹œê°„\": \"ì˜¤í›„ 3ì‹œ\", \"ì¥ì†Œ\": null}}\n"
                "- ì•½: {{\"ì•½ëª…\": \"í˜ˆì••ì•½\", \"ë³µìš©\": [{{\"ì›ë¬¸\": \"í•˜ë£¨ ë‘ ë²ˆ\"}}], \"ë³µìš© ê¸°ê°„\": \"ì¼ì£¼ì¼ì¹˜\"}} (ë³µìš© ì •ë³´ëŠ” ì‹¤ì œ ì–¸ê¸‰ëœ ê²½ìš°ë§Œ!)\n"
                "- ì•½ (ë³µìš© ì •ë³´ ì—†ìŒ): {{\"ì•½ëª…\": \"í˜ˆì••ì•½\"}} (ë³µìš© ì •ë³´ê°€ ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ ìƒëµ!)\n"
                "- ì‹ì‚¬: {{\"ë¼ë‹ˆ\": \"ì ì‹¬\", \"ë©”ë‰´\": [\"í–„ë²„ê±°\"], \"ë‚ ì§œ\": \"ì˜¤ëŠ˜\", \"ì‹œê°„\": \"12:30\"}}\n"
                "- ê¸°ë…ì¼: {{\"ê´€ê³„\": \"ì‚¬ìš©ì\", \"ì œëª©\": \"ìƒì¼\", \"ë‚ ì§œ\": \"4ì›” 7ì¼\"}}\n"
                "- ê±´ê°•ìƒíƒœ: {{\"ì¦ìƒ\": \"ë‘í†µ\", \"ì •ë„\": \"ì‹¬í•¨\", \"ê¸°ê°„\": \"3ì¼\", \"ì§ˆë³‘\": \"ë‹¹ë‡¨\"}}\n"
                "- ë¬¼ê±´: {{\"ì´ë¦„\": \"ì—´ì‡ \", \"ìœ„ì¹˜\": \"ê±°ì‹¤ ì±…ìƒ ìœ„ì—\", \"ì¥ì†Œ\": \"ê±°ì‹¤ ì±…ìƒ\", \"ì„¸ë¶€ìœ„ì¹˜\": \"ìœ„ì—\"}}\n"
                "- ë¬¼ê±´: {{\"ì´ë¦„\": \"ì•ˆì•½\", \"ìœ„ì¹˜\": \"ë‚´ë°© ì•ˆì—\", \"ì¥ì†Œ\": \"ë‚´ë°©\", \"ì„¸ë¶€ìœ„ì¹˜\": \"ì•ˆì—\"}}\n"
                "- ë¬¼ê±´: {{\"ì´ë¦„\": \"ì§€ê°‘\", \"ìœ„ì¹˜\": \"ì¹¨ì‹¤ ì˜†ì—\", \"ì¥ì†Œ\": \"ì¹¨ì‹¤\", \"ì„¸ë¶€ìœ„ì¹˜\": \"ì˜†ì—\"}}\n"
                "- ë¬¼ê±´ (ìœ„ì¹˜ë§Œ): {{\"ì´ë¦„\": \"íœ\", \"ìœ„ì¹˜\": \"ì±…ìƒ\", \"ì¥ì†Œ\": \"ì±…ìƒ\", \"ì„¸ë¶€ìœ„ì¹˜\": \"\"}}\n\n"
                "**ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ ê·œì¹™ (ì¤‘ìš”!):**\n"
                "- 'ì•ˆì•½ì€ ë‚´ë°© ì•ˆì— ìˆì–´' â†’ {{\"user.ë¬¼ê±´\": [{{\"ì´ë¦„\": \"ì•ˆì•½\", \"ìœ„ì¹˜\": \"ë‚´ë°© ì•ˆì—\", \"ì¥ì†Œ\": \"ë‚´ë°©\", \"ì„¸ë¶€ìœ„ì¹˜\": \"ì•ˆì—\"}}]}}\n"
                "- 'ì—´ì‡ ëŠ” ê±°ì‹¤ ì±…ìƒ ìœ„ì— ìˆì–´' â†’ {{\"user.ë¬¼ê±´\": [{{\"ì´ë¦„\": \"ì—´ì‡ \", \"ìœ„ì¹˜\": \"ê±°ì‹¤ ì±…ìƒ ìœ„ì—\", \"ì¥ì†Œ\": \"ê±°ì‹¤ ì±…ìƒ\", \"ì„¸ë¶€ìœ„ì¹˜\": \"ìœ„ì—\"}}]}}\n"
                "- 'ì§€ê°‘ì€ ì¹¨ì‹¤ì— ìˆì–´' â†’ {{\"user.ë¬¼ê±´\": [{{\"ì´ë¦„\": \"ì§€ê°‘\", \"ìœ„ì¹˜\": \"ì¹¨ì‹¤\", \"ì¥ì†Œ\": \"ì¹¨ì‹¤\", \"ì„¸ë¶€ìœ„ì¹˜\": \"\"}}]}}\n"
                "- ìœ„ì¹˜ í‘œí˜„ì—ì„œ \"ìœ„ì—\", \"ì•ˆì—\", \"ì˜†ì—\", \"ì•ì—\", \"ë’¤ì—\", \"ì•„ë˜ì—\" ê°™ì€ ë°©í–¥ í‘œí˜„ì€ ë°˜ë“œì‹œ \"ì„¸ë¶€ìœ„ì¹˜\" í•„ë“œë¡œ ì¶”ì¶œí•˜ì„¸ìš”!\n"
                "- \"ì¥ì†Œ\" í•„ë“œëŠ” ë°©í–¥ í‘œí˜„ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì…ë‹ˆë‹¤ (ì˜ˆ: \"ë‚´ë°© ì•ˆì—\" â†’ ì¥ì†Œ=\"ë‚´ë°©\", ì„¸ë¶€ìœ„ì¹˜=\"ì•ˆì—\")\n\n"
                "**ì¼ì • ì¶”ì¶œ ê°•í™” (ì¤‘ìš”!):**\n"
                "- 'ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ë³‘ì› ì˜ˆì•½ì´ ìˆì–´' â†’ {{\"user.ì¼ì •\": [{{\"ì œëª©\": \"ë³‘ì› ì˜ˆì•½\", \"ë‚ ì§œ\": \"ë‚´ì¼\", \"ì‹œê°„\": \"ì˜¤í›„ 3ì‹œ\"}}]}}\n"
                "- 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì— íšŒì˜ê°€ ìˆì–´' â†’ {{\"user.ì¼ì •\": [{{\"ì œëª©\": \"íšŒì˜\", \"ë‚ ì§œ\": \"ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼\"}}]}}\n"
                "- '12ì›” 25ì¼ì— í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŒŒí‹°ê°€ ìˆì–´' â†’ {{\"user.ì¼ì •\": [{{\"ì œëª©\": \"í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŒŒí‹°\", \"ë‚ ì§œ\": \"12ì›” 25ì¼\"}}]}}\n"
                "- '10ì›” 5ì¼ì— ì¶”ì„ ì—¬í–‰ ì¼ì •ìˆì–´' â†’ {{\"user.ì¼ì •\": [{{\"ì œëª©\": \"ì¶”ì„ ì—¬í–‰ ì¼ì •\", \"ë‚ ì§œ\": \"10ì›” 5ì¼\"}}]}}\n"
                "- 'ì˜¤ëŠ˜ ì €ë… 7ì‹œì— ì¹œêµ¬ ë§Œë‚˜ê¸°ë¡œ í–ˆì–´' â†’ {{\"user.ì¼ì •\": [{{\"ì œëª©\": \"ì¹œêµ¬ ë§Œë‚˜ê¸°\", \"ë‚ ì§œ\": \"ì˜¤ëŠ˜\", \"ì‹œê°„\": \"ì €ë… 7ì‹œ\"}}]}}\n"
                "- **ì ˆëŒ€ ì¤‘ìš”**: ë‚ ì§œ í•„ë“œëŠ” '10ì›” 5ì¼', '12ì›” 25ì¼', 'ë‚´ì¼', 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼' ë“±ì˜ ì‹œê°„ í‘œí˜„ë§Œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤!\n"
                "- **ì ˆëŒ€ ì¤‘ìš”**: ì œëª© í•„ë“œëŠ” 'ì¶”ì„ ì—¬í–‰', 'í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŒŒí‹°', 'íšŒì˜', 'ë³‘ì› ì˜ˆì•½' ë“±ì˜ ì¼ì • ë‚´ìš©ë§Œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤!\n"
                "- **ì ˆëŒ€ ê¸ˆì§€**: ë‚ ì§œì™€ ì œëª©ì„ ë°”ê¿”ì„œ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”! '10ì›” 5ì¼'ì€ ë‚ ì§œì´ê³ , 'ì¶”ì„ ì—¬í–‰'ì€ ì œëª©ì…ë‹ˆë‹¤!\n"
                "- ë‚ ì§œ/ì‹œê°„ì´ ëª…ì‹œë˜ì§€ ì•Šì•„ë„ ì œëª©ë§Œ ìˆìœ¼ë©´ ì¼ì •ìœ¼ë¡œ ì¶”ì¶œ\n\n"
                "{format_instructions}\n\n"
                "[ì‚¬ìš©ì ë°œí™”]\n"
                "{utterance}"
            )
        ).partial(format_instructions=fmt)
        return prompt | self.llm | parser

    def _extract_item_location_rule(self, user_input: str) -> Dict[str, List[Dict[str, Any]]]:
        """ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ (Rule-based ìš°ì„  ì²˜ë¦¬)"""
        out: Dict[str, List[Dict[str, Any]]] = {}
        t = user_input.strip()
        
        # ë¬¸ì¥ì„ ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ê°ê° ì²˜ë¦¬
        sentences = [s.strip() for s in t.split(',') if s.strip()]
        
        for sentence in sentences:
            # ë¬¼ê±´ ìœ„ì¹˜ íŒ¨í„´ë“¤ (ë‹¤ì–‘í•œ í‘œí˜„ ì§€ì›)
            location_patterns = [
                # ê¸°ë³¸ íŒ¨í„´: "ë‚´ ë¬¼ì»µì€ ì£¼ë°© ì°¬ì¥ ì•ˆì— ìˆì–´"
                r"(?:ë‚´|ë„¤|ì´|ê·¸)\s*(.+?)\s*(?:ì€|ëŠ”)\s*(.+?)\s*(?:ì•ˆì—|ìœ„ì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—|ì—)\s*(?:ìˆì–´|ìˆê³ |ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤|ë‘¬|ë†”|ë‘|ë†“|ë³´ê´€)",
                # ì¼ë°˜ íŒ¨í„´: "ë¬¼ê±´ì€ ìœ„ì¹˜ì— ìˆì–´"
                r"(.+?)\s*(?:ì€|ëŠ”)\s*(.+?ì—|ìœ„ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)\s*(?:ìˆ|ë‘¬|ë†”|ë‘|ë†“|ë³´ê´€)",
                # ìœ„ì¹˜+ë¬¼ê±´ ìˆœì„œ: "ì£¼ë°© ì°¬ì¥ì— ë¬¼ì»µì´ ìˆì–´"
                r"(.+?)\s*(?:ì—|ìœ„ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)\s*(.+?)\s*(?:ì´|ê°€)?\s*(?:ìˆì–´|ìˆê³ |ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)",
                # "ë¬¼ê±´ ìœ„ì¹˜ì— ìˆì–´" íŒ¨í„´
                r"(.+?)\s*(.+?ì—|ìœ„ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)\s*(?:ì—|ì—ì„œ)\s*(?:ìˆ|ë‘¬|ë†”|ë‘|ë†“|ë³´ê´€)",
                # "ë¬¼ê±´ì„ ìœ„ì¹˜ì— ë‘ì—ˆì–´" íŒ¨í„´
                r"(.+?)\s*(?:ì„|ë¥¼)\s*(.+?ì—|ìœ„ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)\s*(?:ë‘ì—ˆ|ë†“ì•˜|ë³´ê´€í–ˆ)",
                # ì¶”ê°€ íŒ¨í„´: "ë¬¼ê±´ì€ ìœ„ì¹˜ì— ìˆê³ "
                r"(.+?)\s*(?:ì€|ëŠ”)\s*(.+?ì—|ìœ„ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)\s*(?:ìˆê³ |ìˆì–´)",
                # ì¶”ê°€ íŒ¨í„´: "ë¬¼ê±´ì€ ìœ„ì¹˜ì— ìˆê³ " (ë” ê°„ë‹¨í•œ ë²„ì „)
                r"(.+?)\s*(?:ì€|ëŠ”)\s*(.+?ì—)\s*(?:ìˆê³ |ìˆì–´)",
            ]
            
            for pattern in location_patterns:
                m = re.search(pattern, sentence)
                if m:
                    # íŒ¨í„´ì— ë”°ë¼ ê·¸ë£¹ ìˆœì„œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    groups = m.groups()
                    if len(groups) >= 2:
                        # ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ë¬¼ê±´ì¸ì§€ ìœ„ì¹˜ì¸ì§€ íŒë‹¨
                        g1, g2 = groups[0].strip(), groups[1].strip()
                        
                        # ìœ„ì¹˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê·¸ë£¹ì„ ì°¾ê¸°
                        location_keywords = ["ì—", "ìœ„ì—", "ì•ˆì—", "ë°–ì—", "ì˜†ì—", "ì•ì—", "ë’¤ì—", "ì•„ë˜ì—", "ì£¼ë°©", "ê±°ì‹¤", "ì¹¨ì‹¤", "ì°¬ì¥", "ì„œë", "ì±…ìƒ", "ë°©"]
                        
                        if any(kw in g2 for kw in location_keywords):
                            # g1ì´ ë¬¼ê±´, g2ê°€ ìœ„ì¹˜
                            item = re.sub(r"^(ë‚´|ë„¤|ì´|ê·¸)\s*", "", g1)
                            location = g2
                        elif any(kw in g1 for kw in location_keywords):
                            # g1ì´ ìœ„ì¹˜, g2ê°€ ë¬¼ê±´ (ì—­ìˆœ)
                            location = g1
                            item = re.sub(r"^(ë‚´|ë„¤|ì´|ê·¸)\s*", "", g2)
                        else:
                            # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ë¬¼ê±´
                            item = re.sub(r"^(ë‚´|ë„¤|ì´|ê·¸)\s*", "", g1)
                            location = g2
                        
                        # ìœ íš¨í•œ ë¬¼ê±´ëª…ê³¼ ìœ„ì¹˜ì¸ì§€ í™•ì¸
                        if (item and location and 
                            len(item) >= 1 and len(location) >= 2 and
                            item not in ["ê²ƒ", "ê±°", "ì´ê²ƒ", "ê·¸ê²ƒ", "ì €ê²ƒ"]):
                            
                            # ì¥ì†Œì™€ ì„¸ë¶€ìœ„ì¹˜ ë¶„ë¦¬
                            # âœ… "ë‚´ë°© ì±…ìƒ" ê°™ì€ ë³µí•© ì¥ì†ŒëŠ” í•˜ë‚˜ì˜ ì¥ì†Œë¡œ ë³´ê³ , "ìœ„ì—", "ì•ˆì—" ê°™ì€ ë°©í–¥ë§Œ ì„¸ë¶€ìœ„ì¹˜ë¡œ ë¶„ë¦¬
                            direction_keywords = ["ìœ„ì—", "ì˜†ì—", "ì•ì—", "ë’¤ì—", "ì•„ë˜ì—", "ì•ˆì—", "ë°–ì—", "ì—"]
                            
                            place = None
                            sub_location = ""
                            
                            # 1ë‹¨ê³„: ë°©í–¥ í‚¤ì›Œë“œ ì¶”ì¶œ (ì„¸ë¶€ìœ„ì¹˜)
                            # "ìœ„ì—", "ì˜†ì—" ë“± ëª…í™•í•œ ë°©í–¥ í‚¤ì›Œë“œë¥¼ ìš°ì„  ì²´í¬
                            direction_found = None
                            for direction in ["ìœ„ì—", "ì˜†ì—", "ì•ì—", "ë’¤ì—", "ì•„ë˜ì—", "ì•ˆì—", "ë°–ì—"]:
                                if location.endswith(direction):
                                    direction_found = direction
                                    location_without_direction = location[:-len(direction)].strip()
                                    break
                            
                            # "ì•ˆì—"ê°€ ì—†ì§€ë§Œ "ì•ˆ"ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš° (ì˜ˆ: "ë‚´ ë°© ì•ˆ")
                            if not direction_found and location.endswith("ì•ˆ"):
                                direction_found = "ì•ˆ"
                                location_without_direction = location[:-1].strip()
                            
                            # 2ë‹¨ê³„: ì¥ì†Œ ì¶”ì¶œ
                            if direction_found:
                                # âœ… ë°©í–¥ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì „ì²´ë¥¼ ì¥ì†Œë¡œ, ë°©í–¥ì„ ì„¸ë¶€ìœ„ì¹˜ë¡œ
                                # ì˜ˆ: "ë‚´ ë°© ì•ˆ" â†’ place="ë‚´ ë°©", sub_location="ì•ˆ"
                                # ì˜ˆ: "ë‚´ë°© ì±…ìƒ ìœ„ì—" â†’ place="ë‚´ë°© ì±…ìƒ", sub_location="ìœ„ì—"
                                place = location_without_direction
                                sub_location = direction_found
                            elif location.endswith("ì—"):
                                # âœ… "ì—"ë§Œ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬ (ì˜ˆ: "ë‚´ë°© ì±…ìƒì—")
                                place = location[:-1].strip()  # "ì—" ì œê±°
                                sub_location = "ì—"
                            else:
                                # âœ… ë°©í–¥ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ì¥ì†Œë¡œ, ì„¸ë¶€ìœ„ì¹˜ëŠ” ë¹ˆ ë¬¸ìì—´
                                # ì˜ˆ: "ë‚´ë°© ì±…ìƒ" â†’ place="ë‚´ë°© ì±…ìƒ", sub_location=""
                                place = location
                                sub_location = ""
                            
                            out.setdefault("user.ë¬¼ê±´", []).append({
                                "ì´ë¦„": item,
                                "ìœ„ì¹˜": location,  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ì „ì²´ ìœ„ì¹˜ë„ ìœ ì§€
                                "ì¥ì†Œ": place,
                                "ì„¸ë¶€ìœ„ì¹˜": sub_location,
                                "ì¶”ì¶œë°©ë²•": "rule-based"
                            })
                            break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ì‚¬ìš©
        
        return out

    def _extract_item_command_rule(self, user_input: str) -> Dict[str, List[Dict[str, Any]]]:
        """ë¬¼ê±´ ëª…ë ¹ ì¶”ì¶œ (Rule-based) - êº¼ë‚´ì™€, ê°€ì ¸ì™€, ì°¾ì•„ì¤˜ ë“±"""
        out: Dict[str, List[Dict[str, Any]]] = {}
        t = user_input.strip()
        
        # ë¬¼ê±´ ëª…ë ¹ íŒ¨í„´ë“¤
        command_patterns = [
            # "ìœ„ì¹˜ì—ì„œ ë¬¼ê±´ êº¼ë‚´ì™€/ê°€ì ¸ì™€"
            r"(.+?ì—ì„œ|ì—)\s*(.+?)\s*(?:êº¼ë‚´ì™€|ê°€ì ¸ì™€|êº¼ë‚´ë‹¤|ê°€ì ¸ë‹¤|êº¼ë‚´ì¤˜|ê°€ì ¸ë‹¤ì¤˜)",
            # "ë¬¼ê±´ êº¼ë‚´ì™€/ê°€ì ¸ì™€"
            r"(.+?)\s*(?:êº¼ë‚´ì™€|ê°€ì ¸ì™€|êº¼ë‚´ë‹¤|ê°€ì ¸ë‹¤|êº¼ë‚´ì¤˜|ê°€ì ¸ë‹¤ì¤˜)",
            # "ë¬¼ê±´ ì°¾ì•„ì¤˜"
            r"(.+?)\s*(?:ì°¾ì•„ì¤˜|ì°¾ì•„ë‹¤|ì°¾ì•„)",
            # "ë¬¼ê±´ ì–´ë”” ìˆì–´?"
            r"(.+?)\s*(?:ì–´ë””|ìœ„ì¹˜).*?(?:ìˆì–´|ìˆë‚˜)",
        ]
        
        for pattern in command_patterns:
            matches = re.findall(pattern, t)
            for match in matches:
                if isinstance(match, tuple):
                    if len(match) == 2:
                        location, item = match
                        # ìœ„ì¹˜ì—ì„œ ë¬¼ê±´ ì¶”ì¶œ
                        if location and item:
                            item = item.strip()
                            location = location.strip()
                            if (len(item) >= 1 and len(location) >= 2 and
                                item not in ["ê²ƒ", "ê±°", "ì´ê²ƒ", "ê·¸ê²ƒ", "ì €ê²ƒ"]):
                                out.setdefault("user.ë¬¼ê±´", []).append({
                                    "ì´ë¦„": item,
                                    "ìœ„ì¹˜": location,
                                    "ì¶”ì¶œë°©ë²•": "command-rule"
                                })
                    else:
                        # ë¬¼ê±´ë§Œ ì¶”ì¶œ
                        item = match[0] if match else ""
                        if item and len(item) >= 1 and item not in ["ê²ƒ", "ê±°", "ì´ê²ƒ", "ê·¸ê²ƒ", "ì €ê²ƒ"]:
                            out.setdefault("user.ë¬¼ê±´", []).append({
                                "ì´ë¦„": item,
                                "ìœ„ì¹˜": None,
                                "ì¶”ì¶œë°©ë²•": "command-rule"
                            })
                else:
                    # ë‹¨ì¼ ë§¤ì¹˜
                    item = match.strip()
                    if item and len(item) >= 1 and item not in ["ê²ƒ", "ê±°", "ì´ê²ƒ", "ê·¸ê²ƒ", "ì €ê²ƒ"]:
                        out.setdefault("user.ë¬¼ê±´", []).append({
                            "ì´ë¦„": item,
                            "ìœ„ì¹˜": None,
                            "ì¶”ì¶œë°©ë²•": "command-rule"
                        })
        
        return out

    # ê·œì¹™ ê¸°ë°˜ ì¶”ì¶œ (LLM ë³´ì™„ìš©, ì¶”ì¸¡ ê¸ˆì§€)
    def _rule_based_extract(self, text: str, session_id: str = None) -> Dict[str, Any]:
        # print(f"[DEBUG] _rule_based_extract í˜¸ì¶œ: '{text}'")
        out: Dict[str, Any] = {}
        groups = []  # âœ… ë°˜ë“œì‹œ ì´ˆê¸°í™” (ì¼ì • íŒ¨í„´ ë§¤ì¹­ì—ì„œ ì‚¬ìš©)
        try:
            t = text.strip() if text else ""
            if not t:
                return out

            # ì§ˆë¬¸ì„± ë¬¸ì¥ì€ ìŠ¤í‚µ
            if re.search(r"\?$", t):
                return out

            # ì•½ ë³µìš© íŒ¨í„´ ì²´í¬: ì•½ í‚¤ì›Œë“œ + "ë¨¹" ë˜ëŠ” "ë³µìš©" í‚¤ì›Œë“œ
            # âœ… "ì•½ì†"ì€ ì¼ì •ì´ë¯€ë¡œ ì•½ë¬¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            has_medicine_keyword = False
            try:
                has_medicine_keyword = any(keyword in t for keyword in MEDICINE_KEYWORDS)
                # "ì•½" í‚¤ì›Œë“œ ì²´í¬ (ë‹¨, "ì•½ì†"ì€ ì œì™¸ - ì•½ì†ì€ ì¼ì •)
                if not has_medicine_keyword and "ì•½" in t and "ì•½ì†" not in t:
                    # "~ì•½" íŒ¨í„´ (í˜ˆì••ì•½, ê°ê¸°ì•½ ë“±) ë˜ëŠ” "ì•½ ë¨¹" íŒ¨í„´ ì²´í¬
                    if re.search(r"[ê°€-í£A-Za-z]+ì•½|ì•½\s*[ë¨¹ë“œ]", t):
                        has_medicine_keyword = True
                # "~ì•½" íŒ¨í„´ ì²´í¬ (ì•ˆì „í•˜ê²Œ - ê¸¸ì´ ì œí•œ, "ì•½ì†" ì œì™¸)
                if not has_medicine_keyword and len(t) < 200:
                    if re.search(r"[ê°€-í£A-Za-z]{1,20}ì•½(?!ì†)", t):
                        has_medicine_keyword = True
            except Exception as e:
                print(f"[WARN] ì•½ í‚¤ì›Œë“œ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # "ì•½" + "ë¨¹" ë˜ëŠ” "ë³µìš©" íŒ¨í„´ ì²´í¬ (ë‹¨, "ì•½ì†"ì€ ì œì™¸ - ì•½ì†ì€ ì¼ì •)
            has_medicine_pattern = False
            try:
                # "ì•½ì†"ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì•½ ë³µìš© íŒ¨í„´ ì²´í¬
                if "ì•½ì†" not in t:
                    # ê¸°ë³¸ íŒ¨í„´: "ì•½.*?ë¨¹|ì•½.*?ë³µìš©|ë³µìš©"
                    has_medicine_pattern = bool(re.search(r"ì•½.*?ë¨¹|ì•½.*?ë³µìš©|ë³µìš©", t)) or (has_medicine_keyword and "ë¨¹" in t)
                    
                    # ì¶”ê°€ íŒ¨í„´: "ì•Œ" ë‹¨ìœ„ + "ë¨¹" ë˜ëŠ” ë³µìš© ë°©ë²• í‚¤ì›Œë“œ (ê³µë³µ, ì‹ì „, ì‹í›„ ë“±)
                    if not has_medicine_pattern:
                        # "Xì•Œ" + "ë¨¹" ë˜ëŠ” ë³µìš© ë°©ë²• íŒ¨í„´
                        if re.search(r"\d+\s*ì•Œ.*?ë¨¹|\d+\s*ì•Œ.*?(ê³µë³µ|ì‹ì „|ì‹í›„)|[í•œë‘ì„¸ë„¤ë‹¤ì„¯]\s*ì•Œ.*?ë¨¹", t):
                            has_medicine_pattern = True
                        # ë³µìš© ë°©ë²• í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì•½ìœ¼ë¡œ ì¸ì‹ (ê³µë³µ, ì‹ì „, ì‹í›„ ë“±)
                        elif re.search(r"(ê³µë³µ|ì‹ì „|ì‹í›„|ë³µìš©)", t) and re.search(r"\d+\s*ì•Œ|[í•œë‘ì„¸ë„¤ë‹¤ì„¯]\s*ì•Œ", t):
                            has_medicine_pattern = True
                else:
                    # "ì•½ì†"ì´ ìˆìœ¼ë©´ ì•½ ë³µìš© íŒ¨í„´ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                    has_medicine_pattern = False
            except Exception as e:
                print(f"[WARN] ì•½ íŒ¨í„´ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ì‹ì‚¬ ê´€ë ¨ í‚¤ì›Œë“œ (ì•½ê³¼ êµ¬ë¶„)
            has_food_keyword = False
            try:
                food_keywords = r"(ë°¥|ì‹ì‚¬|ìŒì‹|ìš”ë¦¬|ë©”ë‰´|ê¹€ì¹˜|ì°Œê°œ|êµ­|íƒ•|ë©´|ë¼ë©´|ì¹˜í‚¨|í”¼ì|í–„ë²„ê±°|ë–¡ë³¶ì´|ì‚¼ê²¹ì‚´|ê°ˆë¹„)"
                has_food_keyword = bool(re.search(food_keywords, t))
            except Exception as e:
                print(f"[WARN] ì‹ì‚¬ í‚¤ì›Œë“œ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            if has_medicine_pattern and not has_food_keyword:
                # ìƒˆë¡œìš´ ì•½ ì—”í‹°í‹° ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
                try:
                    print(f"[DEBUG] ì•½ ë³µìš© íŒ¨í„´ ë§¤ì¹­: {t}")
                    medicines = self._extract_medicine_entities(t)
                    print(f"[DEBUG] _extract_medicine_entities ê²°ê³¼: {medicines}")
                    
                    # âœ… ì‹œê°„ëŒ€ ì¶”ì¶œ (ì—¬ëŸ¬ ì‹œê°„ëŒ€ ì§€ì›: "ì•„ì¹¨ ì ì‹¬ ì €ë…" â†’ "ì•„ì¹¨/ì ì‹¬/ì €ë…")
                    time_keywords = {
                        "ì•„ì¹¨": "ì•„ì¹¨", "ì ì‹¬": "ì ì‹¬", "ì €ë…": "ì €ë…", 
                        "ë°¤": "ë°¤", "ìƒˆë²½": "ìƒˆë²½", "ì˜¤ì „": "ì˜¤ì „", "ì˜¤í›„": "ì˜¤í›„",
                        "ìê¸° ì „": "ë°¤", "ìê¸°ì „": "ë°¤", "ì·¨ì¹¨ ì „": "ë°¤", "ì·¨ì¹¨ì „": "ë°¤",
                        "ì ë“¤ê¸° ì „": "ë°¤", "ì ë“¤ê¸°ì „": "ë°¤"
                    }
                    
                    time_of_day_list = []
                    for keyword, time in time_keywords.items():
                        if keyword in t:
                            time_of_day_list.append(time)
                    
                    # âœ… "í•˜ë£¨ Xë²ˆ" ê°™ì€ ë¹ˆë„ í‘œí˜„ì„ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
                    # "í•˜ë£¨ 3ë²ˆ" â†’ "ì•„ì¹¨/ì ì‹¬/ì €ë…", "í•˜ë£¨ 2ë²ˆ" â†’ "ì•„ì¹¨/ì €ë…" ë“±
                    if not time_of_day_list:
                        # "í•˜ë£¨ Xë²ˆ" íŒ¨í„´ ì¶”ì¶œ
                        frequency_match = re.search(r"í•˜ë£¨\s*(?:ì—\s*)?(\d+|[í•œë‘ì„¸ë„¤ë‹¤ì„¯])\s*ë²ˆ", t)
                        if frequency_match:
                            freq_str = frequency_match.group(1)
                            # ìˆ«ì ë˜ëŠ” í•œê¸€ ìˆ«ìë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                            if freq_str.isdigit():
                                frequency = int(freq_str)
                            else:
                                frequency = KOREAN_NUMBERS_INT.get(freq_str, 0)
                            
                            # ë¹ˆë„ì— ë”°ë¼ ì‹œê°„ëŒ€ ì„¤ì •
                            # âœ… "í•˜ë£¨ 1ë²ˆ"ì€ ì‹œê°„ëŒ€ë¥¼ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ì•„ì¹¨ì¼ ìˆ˜ë„ ì €ë…ì¼ ìˆ˜ë„ ìˆìŒ)
                            if frequency == 1:
                                # í•˜ë£¨ 1ë²ˆì€ íŠ¹ì • ì‹œê°„ëŒ€ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ
                                time_of_day_list = []
                            elif frequency == 2:
                                time_of_day_list = ["ì•„ì¹¨", "ì €ë…"]
                            elif frequency == 3:
                                time_of_day_list = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]
                            elif frequency >= 4:
                                # 4ë²ˆ ì´ìƒì´ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ì•„ì¹¨/ì ì‹¬/ì €ë…/ë°¤
                                time_of_day_list = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ë°¤"]
                    
                    # ì—¬ëŸ¬ ì‹œê°„ëŒ€ê°€ ìˆìœ¼ë©´ "/"ë¡œ êµ¬ë¶„í•˜ì—¬ ì €ì¥
                    if time_of_day_list:
                        time_of_day = "/".join(time_of_day_list)
                    else:
                        time_of_day = None
                    
                    # ë‚ ì§œ ì¶”ì¶œ (ì˜¤ëŠ˜/ë‚´ì¼/ëª¨ë ˆ ë“±) - ì¤‘ë³µ import ì œê±°
                    date_str = None
                    if "ì˜¤ëŠ˜" in t or "ì§€ê¸ˆ" in t:
                        date_str = datetime.now().strftime("%Y-%m-%d")
                    elif "ë‚´ì¼" in t:
                        date_str = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
                    elif "ëª¨ë ˆ" in t:
                        date_str = (datetime.now() + timedelta(days=2)).strftime("%Y-%m-%d")
                    else:
                        # ë‚ ì§œ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì˜¤ëŠ˜
                        date_str = datetime.now().strftime("%Y-%m-%d")
                    
                    if medicines:
                        # âœ… ë³µìš©ë°©ë²• ì¶”ì¶œ (ì‹í›„ 30ë¶„, ê³µë³µì— ë“±)
                        # import reëŠ” ì „ì—­ì—ì„œ ì´ë¯¸ importë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì œê±°
                        ë³µìš©ë°©ë²•_ê°’ = ""
                        for pattern in METHOD_PATTERNS:
                            method_match = re.search(pattern, t)
                            if method_match:
                                if "ì‹í›„" in pattern and method_match.group(1):
                                    ë³µìš©ë°©ë²•_ê°’ = f"ì‹í›„ {method_match.group(1)}ë¶„"
                                elif "ì‹í›„" in pattern:
                                    ë³µìš©ë°©ë²•_ê°’ = "ì‹í›„"
                                elif "ì‹ì „" in pattern:
                                    ë³µìš©ë°©ë²•_ê°’ = "ì‹ì „"
                                elif "ê³µë³µ" in pattern:
                                    ë³µìš©ë°©ë²•_ê°’ = "ê³µë³µ"
                                else:
                                    ë³µìš©ë°©ë²•_ê°’ = method_match.group(0)
                                break
                        
                        # âœ… ë³µìš©ê¸°ê°„ ì¶”ì¶œ (ì¼ì£¼ì¼ ë™ì•ˆ, í•œ ë‹¬ ë™ì•ˆ, ë³µìš© ê¸°ê°„ì€ ì¼ì£¼ì¼ ë“±)
                        ë³µìš©ê¸°ê°„_ê°’ = ""
                        # ìš°ì„ ìˆœìœ„: "ë³µìš© ê¸°ê°„" í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ë¨¼ì € ì²˜ë¦¬
                        # "ë³µìš© ê¸°ê°„ì€ ì¼ì£¼ì¼ì´ì•¼", "ë³µìš© ê¸°ê°„ì€ ì¼ì£¼ì¼" ë“± ë‹¤ì–‘í•œ í‘œí˜„ ì§€ì›
                        # "ì€/ëŠ”"ì´ í¬í•¨ë  ìˆ˜ ìˆê³ , ë‹¤ì–‘í•œ ì¢…ê²°ì–´ë¯¸ë„ í—ˆìš©
                        period_with_keyword_patterns = [
                            r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*ì¼ì£¼ì¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                            r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ì¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                            r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ì£¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                            r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ê°œì›”(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                            r"ë³µìš©\s*ê¸°ê°„.*?ì¼ì£¼ì¼",  # ë” ë„“ì€ íŒ¨í„´ (fallback)
                            r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ì¼",
                            r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ì£¼",
                            r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ê°œì›”",
                        ]
                        for pattern in period_with_keyword_patterns:
                            period_match = re.search(pattern, t)
                            if period_match:
                                if "ì¼ì£¼ì¼" in pattern:
                                    ë³µìš©ê¸°ê°„_ê°’ = "7ì¼"
                                    break
                                elif period_match.lastindex and period_match.group(1):
                                    unit = "ì¼"
                                    if "ì£¼" in pattern:
                                        unit = "ì£¼"
                                    elif "ê°œì›”" in pattern:
                                        unit = "ê°œì›”"
                                    ë³µìš©ê¸°ê°„_ê°’ = f"{period_match.group(1)}{unit}"
                                    break
                        
                        # "ë³µìš© ê¸°ê°„" í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ íŒ¨í„´ ê²€ì‚¬
                        if not ë³µìš©ê¸°ê°„_ê°’:
                            period_patterns = [
                                r"ì¼ì£¼ì¼\s*ë™ì•ˆ",
                                r"(\d+)\s*ì¼\s*ë™ì•ˆ",
                                r"(\d+)\s*ì£¼ì¼\s*ë™ì•ˆ",
                                r"(\d+)\s*ì£¼\s*ë™ì•ˆ",
                                r"(\d+)\s*ë‹¬\s*ë™ì•ˆ",
                                r"(\d+)\s*ê°œì›”\s*ë™ì•ˆ",
                                r"í•œ\s*ë‹¬\s*ë™ì•ˆ",
                                r"ì¼ì£¼ì¼ì¹˜",
                                r"(\d+)\s*ì£¼ì¼ì¹˜",
                                r"(\d+)\s*ì£¼\s*ì¹˜",
                                r"(\d+)\s*ì¼ì¹˜",
                                r"(\d+)\s*ê°œì›”ì¹˜",
                            ]
                            for pattern in period_patterns:
                                period_match = re.search(pattern, t)
                                if period_match:
                                    if "ì¼ì£¼ì¼" in pattern:
                                        ë³µìš©ê¸°ê°„_ê°’ = "7ì¼"
                                        break
                                    elif "í•œ ë‹¬" in pattern or "í•œë‹¬" in pattern:
                                        ë³µìš©ê¸°ê°„_ê°’ = "30ì¼"
                                        break
                                    elif period_match.lastindex and period_match.group(1):
                                        unit = "ì¼"
                                        if "ì£¼" in pattern or "ì£¼ì¼" in pattern:
                                            unit = "ì£¼"
                                        elif "ë‹¬" in pattern or "ê°œì›”" in pattern:
                                            unit = "ê°œì›”"
                                        ë³µìš©ê¸°ê°„_ê°’ = f"{period_match.group(1)}{unit}"
                                        break
                        
                        for medicine in medicines:
                            # ì•½ ë³µìš© ì—”í‹°í‹° ìƒì„± (ê°œì„ ëœ ë²„ì „)
                            # âœ… ì‹œê°„ëŒ€ë¥¼ ì‹¤ì œ ì¶”ì¶œëœ ê°’ìœ¼ë¡œ ì„¤ì • (ê¸°ë³¸ê°’ "ë¯¸ì •" ì‚¬ìš© ìµœì†Œí™”)
                            actual_time = time_of_day or ""
                            # ì‹œê°„ëŒ€ê°€ ë¹„ì–´ìˆìœ¼ë©´ "ë¯¸ì •" ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì • (ë” ì •í™•í•œ ì¤‘ë³µ ê°ì§€)
                            medication_entity = {
                                "ì•½ëª…": medicine.get("ì´ë¦„", ""),
                                "ìš©ëŸ‰": medicine.get("ìš©ëŸ‰", ""),
                                "ë‹¨ìœ„": medicine.get("ë‹¨ìœ„", ""),
                                "ì‹œê°„ëŒ€": actual_time,  # âœ… ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” ì‹¤ì œ ì‹œê°„ëŒ€ ì‚¬ìš©
                                "ë³µìš©": "ì˜ˆì •" if "ë¨¹ì„" in t else "ì™„ë£Œ",
                                "ë‚ ì§œ": date_str,
                                "ë³µìš©ë°©ë²•": ë³µìš©ë°©ë²•_ê°’,  # âœ… ì¶”ê°€
                                "ë³µìš©ê¸°ê°„": ë³µìš©ê¸°ê°„_ê°’   # âœ… ì¶”ê°€
                            }
                            
                            out.setdefault("user.ì•½", []).append(medication_entity)
                            print(f"[DEBUG] ì•½ ë³µìš© ì—”í‹°í‹° ì¶”ì¶œ: {medication_entity}")
                        return out
                    else:
                        # ì•½ ì´ë¦„ì´ ì—†ëŠ” ê²½ìš° fallback
                        # âœ… fallbackì—ì„œë„ ë³µìš©ë°©ë²•ê³¼ ë³µìš©ê¸°ê°„ ì¶”ì¶œ ì‹œë„
                        if 'ë³µìš©ë°©ë²•_ê°’' not in locals():
                            ë³µìš©ë°©ë²•_ê°’ = ""
                            for pattern in METHOD_PATTERNS:
                                method_match = re.search(pattern, t)
                                if method_match:
                                    if "ì‹í›„" in pattern and method_match.group(1):
                                        ë³µìš©ë°©ë²•_ê°’ = f"ì‹í›„ {method_match.group(1)}ë¶„"
                                    elif "ì‹í›„" in pattern:
                                        ë³µìš©ë°©ë²•_ê°’ = "ì‹í›„"
                                    elif "ì‹ì „" in pattern:
                                        ë³µìš©ë°©ë²•_ê°’ = "ì‹ì „"
                                    elif "ê³µë³µ" in pattern:
                                        ë³µìš©ë°©ë²•_ê°’ = "ê³µë³µ"
                                    else:
                                        ë³µìš©ë°©ë²•_ê°’ = method_match.group(0)
                                    break
                        
                        if 'ë³µìš©ê¸°ê°„_ê°’' not in locals() or not ë³µìš©ê¸°ê°„_ê°’:
                            ë³µìš©ê¸°ê°„_ê°’ = ""
                            # ë³µìš© ê¸°ê°„ íŒ¨í„´ ì¬ê²€ì‚¬
                            period_with_keyword_patterns = [
                                r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*ì¼ì£¼ì¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                                r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ì¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                                r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ì£¼(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                                r"ë³µìš©\s*ê¸°ê°„\s*(?:ì€|ëŠ”|ì´|ê°€)?\s*(\d+)\s*ê°œì›”(?:\s*(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ë™ì•ˆ|ì¹˜|ì´ë‹¤|ë‹¤|ì–´|ì•„))?",
                                r"ë³µìš©\s*ê¸°ê°„.*?ì¼ì£¼ì¼",  # ë” ë„“ì€ íŒ¨í„´ (fallback)
                                r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ì¼",
                                r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ì£¼",
                                r"ë³µìš©\s*ê¸°ê°„.*?(\d+)\s*ê°œì›”",
                            ]
                            for pattern in period_with_keyword_patterns:
                                period_match = re.search(pattern, t)
                                if period_match:
                                    if "ì¼ì£¼ì¼" in pattern:
                                        ë³µìš©ê¸°ê°„_ê°’ = "7ì¼"
                                        break
                                    elif period_match.lastindex and period_match.group(1):
                                        unit = "ì¼"
                                        if "ì£¼" in pattern:
                                            unit = "ì£¼"
                                        elif "ê°œì›”" in pattern:
                                            unit = "ê°œì›”"
                                        ë³µìš©ê¸°ê°„_ê°’ = f"{period_match.group(1)}{unit}"
                                        break
                        
                        actual_time = time_of_day or ""
                        medication_entity = {
                            "ì‹œê°„ëŒ€": actual_time,  # âœ… ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” ì‹¤ì œ ì‹œê°„ëŒ€ ì‚¬ìš©
                            "ë³µìš©": "ì˜ˆì •" if "ë¨¹ì„" in t else "ì™„ë£Œ",
                            "ë‚ ì§œ": date_str,
                            "ë³µìš©ë°©ë²•": ë³µìš©ë°©ë²•_ê°’,  # âœ… ì¶”ê°€
                            "ë³µìš©ê¸°ê°„": ë³µìš©ê¸°ê°„_ê°’   # âœ… ì¶”ê°€
                        }
                        
                        out.setdefault("user.ì•½", []).append(medication_entity)
                        print(f"[DEBUG] ì•½ ë³µìš© ì—”í‹°í‹° ì¶”ì¶œ (fallback, ì•½ ì´ë¦„ ì—†ìŒ): {medication_entity}")
                        return out
                except Exception as e:
                    print(f"[ERROR] ì•½ ë³µìš© ì—”í‹°í‹° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê³„ì† ì§„í–‰

            # âœ… ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°, ì¼ì • ì¶”ì¶œì„ ë¨¼ì € ì‹œë„ (ë¬¼ê±´ ì¶”ì¶œë³´ë‹¤ ìš°ì„ )
            schedule_keywords = ["ì•½ì†", "ëª¨ì„", "íšŒì‹", "ë¯¸íŒ…", "ë¯¸íŒ…ì´", "ì¼ì •", "ì˜ˆì•½", "ë§Œë‚¨", "ë°ì´íŠ¸", "ëª¨ì„ì´", "ì•½ì†ì´"]
            has_schedule_keyword = any(k in t for k in schedule_keywords)
            
            # âœ… ì¼ì • ì¶”ì¶œì„ ë¨¼ì € ì‹œë„ (ë¬¼ê±´ ì¶”ì¶œë³´ë‹¤ ìš°ì„ )
            # ì¼ì • ì¶”ì¶œì€ ì•„ë˜ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í”Œë˜ê·¸ë§Œ ì„¤ì •
            # ì¼ì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¬¼ê±´ ì¶”ì¶œì„ ì™„ì „íˆ ê±´ë„ˆë›°ê¸°
            if has_schedule_keyword:
                print(f"[DEBUG] [RULE] ì¼ì • í‚¤ì›Œë“œ ê°ì§€ â†’ ë¬¼ê±´ ì¶”ì¶œ ì™„ì „ ì œì™¸: {t}")
            else:
                # âœ… ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ: "ë‚´ ë¬¼ì»µì€ ì£¼ë°© ì°¬ì¥ ì•ˆì— ìˆì–´" ë“±
                # ì¼ì • í‚¤ì›Œë“œê°€ ì—†ì„ ë•Œë§Œ ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ ì‹œë„
                item_location_keywords = ["ìˆì–´", "ìœ„ì¹˜", "ì„œë", "ì°¬ì¥", "ë°©", "ì£¼ë°©", "ì±…ìƒ", "ë¬¼ê±´", "ë³´ê´€", "ë†“ì•˜", "ë‘ì—ˆ", "ì•ˆì—", "ìœ„ì—"]
                has_item_location_keywords = any(k in t for k in item_location_keywords)
                
                # ë¬¼ê±´ ìœ„ì¹˜ ì—”í‹°í‹°ê°€ ì•„ì§ ì—†ê³ , ì•½/ì‹ì‚¬ íŒ¨í„´ì´ ì•„ë‹ ë•Œë§Œ ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ
                if has_item_location_keywords and "user.ë¬¼ê±´" not in out:
                    try:
                        item_extracted = self._extract_item_location_rule(t)
                        if item_extracted and item_extracted.get("user.ë¬¼ê±´"):
                            out.setdefault("user.ë¬¼ê±´", []).extend(item_extracted["user.ë¬¼ê±´"])
                            print(f"[DEBUG] _rule_based_extractì—ì„œ ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ: {item_extracted['user.ë¬¼ê±´']}")
                    except Exception as e:
                        print(f"[DEBUG] ë¬¼ê±´ ìœ„ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                        pass

            # âœ… ì‚¬ìš©ì ê°œì¸ì •ë³´ ì¶”ì¶œ (ì´ë¦„, ë‚˜ì´, í•™êµ ë“±)
            try:
                print(f"[DEBUG] ì‚¬ìš©ì ê°œì¸ì •ë³´ ì¶”ì¶œ ì‹œì‘: '{t}'")
            except Exception:
                pass
            
            # ë‚˜ì´ ì¶”ì¶œ
            age_patterns = [
                r"ë‚´\s*ë‚˜ì´(?:ëŠ”|ê°€)?\s*(\d+)(?:ì‚´|ì„¸)",
                r"ë‚˜ëŠ”\s*(\d+)(?:ì‚´|ì„¸)",
                r"ì €ëŠ”\s*(\d+)(?:ì‚´|ì„¸)",
                r"(\d+)(?:ì‚´|ì„¸)(?:ì•¼|ì´ì•¼|ì…ë‹ˆë‹¤|ì´ì—ìš”)"
            ]
            
            age = None
            for pattern in age_patterns:
                m = re.search(pattern, t)
                if m:
                    age = f"{m.group(1)}ì‚´"
                    break
            
            # í•™êµ ì¶”ì¶œ
            school_patterns = [
                r"ë‚˜ëŠ”\s*([ê°€-í£\s]+(?:ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ì´ˆë“±í•™êµ|í•™êµ))ì—?\s*ë‹¤ë…€",
                r"ì €ëŠ”\s*([ê°€-í£\s]+(?:ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ì´ˆë“±í•™êµ|í•™êµ))ì—?\s*ë‹¤ë…€",
                r"([ê°€-í£\s]+(?:ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ì´ˆë“±í•™êµ|í•™êµ))ì—?\s*ë‹¤ë…€",
                r"([ê°€-í£\s]+(?:ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ì´ˆë“±í•™êµ|í•™êµ))ì—?\s*ë‹¤ë‹ˆê³ "
            ]
            
            school = None
            for pattern in school_patterns:
                m = re.search(pattern, t)
                if m:
                    school = m.group(1).strip()
                    break
        
            # ì§ì—… ì¶”ì¶œ
            job_patterns = [
                r"ë‚˜ëŠ”\s*([ê°€-í£\s]+)(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤)",
                r"ì €ëŠ”\s*([ê°€-í£\s]+)(?:ì´ì—ìš”|ì…ë‹ˆë‹¤)",
                r"ì§ì—…(?:ì€|ì´)?\s*([ê°€-í£\s]+)(?:ì•¼|ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤)"
            ]
            
            job = None
            for pattern in job_patterns:
                m = re.search(pattern, t)
                if m:
                    job_candidate = m.group(1).strip()
                    # ì§ì—… ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    if any(keyword in job_candidate for keyword in ["í•™ìƒ", "íšŒì‚¬ì›", "ì„ ìƒë‹˜", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "ì—”ì§€ë‹ˆì–´", "ê°œë°œì", "ë””ìì´ë„ˆ"]):
                        job = job_candidate
                        break
            
            # ê°œì¸ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì ì—”í‹°í‹° ìƒì„±
            if age or school or job:
                user_entity = {}
                if age:
                    user_entity["ë‚˜ì´"] = age
                if school:
                    user_entity["í•™êµ"] = school
                if job:
                    user_entity["ì§ì—…"] = job
                
                out.setdefault("user.ì‚¬ìš©ì", []).append(user_entity)
                print(f"[DEBUG] ì‚¬ìš©ì ê°œì¸ì •ë³´ ì¶”ì¶œ: {user_entity}")
        
            # 1ì°¨: ì§ˆë¬¸ íŒ¨í„´ í™•ì¸ (ìƒˆë¡œìš´ ì—”í‹°í‹° ìƒì„±í•˜ì§€ ì•ŠìŒ)
            if self._is_name_question(t):
                print(f"[DEBUG] ì´ë¦„ ì§ˆë¬¸ íŒ¨í„´ìœ¼ë¡œ ì¸í•´ ìŠ¤í‚µ")
                return out  # ì§ˆë¬¸ì€ ìƒˆë¡œìš´ ì—”í‹°í‹° ìƒì„±í•˜ì§€ ì•ŠìŒ
            
            # 2ì°¨: LLM ê¸°ë°˜ ì´ë¦„ ë° ë³„ì¹­ ì¶”ì¶œ (ë¬¸ë§¥ ì´í•´)
            llm_result = self._extract_name_llm(t)
            if llm_result and llm_result.get("name"):
                user_entity = {"ì´ë¦„": llm_result["name"], "í™•ì¸ë¨": True}
                if llm_result.get("alias"):
                    user_entity["ë³„ì¹­"] = llm_result["alias"]
                out.setdefault("user.ì‚¬ìš©ì", []).append(user_entity)
            else:
                # 3ì°¨: ê·œì¹™ ê¸°ë°˜ fallback (ë³¸ëª…ê³¼ ë³„ì¹­ êµ¬ë¶„)
                clean_text = re.sub(r'[\.,!?]+$', '', t.strip())
                
                # ê°€ì¡± ì´ë¦„ íŒ¨í„´ì´ í¬í•¨ëœ ê²½ìš° ì‚¬ìš©ì ì´ë¦„ ì¶”ì¶œ ìŠ¤í‚µ
                family_patterns = [
                    r"ìš°ë¦¬\s*(ë™ìƒ|ì—„ë§ˆ|ì•„ë¹ |í˜•|ëˆ„ë‚˜|ì–¸ë‹ˆ|ì˜¤ë¹ |í• ë¨¸ë‹ˆ|í• ì•„ë²„ì§€)",
                    r"(ë™ìƒ|ì—„ë§ˆ|ì•„ë¹ |í˜•|ëˆ„ë‚˜|ì–¸ë‹ˆ|ì˜¤ë¹ |í• ë¨¸ë‹ˆ|í• ì•„ë²„ì§€)\s*ì´ë¦„",
                    r"ê°€ì¡±\s*ì´ë¦„"
                ]
                
                is_family_context = any(re.search(pattern, clean_text) for pattern in family_patterns)
                
                # ë³¸ëª… ì¶”ì¶œ íŒ¨í„´ (ê°€ì¡± ì»¨í…ìŠ¤íŠ¸ì™€ ê´€ê³„ì—†ì´ ì •ì˜)
                name_patterns = [
                    r"ë‚´\s*ì´ë¦„(?:ì€|ì´)?\s*([ê°€-í£A-Za-z\s]{2,10})(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ì˜ˆìš”|ì•¼|ë‹¤|ì–´|ì•„)?",
                    r"ë‚˜ëŠ”\s*([ê°€-í£A-Za-z\s]{2,10})(?:ì•¼|ì´ë‹¤|ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”)",
                    r"ì €ëŠ”\s*([ê°€-í£A-Za-z\s]{2,10})(?:ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”|ì•¼)",
                    r"ë‚œ\s*([ê°€-í£A-Za-z\s]{2,10})(?:ì•¼|ì´ë‹¤|ì´ì•¼)"
                ]
                
                # ê°€ì¡± ì»¨í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì‚¬ìš©ì ì´ë¦„ ì¶”ì¶œ ì‹œë„
                if not is_family_context:
                    # ë³¸ëª… ì¶”ì¶œ ì‹œë„ (ë³„ëª…ì€ LLMì´ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë³¸ëª…ë§Œ)
                    for pattern in name_patterns:
                        m = re.search(pattern, clean_text)
                        if m:
                            name = self._normalize_name(m.group(1))
                            if self._is_valid_name(name):
                                out.setdefault("user.ì‚¬ìš©ì", []).append({"ì´ë¦„": name, "í™•ì¸ë¨": True})
                                break
                
                # ê°€ì¡± ë§¥ë½ì´ì–´ë„ 'ë‚´ ì´ë¦„' íŒ¨í„´ì€ í—ˆìš©
                if is_family_context:
                    for pattern in name_patterns:
                        m = re.search(pattern, clean_text)
                        if m:
                            name = self._normalize_name(m.group(1))
                            if (name 
                                and name not in {"ëˆ„êµ¬ê²Œ", "ëª°ë¼"} 
                                and name not in NAME_BLACKLIST 
                                and len(name) >= 2 
                                and not re.search(r"[0-9]", name) 
                                and self._is_valid_name(name)):
                                out.setdefault("user.ì‚¬ìš©ì", []).append({"ì´ë¦„": name, "í™•ì¸ë¨": True})
                            break

            # âœ… ê°€ì¡± (ì›ë¬¸ substring ê²€ì¦ + ì´ë¦„ ì¶”ì¶œ)
            # âœ… FAMILY_RELATION_KEYWORDSì™€ ì¼ì¹˜í•˜ë„ë¡ í™•ì¥: ë©°ëŠë¦¬, ì‚¬ìœ„ ë“± ì¶”ê°€
            family_patterns = [
                r"(ë‚¨í¸|ì•„ë‚´|ì—„ë§ˆ|ì–´ë¨¸ë‹ˆ|ì•„ë¹ |ì•„ë²„ì§€|ì•„ë“¤|ë”¸|í˜•|ëˆ„ë‚˜|ë™ìƒ|ì–¸ë‹ˆ|ì˜¤ë¹ |í• ë¨¸ë‹ˆ|í• ì•„ë²„ì§€|ì†ì|ì†ë…€|ì†ì£¼|ë©°ëŠë¦¬|ì‚¬ìœ„|ë¶€ëª¨)"
            ]
            for pattern in family_patterns:
                m = re.search(pattern, t)
                if m:
                    rel = NORMALIZE_KEYS.get(m.group(1), m.group(1))
                    # ì›ë¬¸ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì¦
                    if m.group(1) in t:
                        family_info = {"ê´€ê³„": rel}
                    
                    # ê°€ì¡± ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "ì•„ë¹  ì´ë¦„ì€ í™ê¸¸ë™", "ìš°ë¦¬ ë™ìƒ ì´ë¦„ì€ ê¶Œì„œìœ¨ì´ì•¼")
                    # **ì£¼ì˜: ê°€ì¡± ì´ë¦„ë§Œ ì¶”ì¶œí•˜ê³  ì‚¬ìš©ì ì´ë¦„ê³¼ ì ˆëŒ€ í˜¼ë™í•˜ì§€ ì•ŠìŒ**
                    name_patterns = [
                        f"{m.group(1)}\\s*ì´ë¦„(?:ì€|ì´)?\\s*([ê°€-í£A-Za-z]{{2,}})(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ì•¼|ë‹¤|ì–´|ì•„|ì´ê³ |ì´ê³ ìš”)?",
                        f"{m.group(1)}\\s*([ê°€-í£A-Za-z]{{2,}})(?:ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ì•¼|ë‹¤|ì–´|ì•„|ì´ê³ |ì´ê³ ìš”)(?!\\s*(?:ì´ë¦„|ì€|ì´|ì´ë‹¤|ì…ë‹ˆë‹¤))"  # "ì´ë¦„", "ì€", "ì´", "ì´ë‹¤", "ì…ë‹ˆë‹¤" ë’¤ì— ì˜¤ëŠ” ê²ƒì€ ì œì™¸
                    ]
                    
                    name_found = False
                    for name_pattern in name_patterns:
                        name_match = re.search(name_pattern, t)
                        if name_match:
                            name = self._normalize_name(name_match.group(1))
                            # ê´€ê³„ëª… ìì²´ëŠ” ì´ë¦„ì— ë“¤ì–´ê°€ì§€ ì•Šë„ë¡ ì œì™¸ + "ì´ë¦„ì€" ê°™ì€ ë¶ˆì™„ì „í•œ í‘œí˜„ ì œì™¸
                            if (name 
                                and name not in NAME_BLACKLIST 
                                and name != rel 
                                and name not in ["ì´ë¦„ì€", "ì´ë¦„ì´", "ì´ë¦„", "ì€", "ì´", "ì´ë‹¤", "ì…ë‹ˆë‹¤"]):
                                family_info["ì´ë¦„"] = name
                                name_found = True
                            break
                    
                    # ì¶”ê°€ íŒ¨í„´: "ê¶Œì„œìœ¨ì´ë¼ê³ " ê°™ì€ ê²½ìš° ì²˜ë¦¬
                    if not name_found:
                        direct_name_pattern = f"{m.group(1)}\\s*([ê°€-í£A-Za-z]{{2,}})(?:ì´ë¼ê³ |ë¼ê³ |ë¼)$"
                        direct_match = re.search(direct_name_pattern, t)
                        if direct_match:
                            name = self._normalize_name(direct_match.group(1))
                            if (name 
                                and name not in NAME_BLACKLIST 
                                and name != rel 
                                and name not in ["ì´ë¦„ì€", "ì´ë¦„ì´", "ì´ë¦„", "ì€", "ì´", "ì´ë‹¤", "ì…ë‹ˆë‹¤"]):
                                family_info["ì´ë¦„"] = name
                                name_found = True
                            break
                    
                    # ì´ë¦„ì´ ìˆì„ ë•Œë§Œ ê°€ì¡± ì •ë³´ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                    if name_found:
                        # ì´ë¯¸ ë™ì¼í•œ ê°€ì¡± ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
                        existing_family = out.get("user.ê°€ì¡±", [])
                        is_duplicate = any(
                            f.get("ê´€ê³„") == family_info.get("ê´€ê³„") and 
                            f.get("ì´ë¦„") == family_info.get("ì´ë¦„")
                            for f in existing_family
                        )
                        
                        if not is_duplicate:
                            out.setdefault("user.ê°€ì¡±", []).append(family_info)
                            logger.debug(f"ê°€ì¡± ì •ë³´ ì¶”ê°€: {family_info}")
                        else:
                            logger.debug(f"ê°€ì¡± ì •ë³´ ì¤‘ë³µ ë°©ì§€: {family_info}")
                    break

            # âœ… ì•½ ì¶”ì¶œ (ê°œì„ ëœ ì•½ë³„ ë³µìš© ì •ë³´ ë¶„ë¦¬)
            if (re.search(r"\bì•½\b", t) or 
                re.search(r"[ê°€-í£A-Za-z]+ì•½", t) or 
                any(drug in t for drug in ["ì•„ìŠ¤í”¼ë¦°", "íƒ€ì´ë ˆë†€", "ì´ë¶€í”„ë¡œíœ", "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ"])):
                drugs = self._extract_drugs_with_info(t)
                if drugs:
                    out.setdefault("user.ì•½", []).extend(drugs)

            # âœ… ì¼ì • ì¶”ì¶œ (ë‹¨ìˆœí™”ëœ íŒ¨í„´)
            print(f"[DEBUG] ì¼ì • ì¶”ì¶œ ì‹œì‘: '{t}'")
            schedule_patterns = [
                r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*(\d{1,2}ì‹œ)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)",
                r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*(ì˜¤í›„|ì˜¤ì „)?\s*(\d{1,2}ì‹œ)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)",
                r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*(ì˜¤í›„|ì˜¤ì „)?\s*(\d{1,2}ì‹œ)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ê°€ì•¼|í•´ì•¼|í•´ì•¼í•´|ê°€ì•¼í•´|í•´ì•¼í•´ìš”|ê°€ì•¼í•´ìš”)",
                r"([ê°€-í£A-Za-z\s]+?)\s*(?:ê°€ì•¼|í•´ì•¼|í•´ì•¼í•´|ê°€ì•¼í•´|í•´ì•¼í•´ìš”|ê°€ì•¼í•´ìš”)\s*(?:ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)?\s*(?:ì˜¤í›„|ì˜¤ì „)?\s*(\d{1,2}ì‹œ)?",
                r"(?:ë³‘ì›|íšŒì˜|ì•½ì†|ë¯¸íŒ…|ë°ì´íŠ¸|ì¼ì •|ìŠ¤ì¼€ì¤„|ì˜ˆì•½)\s*(?:ê°€ì•¼|í•´ì•¼|í•´ì•¼í•´|ê°€ì•¼í•´|í•´ì•¼í•´ìš”|ê°€ì•¼í•´ìš”)",
                r"(ë‹¤ìŒ\s*ì£¼|ì´ë²ˆ\s*ì£¼|ë‹¤ìŒì£¼|ì´ë²ˆì£¼)\s*([ê°€-í£]+ìš”ì¼)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ê°€ì•¼|í•´ì•¼|ìˆì–´|ìˆì–´ìš”)",
                r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆì£¼|ë‹¤ìŒì£¼)\s*([ê°€-í£]+ìš”ì¼)\s*(ì €ë…|ì˜¤í›„|ì˜¤ì „|ì•„ì¹¨)?\s*(\d{1,2}ì‹œ)?\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(ì•½ì†|ëª¨ì„|ë§Œë‚¨)\s*(?:ìˆì–´|ìˆì–´ìš”)",
                r"([ê°€-í£A-Za-z\s]+?)\s*(ì €ë…|ì˜¤í›„|ì˜¤ì „|ì•„ì¹¨)?\s*(\d{1,2}ì‹œ)?\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(ì•½ì†|ëª¨ì„|ë§Œë‚¨)\s*(?:ìˆì–´|ìˆì–´ìš”)",
                r"(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ê°€ì•¼|í•´ì•¼|ìˆì–´|ìˆì–´ìš”)",
                r"(ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ)\s*(ì €ë…|ì˜¤í›„|ì˜¤ì „)?\s*(\d{1,2}ì‹œ)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ë¡œ\s*í–ˆì–´|ë¡œ\s*í–ˆì–´ìš”|ë§Œë‚˜ê¸°ë¡œ\s*í–ˆì–´|ë§Œë‚˜ê¸°ë¡œ\s*í–ˆì–´ìš”)",
                r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*([ê°€-í£A-Za-z\s]+?),\s*(ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…)?\s*(\d{1,2}ì‹œ)\s*([ê°€-í£A-Za-z\s]+?)(?:ì•¼|ì´ì•¼|ì˜ˆìš”|ì—ìš”)",
                r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)",
                r"([ê°€-í£A-Za-z\s]+?),\s*(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)\s*(ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…)?\s*(\d{1,2}ì‹œ)"
            ]
            
            cancel_patterns = [
                r"([ê°€-í£A-Za-z\s]+?)\s*(?:ì·¨ì†Œ|ì·¨ì†Œí–ˆì–´|ì·¨ì†Œí–ˆì–´ìš”|ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤|ì·¨ì†Œí•¨)",
                r"(?:ì·¨ì†Œ|ì·¨ì†Œí–ˆì–´|ì·¨ì†Œí–ˆì–´ìš”|ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤|ì·¨ì†Œí•¨)\s*([ê°€-í£A-Za-z\s]+?)",
                r"([ê°€-í£A-Za-z\s]+?)\s*(?:ì•ˆ\s*í•´|ì•ˆ\s*í•´ìš”|ì•ˆ\s*í•©ë‹ˆë‹¤|ì•ˆ\s*í•¨)"
            ]
            
            # ì¼ì • ì·¨ì†Œ ì²˜ë¦¬
            for pattern in cancel_patterns:
                m = re.search(pattern, t)
                if m:
                    title = m.group(1).strip()
                    print(f"[DEBUG] ì¼ì • ì·¨ì†Œ ê°ì§€: '{title}'")
                    # ì·¨ì†Œëœ ì¼ì •ì„ VectorStoreì—ì„œ ì‚­ì œ
                    self._cancel_schedule(session_id, title)
                    return {"user.ì¼ì •ì·¨ì†Œ": [{"ì œëª©": title, "ìƒíƒœ": "ì·¨ì†Œë¨"}]}
            
            for i, pattern in enumerate(schedule_patterns):
                m = re.search(pattern, t)
                if m:
                    print(f"[DEBUG] íŒ¨í„´ {i+1} ë§¤ì¹˜ë¨: {pattern}")
                    print(f"[DEBUG] ë§¤ì¹˜ ê·¸ë£¹: {m.groups()}")
                    groups = m.groups()
                    title_part = ""
                    date_part = "ì˜¤ëŠ˜"
                    time_part = ""
                    ampm_part = ""  # âœ… ì´ˆê¸°í™” ì¶”ê°€
                    
                    
                    is_appointment_pattern = (
                        (i == 4) or  # íŒ¨í„´ ì¸ë±ìŠ¤ 4 (ì•½ì† íŒ¨í„´ - "ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼ ì €ë… 7ì‹œì— ì¹œêµ¬ë‘ ì•½ì† ìˆì–´")
                        (("ì´ë²ˆ\\s*ì£¼" in pattern or "ë‹¤ìŒ\\s*ì£¼" in pattern or "ì´ë²ˆì£¼" in pattern or "ë‹¤ìŒì£¼" in pattern) and
                         ("ì•½ì†|ëª¨ì„|ë§Œë‚¨" in pattern or "ì•½ì†" in pattern or "ëª¨ì„" in pattern or "ë§Œë‚¨" in pattern))
                    )
                    
                    print(f"[DEBUG] íŒ¨í„´ {i+1} ê²€ì‚¬: is_appointment_pattern={is_appointment_pattern}, len(groups)={len(groups)}")
                    
                    if is_appointment_pattern and len(groups) >= 6:
                        # groups[0] = ì´ë²ˆì£¼/ë‹¤ìŒì£¼, groups[1] = ê¸ˆìš”ì¼, groups[2] = ì €ë…, groups[3] = 7ì‹œ, groups[4] = ì¹œêµ¬, groups[5] = ì•½ì†
                        print(f"[DEBUG] ì•½ì† íŒ¨í„´ ê°ì§€ë¨ (ì¸ë±ìŠ¤ {i}) - ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬")
                        week_part = groups[0] if len(groups) > 0 and groups[0] else ""
                        day_part = groups[1] if len(groups) > 1 and groups[1] else ""
                        ampm_part = groups[2] if len(groups) > 2 and groups[2] else ""
                        time_hour_part = groups[3] if len(groups) > 3 and groups[3] else ""
                        person_part = groups[4] if len(groups) > 4 and groups[4] else ""
                        keyword_part = groups[5] if len(groups) > 5 and groups[5] else ""
                        
                        # ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™”
                        if week_part and day_part:
                            date_part = f"{week_part.strip()} {day_part.strip()}".strip()
                        elif week_part:
                            date_part = week_part.strip()
                        elif day_part:
                            date_part = day_part.strip()
                        else:
                            date_part = ""
                        
                        # ì‹œê°„ ë¬¸ìì—´ ì •ê·œí™”
                        if ampm_part and time_hour_part:
                            time_part = f"{ampm_part.strip()} {time_hour_part.strip()}".strip()
                        elif ampm_part:
                            time_part = ampm_part.strip()
                        elif time_hour_part:
                            time_part = time_hour_part.strip()
                        else:
                            time_part = ""
                        
                        # ì œëª© ë¬¸ìì—´ ì •ê·œí™”
                        if person_part and keyword_part:
                            title_part = f"{person_part.strip()} {keyword_part.strip()}".strip()
                        elif person_part:
                            title_part = person_part.strip()
                        elif keyword_part:
                            title_part = keyword_part.strip()
                        else:
                            title_part = "ì•½ì†"  # ê¸°ë³¸ ì œëª©
                        
                        # ì¼ì • ì •ë³´ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ì €ì¥í•˜ê³  break
                        if title_part or date_part:
                            schedule_info = {
                                "ì œëª©": title_part,
                                "ë‚ ì§œ": date_part,
                                "ì‹œê°„": time_part
                            }
                            out.setdefault("user.ì¼ì •", []).append(schedule_info)
                            print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì¶”ì¶œ (ì•½ì† íŒ¨í„´): {schedule_info}")
                            # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ ë¬¼ê±´ ì—”í‹°í‹° ì œê±° (ì´ë¯¸ ì¶”ê°€ë˜ì—ˆë‹¤ë©´)
                            if "user.ë¬¼ê±´" in out:
                                print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì €ì¥ë¨ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
                                out.pop("user.ë¬¼ê±´", None)
                            # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ í•¨ìˆ˜ ì¢…ë£Œ (ë¬¼ê±´ ì¶”ì¶œ ë°©ì§€)
                            return out
                    
                    # âœ… íŒ¨í„´ 4 (ì¸ë±ìŠ¤ 3): (ì´ë²ˆì£¼/ë‹¤ìŒì£¼) (ìš”ì¼) (ì œëª©) - ì¼ì • ì²˜ë¦¬
                    # íŒ¨í„´: (ë‹¤ìŒ\s*ì£¼|ì´ë²ˆ\s*ì£¼|ë‹¤ìŒì£¼|ì´ë²ˆì£¼)\s*([ê°€-í£]+ìš”ì¼)\s*(?:ì—|ì—ëŠ”)?\s*([ê°€-í£A-Za-z\s]+?)\s*(?:ê°€ì•¼|í•´ì•¼|ìˆì–´|ìˆì–´ìš”)
                    if i == 3 and len(groups) >= 3 and ("ì´ë²ˆ" in pattern or "ë‹¤ìŒ" in pattern) and "ì£¼" in pattern and "ìš”ì¼" in pattern:
                        # groups[0] = ì´ë²ˆì£¼/ë‹¤ìŒì£¼, groups[1] = ìš”ì¼, groups[2] = ì œëª©
                        week_part = groups[0] if len(groups) > 0 and groups[0] else ""
                        day_part = groups[1] if len(groups) > 1 and groups[1] else ""
                        title_part = groups[2] if len(groups) > 2 and groups[2] else ""
                        
                        # ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™”
                        if week_part and day_part:
                            date_part = f"{week_part.strip()} {day_part.strip()}".strip()
                        elif week_part:
                            date_part = week_part.strip()
                        elif day_part:
                            date_part = day_part.strip()
                        else:
                            date_part = ""
                        
                        # ì œëª© ì •ë¦¬
                        if title_part:
                            title_clean = re.sub(r"^(ëŠ”|ì€|ì´|ê°€|ì„|ë¥¼)\s*", "", title_part.strip())
                            title_clean = re.sub(r"(ê°€|ì´|ì„|ë¥¼)\s*$", "", title_clean.strip())
                        else:
                            title_clean = ""
                        
                        # ì¼ì • ì •ë³´ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ì €ì¥í•˜ê³  return
                        if title_clean or date_part:
                            schedule_info = {
                                "ì œëª©": title_clean,
                                "ë‚ ì§œ": date_part,
                                "ì‹œê°„": ""
                            }
                            out.setdefault("user.ì¼ì •", []).append(schedule_info)
                            print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì¶”ì¶œ (íŒ¨í„´ 4): {schedule_info}")
                            # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°
                            if "user.ë¬¼ê±´" in out:
                                print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì €ì¥ë¨ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
                                out.pop("user.ë¬¼ê±´", None)
                            # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ í•¨ìˆ˜ ì¢…ë£Œ (ë¬¼ê±´ ì¶”ì¶œ ë°©ì§€)
                            return out
                    
                    # íŒ¨í„´ 1 ì²˜ë¦¬: "ë‚´ì¼ 4ì‹œì— ë¯¸íŒ…ìˆì–´" - (ë‚ ì§œ) (ì‹œê°„) (ì œëª©) (ìˆì–´)
                    if i == 0 and len(groups) >= 3 and "ìˆì–´" in pattern:
                        date_part = groups[0] if groups[0] else "ì˜¤ëŠ˜"
                        time_part = groups[1] if groups[1] else ""
                        title_part = groups[2] if groups[2] else ""
                        ampm_part = ""
                        # ì œëª© ì •ë¦¬ (ê³µë°± ì œê±°, ì¡°ì‚¬ ì œê±°)
                        if title_part:
                            title_part = re.sub(r"(ê°€|ì´|ì„|ë¥¼|ì€|ëŠ”)\s*$", "", title_part.strip())
                        # ì¼ì • ì €ì¥
                        if title_part or date_part:
                            schedule_info = {
                                "ì œëª©": title_part,
                                "ë‚ ì§œ": date_part,
                                "ì‹œê°„": time_part
                            }
                            out.setdefault("user.ì¼ì •", []).append(schedule_info)
                            print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì¶”ì¶œ (íŒ¨í„´ 1): {schedule_info}")
                            if "user.ë¬¼ê±´" in out:
                                print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì €ì¥ë¨ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
                                out.pop("user.ë¬¼ê±´", None)
                            return out
                    # íŒ¨í„´ 2 ì²˜ë¦¬: "ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ë³‘ì› ì˜ˆì•½ì´ ìˆì–´" - (ë‚ ì§œ) (ì˜¤í›„/ì˜¤ì „?) (ì‹œê°„) (ì œëª©) (ìˆì–´)
                    elif i == 1 and len(groups) >= 4 and "ìˆì–´" in pattern:
                        date_part = groups[0] if groups[0] else "ì˜¤ëŠ˜"
                        ampm_part = groups[1] if groups[1] else ""
                        time_part = groups[2] if groups[2] else ""
                        title_part = groups[3] if groups[3] else ""
                        # ì˜¤í›„/ì˜¤ì „ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‹œê°„ì— í¬í•¨
                        if ampm_part:
                            time_part = f"{ampm_part} {time_part}"
                        # ì œëª© ì •ë¦¬
                        if title_part:
                            title_part = re.sub(r"(ê°€|ì´|ì„|ë¥¼|ì€|ëŠ”)\s*$", "", title_part.strip())
                        # ì¼ì • ì €ì¥
                        if title_part or date_part:
                            schedule_info = {
                                "ì œëª©": title_part,
                                "ë‚ ì§œ": date_part,
                                "ì‹œê°„": time_part
                            }
                            out.setdefault("user.ì¼ì •", []).append(schedule_info)
                            print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì¶”ì¶œ (íŒ¨í„´ 2): {schedule_info}")
                            if "user.ë¬¼ê±´" in out:
                                print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì €ì¥ë¨ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
                                out.pop("user.ë¬¼ê±´", None)
                            return out
                    # ì²« ë²ˆì§¸ íŒ¨í„´: (ë‚ ì§œ) (ì˜¤í›„/ì˜¤ì „?) (ì‹œê°„) (ì œëª©)
                    elif pattern.startswith(r"(ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ)") and len(groups) >= 4:
                        date_part = groups[0] if groups[0] else "ì˜¤ëŠ˜"
                        ampm_part = groups[1] if groups[1] else ""
                        time_part = groups[2] if groups[2] else ""
                        title_part = groups[3] if groups[3] else ""
                        
                        # ì œëª©ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "ì¼ë³¸ ì—¬í–‰, ì•„ì¹¨" â†’ "ì¼ë³¸ ì—¬í–‰"ê³¼ "ì•„ì¹¨")
                        if title_part and "," in title_part:
                            parts = title_part.split(",")
                            if len(parts) >= 2:
                                title_part = parts[0].strip()
                                time_info = parts[1].strip()
                                # ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ì‹œê°„ê³¼ ê²°í•©
                                if time_info:
                                    time_part = f"{time_info} {time_part}" if time_part else time_info
                        
                        # ì˜¤í›„/ì˜¤ì „ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‹œê°„ì— í¬í•¨
                        if ampm_part:
                            time_part = f"{ampm_part} {time_part}"
                    
                    # âœ… ìƒˆë¡œìš´ íŒ¨í„´: (ë‚ ì§œ/ì‹œê°„ í‘œí˜„) (ì €ë…|ì˜¤í›„?) (ì‹œê°„?) (ì œëª©) (ì•½ì†|ëª¨ì„|ë§Œë‚¨) (ìˆì–´|ìˆì–´ìš”)
                    elif "ì•½ì†|ëª¨ì„|ë§Œë‚¨" in pattern and "ìˆì–´|ìˆì–´ìš”" in pattern and "ì´ë²ˆ.*ì£¼|ë‹¤ìŒ.*ì£¼" not in pattern:
                        # groups[0] = ë‚ ì§œ/ì‹œê°„ í‘œí˜„, groups[1] = ì €ë…/ì˜¤í›„ ë“±, groups[2] = ì‹œê°„, groups[3] = ì œëª©, groups[4] = ì•½ì†/ëª¨ì„/ë§Œë‚¨
                        if len(groups) >= 5:
                            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                            date_match = re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆì£¼|ë‹¤ìŒì£¼|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ)", t)
                            if date_match:
                                date_part = date_match.group(1)
                            time_part = f"{groups[1]} {groups[2]}" if groups[1] and groups[2] else (groups[1] if groups[1] else (groups[2] if groups[2] else ""))
                            title_part = f"{groups[3]} {groups[4]}" if groups[3] and groups[4] else (groups[3] if groups[3] else (groups[4] if groups[4] else ""))
                        elif len(groups) >= 3:
                            date_match = re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆì£¼|ë‹¤ìŒì£¼|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ)", t)
                            if date_match:
                                date_part = date_match.group(1)
                            time_part = groups[1] if len(groups) > 1 and groups[1] else ""
                            title_part = groups[2] if len(groups) > 2 and groups[2] else ""
                        else:
                            # ê·¸ë£¹ì´ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                            date_match = re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆì£¼|ë‹¤ìŒì£¼|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ)", t)
                            if date_match:
                                date_part = date_match.group(1)
                            else:
                                date_part = "ì˜¤ëŠ˜"
                            time_part = ""
                            title_part = groups[0] if len(groups) > 0 else ""
                    
                    # ë„¤ ë²ˆì§¸ íŒ¨í„´: (ë‹¤ìŒ ì£¼|ì´ë²ˆ ì£¼) (ìš”ì¼) (ì œëª©) - ì•½ì†/ëª¨ì„ ì—†ìŒ
                    elif "ë‹¤ìŒ" in pattern and "ì£¼" in pattern and "ì•½ì†|ëª¨ì„|ë§Œë‚¨" not in pattern:
                        date_part = f"{groups[0]} {groups[1]}" if len(groups) > 1 else groups[0] if len(groups) > 0 else ""
                        title_part = groups[2] if len(groups) > 2 else ""
                        time_part = ""  # ì‹œê°„ ì •ë³´ ì´ˆê¸°í™”
                # ë‘ ë²ˆì§¸ íŒ¨í„´: (ì œëª©) (ê°€ì•¼/í•´ì•¼) (ë‚ ì§œ?) (ì‹œê°„?)
                elif "ê°€ì•¼" in pattern and "í•´ì•¼" in pattern:
                    title_part = groups[0] if len(groups) > 0 else ""
                    date_part = groups[1] if len(groups) > 1 and groups[1] else "ì˜¤ëŠ˜"
                    time_part = groups[2] if len(groups) > 2 and groups[2] else ""
                # ì„¸ ë²ˆì§¸ íŒ¨í„´: (ë³‘ì›|íšŒì˜|ì•½ì†|ë¯¸íŒ…|ë°ì´íŠ¸|ì¼ì •|ìŠ¤ì¼€ì¤„|ì˜ˆì•½)
                elif "ë³‘ì›|íšŒì˜|ì•½ì†|ë¯¸íŒ…|ë°ì´íŠ¸|ì¼ì •|ìŠ¤ì¼€ì¤„|ì˜ˆì•½" in pattern:
                    title_part = groups[0] if len(groups) > 0 else ""
                    time_part = ""  # ì‹œê°„ ì •ë³´ ì´ˆê¸°í™”
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    date_match = re.search(r"(ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ|ë‹¤ìŒì£¼|ì´ë²ˆì£¼)", t)
                    if date_match:
                        date_part = date_match.group(1)
                # ë„¤ ë²ˆì§¸ íŒ¨í„´: (ë‹¤ìŒ ì£¼|ì´ë²ˆ ì£¼) (ìš”ì¼) (ì œëª©)
                elif "ë‹¤ìŒ.*ì£¼|ì´ë²ˆ.*ì£¼" in pattern:
                    date_part = f"{groups[0]} {groups[1]}" if len(groups) > 1 else groups[0] if len(groups) > 0 else ""
                    title_part = groups[2] if len(groups) > 2 else ""
                    time_part = ""  # ì‹œê°„ ì •ë³´ ì´ˆê¸°í™”
                # ë‹¤ì„¯ ë²ˆì§¸ íŒ¨í„´: (ì›” ì¼) (ì œëª©)
                elif r"\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼" in pattern:
                    date_part = groups[0] if len(groups) > 0 else ""
                    title_part = groups[1] if len(groups) > 1 else ""
                    time_part = ""  # ì‹œê°„ ì •ë³´ ì´ˆê¸°í™”
                # ì—¬ì„¯ ë²ˆì§¸ íŒ¨í„´: (ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ) (ì €ë…|ì˜¤í›„|ì˜¤ì „) (ì‹œ) (ì œëª©)
                elif "ë¡œ\s*í–ˆì–´|ë¡œ\s*í–ˆì–´ìš”|ë§Œë‚˜ê¸°ë¡œ\s*í–ˆì–´|ë§Œë‚˜ê¸°ë¡œ\s*í–ˆì–´ìš”" in pattern:
                    date_part = groups[0] if len(groups) > 0 else ""
                    time_part = f"{groups[1]} {groups[2]}" if len(groups) > 2 and groups[1] and groups[2] else ""
                    title_part = groups[3] if len(groups) > 3 else ""
                # ìƒˆë¡œìš´ íŒ¨í„´: (ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ) (ì œëª©), (ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…) (ì‹œê°„) (ë‚´ìš©)
                elif r"ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ.*,\s*ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…" in pattern:
                    date_part = groups[0] if len(groups) > 0 else ""
                    title_part = groups[1] if len(groups) > 1 else ""
                    time_part = f"{groups[2]} {groups[3]}" if len(groups) > 3 and groups[2] and groups[3] else ""
                    # ì œëª©ê³¼ ì‹œê°„ì´ ë°”ë€Œì–´ì„œ íŒŒì‹±ëœ ê²½ìš° ìˆ˜ì •
                    if title_part and time_part and title_part.isdigit() and not time_part.isdigit():
                        # ì œëª©ê³¼ ì‹œê°„ì„ ë°”ê¿”ì„œ ì €ì¥
                        temp = title_part
                        title_part = time_part
                        time_part = temp
                    # ì¶”ê°€ ìˆ˜ì •: "ì¼ë³¸ ì—¬í–‰ ì•„ì¹¨"ì„ "ì¼ë³¸ ì—¬í–‰"ê³¼ "ì•„ì¹¨"ìœ¼ë¡œ ë¶„ë¦¬
                    if title_part and "ì—¬í–‰" in title_part and "ì•„ì¹¨" in title_part:
                        # "ì¼ë³¸ ì—¬í–‰ ì•„ì¹¨" -> "ì¼ë³¸ ì—¬í–‰"ê³¼ "ì•„ì¹¨"ìœ¼ë¡œ ë¶„ë¦¬
                        if "ì•„ì¹¨" in title_part:
                            title_part = title_part.replace(" ì•„ì¹¨", "").replace("ì•„ì¹¨", "")
                            time_part = f"ì•„ì¹¨ {time_part}" if time_part else "ì•„ì¹¨"
                # ìƒˆë¡œìš´ íŒ¨í„´: (ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ) (ì œëª©) (ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)
                elif r"ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ.*ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤" in pattern and len(groups) == 2:
                    date_part = groups[0] if len(groups) > 0 else ""
                    title_part = groups[1] if len(groups) > 1 else ""
                    time_part = ""
                # ìƒˆë¡œìš´ íŒ¨í„´: (ì œëª©), (ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ) (ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…) (ì‹œê°„)
                elif r",\s*ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ.*ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…" in pattern:
                    title_part = groups[0] if len(groups) > 0 else ""
                    date_part = groups[1] if len(groups) > 1 else ""
                    time_part = f"{groups[2]} {groups[3]}" if len(groups) > 3 and groups[2] and groups[3] else ""
                # íŒ¨í„´ 7: (ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ) (ì œëª©), (ì•„ì¹¨|ì˜¤í›„|ì˜¤ì „|ì €ë…) (ì‹œê°„) (ì¶”ê°€ì •ë³´)
                elif "ì•¼|ì´ì•¼|ì˜ˆìš”|ì—ìš”" in pattern:
                    date_part = groups[0] if len(groups) > 0 else ""
                    title_part = groups[1] if len(groups) > 1 else ""
                    time_part = f"{groups[2]} {groups[3]}" if len(groups) > 3 and groups[2] and groups[3] else ""
                # íŒ¨í„´ 8: (ë‚´ì¼|ì˜¤ëŠ˜|ì–´ì œ) (ì œëª©) (ìˆì–´|ìˆì–´ìš”|ìˆìŠµë‹ˆë‹¤)
                elif len(groups) == 2 and "ìˆì–´" in t:
                    date_part = groups[0] if len(groups) > 0 else ""
                    title_part = groups[1] if len(groups) > 1 else ""
                    time_part = ""
                
                    # âœ… ì¼ì • ì •ë³´ ì •ë¦¬ ë° ì €ì¥
                    if title_part or date_part:
                        # ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ ì œê±°
                        if title_part:
                            title_clean = re.sub(r"^(ëŠ”|ì€|ì´|ê°€|ì„|ë¥¼)\s*", "", title_part.strip())
                            title_clean = re.sub(r"(ê°€|ì´|ì„|ë¥¼)\s*$", "", title_clean.strip())
                        else:
                            # ì œëª©ì´ ì—†ìœ¼ë©´ ë‚ ì§œ ì •ë³´ë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                            title_clean = date_part if date_part else "ì¼ì •"
                        
                        # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                        if not date_part:
                            date_match = re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆì£¼|ë‹¤ìŒì£¼|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ)", t)
                            if date_match:
                                date_part = date_match.group(1)
                            else:
                                date_part = "ì˜¤ëŠ˜"
                        
                        schedule_info = {
                            "ì œëª©": title_clean,
                            "ë‚ ì§œ": date_part,
                            "ì‹œê°„": time_part if time_part else ""
                        }
                        out.setdefault("user.ì¼ì •", []).append(schedule_info)
                        print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì¶”ì¶œ: {schedule_info}")
                        # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ ë¬¼ê±´ ì—”í‹°í‹° ì œê±° (ì´ë¯¸ ì¶”ê°€ë˜ì—ˆë‹¤ë©´)
                        if "user.ë¬¼ê±´" in out:
                            print(f"[DEBUG] ì¼ì • ì—”í‹°í‹° ì €ì¥ë¨ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
                            out.pop("user.ë¬¼ê±´", None)
                        # âœ… ì¼ì •ì´ ì €ì¥ë˜ì—ˆìœ¼ë©´ í•¨ìˆ˜ ì¢…ë£Œ (ë¬¼ê±´ ì¶”ì¶œ ë°©ì§€)
                        return out

            # âœ… ìƒì¼ ì¶”ì¶œ ë³´ê°•
            birthday_patterns = [
                r"ìƒì¼.*?(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼)",
                r"(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼).*?ìƒì¼",
                r"ë‚´\s*ìƒì¼.*?(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼)",
                r"(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼).*?ê¸°ì–µ",
            ]
            for p in birthday_patterns:
                m = re.search(p, t)
                if m:
                    out.setdefault("user.ê¸°ë…ì¼", []).append({
                        "ê´€ê³„": "ì‚¬ìš©ì", "ì œëª©": "ìƒì¼", "ë‚ ì§œ": m.group(1)
                    })
                    break
            
            # ë‹¤ë¥¸ ê¸°ë…ì¼ë“¤
            m = re.search(r"(ì œì‚¬|ê¸°ì¼|ê²°í˜¼ê¸°ë…ì¼).*?(\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼)", t)
            if m:
                out.setdefault("user.ê¸°ë…ì¼", []).append({
                    "ê´€ê³„": "",
                    "ì œëª©": m.group(1),
                    "ë‚ ì§œ": m.group(2)
                })

            # ì·¨ë¯¸
            m = re.search(r"ì·¨ë¯¸(?:ëŠ”|ê°€)?\s*([ê°€-í£A-Za-z0-9 ]+)", t)
            if m:
                hobby = re.sub(r"(ì´ì•¼|ì•¼|ì…ë‹ˆë‹¤|ì˜ˆìš”|ì—ìš”)$", "", m.group(1)).strip()
                if hobby:
                    out.setdefault("user.ì·¨ë¯¸", []).append({"ì´ë¦„": hobby})

            # âœ… ì·¨í–¥ (íŒ¨í„´ í™•ì¥)
            preference_patterns = [
                r"(?:ë‚˜ëŠ”|ë‚œ|ì „|ì €ëŠ”)?\s*([ê°€-í£A-Za-z0-9 ]+?)\s*(?:ì¢‹ì•„í•´|ì¢‹ì•„í•©ë‹ˆë‹¤|ì¢‹ì•„í•¨|ì¢‹ì•„|ì„ í˜¸í•´|ì„ í˜¸í•©ë‹ˆë‹¤)",
                r"([ê°€-í£A-Za-z0-9 ]+?)\s*(?:ê°€|ì´)\s*(?:ì·¨í–¥ì´ì•¼|ì·¨í–¥ì´ì—ìš”|ì·¨í–¥ì…ë‹ˆë‹¤|ì·¨í–¥ì´ì—ìš”)",
                r"([ê°€-í£A-Za-z0-9 ]+?)\s*(?:ë¥¼|ì„)\s*(?:ì¢‹ì•„í•´|ì¢‹ì•„í•©ë‹ˆë‹¤|ì¢‹ì•„í•¨|ì¢‹ì•„|ì„ í˜¸í•´|ì„ í˜¸í•©ë‹ˆë‹¤)",
                r"([ê°€-í£A-Za-z0-9 ]+?)\s*(?:ë¥¼|ì„)\s*(?:ì„ í˜¸í•´|ì„ í˜¸í•©ë‹ˆë‹¤|ì„ í˜¸í•¨|ì„ í˜¸)"
            ]
            for pattern in preference_patterns:
                m = re.search(pattern, t)
                if m:
                    val = m.group(1).strip()
                    # ì¡°ì‚¬ ì œê±° (ë¥¼, ì„, ê°€, ì´)
                    val = re.sub(r'(ë¥¼|ì„|ê°€|ì´)$', '', val).strip()
                    # "ë‚˜ëŠ”", "ë‚œ", "ì „", "ì €ëŠ”" ì œê±°
                    val = re.sub(r'^(ë‚˜ëŠ”|ë‚œ|ì „|ì €ëŠ”)\s*', '', val).strip()
                    if val and val not in STOPWORDS:
                        out.setdefault("user.ì·¨í–¥", []).append({"ì¢…ë¥˜": "", "ê°’": val})
                    break

            # ì•½ ë³µìš© ì •ë³´ ì¶”ì¶œ
            medicine_patterns = [
                r"([ê°€-í£]+ì•½)\s*(?:ë¨¹|ë³µìš©|ë“œì…¨|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤)",
                r"(?:ë¨¹|ë³µìš©|ë“œì…¨|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤)\s*([ê°€-í£]+ì•½)",
                r"([ê°€-í£]+ì•½)\s*(?:ê³¼|ì™€)\s*([ê°€-í£]+ì•½)\s*(?:ë¨¹|ë³µìš©|ë“œì…¨|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤)",
                r"(?:í•˜ë£¨|ë§¤ì¼|ì¼ì¼)\s*(\d+)\s*(?:ë²ˆ|íšŒ|ì°¨)\s*(?:ì”©|ë§ˆë‹¤)\s*(?:ë¨¹|ë³µìš©|ë“œì…¨|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤)",
                r"(\d+)\s*(?:ì¼|ì£¼|ê°œì›”|ë…„)\s*(?:ë™ì•ˆ|ê°„)\s*(?:ë¨¹|ë³µìš©|ë“œì…¨|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤)"
            ]
            
            for pattern in medicine_patterns:
                m = re.search(pattern, t)
                if m:
                    if "ê³¼" in pattern or "ì™€" in pattern:
                        # ì—¬ëŸ¬ ì•½ë¬¼
                        med1 = m.group(1)
                        med2 = m.group(2)
                        out.setdefault("user.ì•½", []).append({
                            "ì•½ëª…": med1,
                            "ë³µìš©ëŸ‰": None,
                            "ë³µìš©ì£¼ê¸°": None,
                            "ë³µìš©ê¸°ê°„": None
                        })
                        out.setdefault("user.ì•½", []).append({
                            "ì•½ëª…": med2,
                            "ë³µìš©ëŸ‰": None,
                            "ë³µìš©ì£¼ê¸°": None,
                            "ë³µìš©ê¸°ê°„": None
                        })
                    elif "ë²ˆ" in pattern or "íšŒ" in pattern or "ì°¨" in pattern:
                        # ë³µìš© ì£¼ê¸°
                        frequency = m.group(1)
                        # ì´ì „ ì•½ ì •ë³´ì— ë³µìš© ì£¼ê¸° ì¶”ê°€
                        if "user.ì•½" in out and out["user.ì•½"]:
                            for med in out["user.ì•½"]:
                                med["ë³µìš©ì£¼ê¸°"] = f"í•˜ë£¨ {frequency}ë²ˆ"
                    elif "ì¼" in pattern or "ì£¼" in pattern or "ê°œì›”" in pattern or "ë…„" in pattern:
                        # ë³µìš© ê¸°ê°„
                        period = m.group(1) + ("ì¼" if "ì¼" in pattern else "ì£¼" if "ì£¼" in pattern else "ê°œì›”" if "ê°œì›”" in pattern else "ë…„")
                        # ì´ì „ ì•½ ì •ë³´ì— ë³µìš© ê¸°ê°„ ì¶”ê°€
                        if "user.ì•½" in out and out["user.ì•½"]:
                            for med in out["user.ì•½"]:
                                med["ë³µìš©ê¸°ê°„"] = period
                    else:
                        # ë‹¨ì¼ ì•½ë¬¼
                        med_name = m.group(1)
                        out.setdefault("user.ì•½", []).append({
                            "ì•½ëª…": med_name,
                            "ë³µìš©ëŸ‰": None,
                            "ë³µìš©ì£¼ê¸°": None,
                            "ë³µìš©ê¸°ê°„": None
                        })
                    break

            # ê±´ê°• ìƒíƒœ
            m = re.search(r"(ë‘í†µ|ë¨¸ë¦¬\s*ì•„í””|ê¸°ì¹¨|ì¬ì±„ê¸°|ì½§ë¬¼|í”¼ê³¤|ì–´ì§€ëŸ¼|ì—´|ë°œì—´|ë³µí†µ|ëª¸ì‚´)", t)
            if m:
                out.setdefault("user.ê±´ê°•ìƒíƒœ", []).append({
                    "ì¦ìƒ": m.group(1),
                    "ì •ë„": None,
                    "ê¸°ê°„": None,
                    "ê¸°íƒ€": None
                })

            # âœ… ì•½ë¬¼ íŒ¨í„´ (ì‹ì‚¬ë³´ë‹¤ ìš°ì„ )
            drug_patterns = [
                r"([ê°€-í£A-Za-z]+ì•½)(?:ì„|ë¥¼)?\s*(?:ë¨¹ì—ˆì–´|ë¨¹ì—ˆì–´ìš”|ë¨¹ì—ˆìŠµë‹ˆë‹¤|ë¨¹ìŒ|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤|ë“œì‹¬|ë³µìš©í–ˆì–´|ë³µìš©í–ˆì–´ìš”|ë³µìš©í–ˆìŠµë‹ˆë‹¤|ë³µìš©í•¨)",
                r"(?:ë¨¹ì—ˆì–´|ë¨¹ì—ˆì–´ìš”|ë¨¹ì—ˆìŠµë‹ˆë‹¤|ë¨¹ìŒ|ë“œì…¨ì–´|ë“œì…¨ì–´ìš”|ë“œì…¨ìŠµë‹ˆë‹¤|ë“œì‹¬|ë³µìš©í–ˆì–´|ë³µìš©í–ˆì–´ìš”|ë³µìš©í–ˆìŠµë‹ˆë‹¤|ë³µìš©í•¨)\s*([ê°€-í£A-Za-z]+ì•½)",
                r"([ê°€-í£A-Za-z]+ì•½)(?:ì„|ë¥¼)?\s*(?:ë¨¹ì–´|ë¨¹ì–´ìš”|ë¨¹ìŠµë‹ˆë‹¤|ë¨¹ì–´ì•¼|ë¨¹ì–´ì•¼í•´|ë¨¹ì–´ì•¼í•´ìš”|ë¨¹ì–´ì•¼í•©ë‹ˆë‹¤|ë¨¹ì–´ì•¼í•¨|ë³µìš©í•´|ë³µìš©í•´ìš”|ë³µìš©í•©ë‹ˆë‹¤|ë³µìš©í•´ì•¼|ë³µìš©í•´ì•¼í•´|ë³µìš©í•´ì•¼í•´ìš”|ë³µìš©í•´ì•¼í•©ë‹ˆë‹¤|ë³µìš©í•´ì•¼í•¨)",
                r"(?:ë¨¹ì–´|ë¨¹ì–´ìš”|ë¨¹ìŠµë‹ˆë‹¤|ë¨¹ì–´ì•¼|ë¨¹ì–´ì•¼í•´|ë¨¹ì–´ì•¼í•´ìš”|ë¨¹ì–´ì•¼í•©ë‹ˆë‹¤|ë¨¹ì–´ì•¼í•¨|ë³µìš©í•´|ë³µìš©í•´ìš”|ë³µìš©í•©ë‹ˆë‹¤|ë³µìš©í•´ì•¼|ë³µìš©í•´ì•¼í•´|ë³µìš©í•´ì•¼í•´ìš”|ë³µìš©í•´ì•¼í•©ë‹ˆë‹¤|ë³µìš©í•´ì•¼í•¨)\s*([ê°€-í£A-Za-z]+ì•½)"
            ]
            
            # ì•½ë¬¼ íŒ¨í„´ ë¨¼ì € ì²´í¬ (LLMë³´ë‹¤ ìš°ì„ )
            for pattern in drug_patterns:
                m = re.search(pattern, t)
                if m:
                    drug_name = m.group(1).strip()
                    print(f"[DEBUG] ì•½ë¬¼ íŒ¨í„´ ê°ì§€: '{drug_name}'")
                    return {"user.ì•½ë¬¼": [{"ì•½ëª…": drug_name, "ë³µìš©ì¼": "ì˜¤ëŠ˜"}]}
        
            # âœ… ì‹ì‚¬ (ì‹œê°„ í¬í•¨ + ìë™ íŒŒì‹± + ë°¥ ì²˜ë¦¬) - ê°œì„ ëœ ë²„ì „
            # ì•½ ë³µìš© ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‹ì‚¬ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ (ì•½ ë³µìš© ì²´í¬ë¥¼ ë¨¼ì € í•´ì•¼ í•¨)
            # âœ… "ì•½ì†"ì€ ì¼ì •ì´ë¯€ë¡œ ì•½ë¬¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            has_medicine_keyword = any(keyword in t for keyword in MEDICINE_KEYWORDS)
            # "ì•½" í‚¤ì›Œë“œ ì²´í¬ (ë‹¨, "ì•½ì†"ì€ ì œì™¸ - ì•½ì†ì€ ì¼ì •)
            if not has_medicine_keyword and "ì•½" in t and "ì•½ì†" not in t:
                # "~ì•½" íŒ¨í„´ (í˜ˆì••ì•½, ê°ê¸°ì•½ ë“±) ë˜ëŠ” "ì•½ ë¨¹" íŒ¨í„´ ì²´í¬
                if re.search(r"[ê°€-í£A-Za-z]+ì•½|ì•½\s*[ë¨¹ë“œ]", t):
                    has_medicine_keyword = True
            # "~ì•½" íŒ¨í„´ ì²´í¬ (ë‹¨, "ì•½ì†"ì€ ì œì™¸)
            if not has_medicine_keyword:
                if re.search(r"[ê°€-í£A-Za-z]+ì•½(?!ì†)", t):
                    has_medicine_keyword = True
        
            if "ë¨¹" in t and not has_medicine_keyword:
                # "ì•ˆ ë¨¹ì—ˆì–´", "êµ¶ì—ˆì–´" íŒ¨í„´ ì²´í¬ (skip ì²˜ë¦¬)
                skip_patterns = [
                    r"(ì•„ë¬´ê²ƒë„|ì•„ë¬´ê²ƒ)\s*ì•ˆ\s*ë¨¹",
                    r"ì•ˆ\s*ë¨¹ì—ˆì–´",
                    r"êµ¶ì—ˆì–´",
                    r"ë¨¹ì§€\s*ì•Šì•˜ì–´",
                    r"ì‹ì‚¬\s*ì•ˆ\s*í–ˆì–´"
                ]
                
                for skip_pattern in skip_patterns:
                    if re.search(skip_pattern, t):
                        # ì‹ì‚¬ skip - ì—”í‹°í‹° ìƒì„±í•˜ì§€ ì•ŠìŒ
                        break
                else:
                    # ìƒˆë¡œìš´ ì‹ì‚¬ ì—”í‹°í‹° ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
                    meal_data = self._extract_meal_entity(t)
                    if meal_data.get("ë¼ë‹ˆ") or meal_data.get("ë©”ë‰´"):
                        # ê¸°ì¡´ íŒ¨í„´ê³¼ í˜¸í™˜ë˜ë„ë¡ ë³€í™˜
                        # ë‚ ì§œê°€ Noneì´ë©´ "ì˜¤ëŠ˜"ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
                        meal_date = meal_data.get("ë‚ ì§œ") or "ì˜¤ëŠ˜"
                        meal_entity = {
                            "ë¼ë‹ˆ": meal_data.get("ë¼ë‹ˆ"),
                            "ë©”ë‰´": meal_data.get("ë©”ë‰´", []),
                            "ë‚ ì§œ": meal_date,
                            "ì‹œê°„": None  # ì‹œê°„ì€ ë³„ë„ ì¶”ì¶œ
                        }
                        
                        # ì‹œê°„ ìë™ ì¶”ì¶œ
                        extracted_time = self._extract_time_from_text(t)
                        if extracted_time:
                            meal_entity["ì‹œê°„"] = extracted_time
                        
                        out.setdefault("user.ì‹ì‚¬", []).append(meal_entity)
                        print(f"[DEBUG] ì‹ì‚¬ ì—”í‹°í‹° ì¶”ì¶œ (ê°œì„ ): {meal_entity}")
                        return out
                    else:
                        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
                        # íŒ¨í„´ 1: "ì˜¤ëŠ˜ ì ì‹¬ í–„ë²„ê±° ë¨¹ì—ˆì–´" (ë©”ë‰´ í¬í•¨) - ì¡°ì‚¬ ì œì™¸
                        m1 = re.search(r"(ì˜¤ëŠ˜|ì–´ì œ|ë‚´ì¼)?\s*(ì•„ì¹¨|ì ì‹¬|ì €ë…).*?([ê°€-í£]+?)\s*(?:ë¨¹|ë¨¹ì–´|ë¨¹ì—ˆ|ë¨¹ì—ˆì–´|ë¨¹ì—ˆì–´ìš”|ë¨¹ì—ˆìŠµë‹ˆë‹¤)", t)
                    # íŒ¨í„´ 1-1: "ì ì‹¬ì—ëŠ” ê·¸ëƒ¥ ì´ˆì½” íŒŒì´ ë¨¹ì—ˆì–´" (ì—ëŠ” í¬í•¨) - ë” ìœ ì—°í•œ íŒ¨í„´
                    m1_1 = re.search(r"(ì˜¤ëŠ˜|ì–´ì œ|ë‚´ì¼)?\s*(ì•„ì¹¨|ì ì‹¬|ì €ë…)ì—\s*([ê°€-í£]+?)\s*(?:ë¨¹|ë¨¹ì–´|ë¨¹ì—ˆ|ë¨¹ì—ˆì–´|ë¨¹ì—ˆì–´ìš”|ë¨¹ì—ˆìŠµë‹ˆë‹¤)", t)
                    # íŒ¨í„´ 1-2: "ì•„ì¹¨ì—ëŠ” ë–¡ë§Œë‘£êµ­ë¨¹ì–´ì½" ê°™ì€ ê²½ìš°ë¥¼ ìœ„í•œ ì¶”ê°€ íŒ¨í„´
                    m1_2 = re.search(r"(ì˜¤ëŠ˜|ì–´ì œ|ë‚´ì¼)?\s*(ì•„ì¹¨|ì ì‹¬|ì €ë…)ì—\s*([ê°€-í£]+?)(?:ë¨¹ì–´|ë¨¹ì—ˆ|ë¨¹ì—ˆì–´|ë¨¹ì—ˆì–´ìš”|ë¨¹ì—ˆìŠµë‹ˆë‹¤|ë¨¹ì–´ì½)", t)
                    # íŒ¨í„´ 2: "ì €ë… ë¨¹ì—ˆì–´" (ë©”ë‰´ ì—†ìŒ) - ë©”ë‰´ê°€ ì—†ëŠ” ê²½ìš°ë§Œ ë§¤ì¹˜
                    m2 = re.search(r"(ì˜¤ëŠ˜|ì–´ì œ|ë‚´ì¼)?\s*(ì•„ì¹¨|ì ì‹¬|ì €ë…)\s*ë¨¹", t)
                    # íŒ¨í„´ 2-1: "ì ì‹¬ì—ëŠ” ë¨¹ì—ˆì–´" (ì—ëŠ” í¬í•¨, ë©”ë‰´ ì—†ìŒ)
                    m2_1 = re.search(r"(ì˜¤ëŠ˜|ì–´ì œ|ë‚´ì¼)?\s*(ì•„ì¹¨|ì ì‹¬|ì €ë…)ì—\s*ë¨¹", t)
                    # íŒ¨í„´ 3: "ë°¥ ë¨¹ì—ˆì–´" (ë¼ë‹ˆ ì—†ìŒ, ë©”ë‰´ë§Œ)
                    m3 = re.search(r"([ê°€-í£]+)\s*ë¨¹", t)
                    # íŒ¨í„´ 3-1: "ë–¡ë§Œë‘£êµ­ ë¨¹ì—ˆê³ , 7ì‹œë°˜ì— ë¨¹ì—ˆì–´" (ë©”ë‰´ + ì‹œê°„)
                    m3_1 = re.search(r"([ê°€-í£]+)\s*ë¨¹ì—ˆê³ ,?\s*(\d{1,2}ì‹œ\s*ë°˜?)\s*ì—?\s*ë¨¹", t)
            
                    if m3_1:
                        # íŒ¨í„´ 3-1: "ë–¡ë§Œë‘£êµ­ ë¨¹ì—ˆê³ , 7ì‹œë°˜ì— ë¨¹ì—ˆì–´"
                        # print(f"[DEBUG] íŒ¨í„´ 3-1 ë§¤ì¹­: ë©”ë‰´={m3_1.group(1)}, ì‹œê°„={m3_1.group(2)}")
                        menu_item = m3_1.group(1).strip()
                        extracted_time = m3_1.group(2).strip()
                        
                        # "ì•½" ë“±ì€ ì‹ì‚¬ ë©”ë‰´ì—ì„œ ì œì™¸ (ë°¥ì€ ìœ íš¨í•œ ë©”ë‰´)
                        # "ì‹í›„ì—", "ì‹ì „ì—" ê°™ì€ ì•½ ë³µìš© ê´€ë ¨ í‘œí˜„ë„ ì œì™¸
                        if menu_item not in {"ìŒì‹", "ë­”ê°€", "ë­", "ì•½", "ì•½ë¬¼", "ì•½í’ˆ", "ì‹í›„ì—", "ì‹ì „ì—", "ì‹í›„", "ì‹ì „"}: 
                            # ì‹œê°„ëŒ€ ê¸°ë°˜ìœ¼ë¡œ ë¼ë‹ˆ ì¶”ë¡ 
                            inferred_meal = None
                            if extracted_time:
                                hour = self._extract_hour_from_time(extracted_time)
                                if hour and 6 <= hour < 11:
                                    inferred_meal = "ì•„ì¹¨"
                                elif hour and 11 <= hour < 15:
                                    inferred_meal = "ì ì‹¬"
                                elif hour and 15 <= hour < 22:
                                    inferred_meal = "ì €ë…"
                            
                            # ì‹œê°„ìœ¼ë¡œ ì¶”ë¡  ì•ˆë˜ë©´ ë¼ë‹ˆë¥¼ nullë¡œ ì„¤ì • (ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ)
                            if not inferred_meal:
                                inferred_meal = None
                        
                            meal_entity = {
                                "ë¼ë‹ˆ": inferred_meal, "ë©”ë‰´": [menu_item], "ë‚ ì§œ": "ì˜¤ëŠ˜", "ì‹œê°„": extracted_time
                            }
                            # print(f"[DEBUG] íŒ¨í„´ 3-1 ì‹ì‚¬ ì—”í‹°í‹° ìƒì„±: {meal_entity}")
                            out.setdefault("user.ì‹ì‚¬", []).append(meal_entity)
                    elif m2 or m2_1:
                        # íŒ¨í„´ 2: "ì €ë… ë¨¹ì—ˆì–´" (ë©”ë‰´ ì—†ìŒ) - ì‹œê°„ ì •ë³´ë§Œ ìˆëŠ” ê²½ìš°
                        if m2_1:
                            rel_date, meal = m2_1.group(1), m2_1.group(2)
                        else:
                            rel_date, meal = m2.group(1), m2.group(2)
                        
                        # ì‹œê°„ ìë™ ì¶”ì¶œ
                        extracted_time = self._extract_time_from_text(t)
                        
                        # ì´ì „ ëŒ€í™”ì—ì„œ ì‹œê°„ ì •ë³´ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸
                        if not extracted_time and session_id in self.time_context:
                            context = self.time_context[session_id]
                            if context.get("last_meal") == meal and context.get("last_time"):
                                extracted_time = context["last_time"]
                                logger.debug(f"ì´ì „ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì •ë³´ ì—°ê²°: {meal} {extracted_time}")
                        
                        # ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                        if extracted_time:
                            if session_id not in self.time_context:
                                self.time_context[session_id] = {}
                            self.time_context[session_id]["last_time"] = extracted_time
                            self.time_context[session_id]["last_meal"] = meal
                            self.time_context[session_id]["last_menu"] = None  # ë©”ë‰´ëŠ” ë¹„ì–´ìˆìŒ
                        
                        out.setdefault("user.ì‹ì‚¬", []).append({
                            "ë¼ë‹ˆ": meal, "ë©”ë‰´": [], "ë‚ ì§œ": rel_date, "ì‹œê°„": extracted_time
                        })
                    elif m1 or m1_1 or m1_2:
                        if m1_2:
                            rel_date, meal, menu_raw = m1_2.group(1), m1_2.group(2), m1_2.group(3)
                        elif m1_1:
                            rel_date, meal, menu_raw = m1_1.group(1), m1_1.group(2), m1_1.group(3)
                        else:
                            rel_date, meal, menu_raw = m1.group(1), m1.group(2), m1.group(3)
                        
                        # ë©”ë‰´ ì¶”ì¶œ ì‹œ ë¶ˆìš©ì–´ í•„í„°ë§ ê°•í™” (ë³µí•© ë©”ë‰´ëª… ë³´ì¡´)
                        # ë¨¼ì € ë³µí•© ë©”ë‰´ëª…ì„ ë³´ì¡´í•˜ê¸° ìœ„í•´ íŠ¹ë³„í•œ íŒ¨í„´ ì²˜ë¦¬
                        menu_raw_processed = menu_raw
                        
                        # ë³µí•© ë©”ë‰´ëª… íŒ¨í„´ ë³´ì¡´ (ì˜ˆ: "ìƒ¤ì¸ ë¨¸ìŠ¤ì¼“", "ì¹˜í‚¨ ë²„ê±°", "í”¼ì ìŠ¬ë¼ì´ìŠ¤" ë“±)
                        complex_menu_patterns = [
                            r"ìƒ¤ì¸\s*ë¨¸ìŠ¤ì¼“", r"ì¹˜í‚¨\s*ë²„ê±°", r"í”¼ì\s*ìŠ¬ë¼ì´ìŠ¤", r"í–„\s*ë²„ê±°", r"ì¹˜ì¦ˆ\s*ë²„ê±°",
                            r"ê¹€ì¹˜\s*ì°Œê°œ", r"ëœì¥\s*ì°Œê°œ", r"ë¯¸ì—­\s*êµ­", r"ê³„ë€\s*ë§ì´", r"ê¹€ì¹˜\s*ì „"
                        ]
                        
                        for pattern in complex_menu_patterns:
                            menu_raw_processed = re.sub(pattern, lambda m: m.group(0).replace(" ", "_"), menu_raw_processed)
                        
                        # ì´ì œ ë¶„í•  (ê³µë°±ì€ ì œì™¸í•˜ê³  êµ¬ë¶„ìë§Œ ì‚¬ìš©)
                        menu_candidates = [x.strip().replace("_", " ") for x in re.split(r"[,ì™€ê³¼ë‘ë°]", menu_raw_processed) if x.strip()]
                        
                        # ë©”ë‰´ ë¶ˆìš©ì–´ í™•ì¥
                        menu_stopwords = {
                            "ê·¸ëƒ¥", "ì—ëŠ”", "ì—ì„œ", "ì„", "ë¥¼", "ì´", "ê°€", "ì€", "ëŠ”", "ì—", "ì˜", "ë¡œ", "ìœ¼ë¡œ",
                        "í•˜ê³ ", "í•˜ë©´ì„œ", "ë¨¹ì—ˆì–´", "ë¨¹ì—ˆê³ ", "ë¨¹ì—ˆëŠ”ë°", "ë¨¹ì—ˆì–´ìš”", "ë¨¹ì—ˆìŠµë‹ˆë‹¤",
                        "ë“œì…¨ì–´", "ë“œì…¨ê³ ", "ë“œì…¨ëŠ”ë°", "ë“œì…¨ì–´ìš”", "ë“œì…¨ìŠµë‹ˆë‹¤",
                        "í–ˆì–´", "í–ˆê³ ", "í–ˆëŠ”ë°", "í–ˆì–´ìš”", "í–ˆìŠµë‹ˆë‹¤",
                        "ìŒì‹", "ë­”ê°€", "ë­", "ì•½", "ì•½ë¬¼", "ì•½í’ˆ", "ê°„ì‹", "ë””ì €íŠ¸"
                        }
                        
                        menus = [x for x in menu_candidates 
                                if (x not in STOPWORDS and x not in menu_stopwords and 
                                    len(x) > 1 and not re.match(r'^[0-9]+$', x) and
                                    not re.match(r'^[ê°€-í£]{1}$', x))]  # í•œ ê¸€ì ë‹¨ì–´ ì œì™¸
                        
                        # ì‹œê°„ ìë™ ì¶”ì¶œ (ì´ì „ ì»¨í…ìŠ¤íŠ¸ í™œìš©)
                        extracted_time = self._extract_time_from_text(t)
                        
                        # ì´ì „ ëŒ€í™”ì—ì„œ ì‹œê°„ ì •ë³´ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸
                        if not extracted_time and session_id in self.time_context:
                            context = self.time_context[session_id]
                            if context.get("last_meal") == meal and context.get("last_time"):
                                extracted_time = context["last_time"]
                                logger.debug(f"ì´ì „ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì •ë³´ ì—°ê²°: {meal} {extracted_time}")
                        
                        # ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                        if extracted_time:
                            if session_id not in self.time_context:
                                self.time_context[session_id] = {}
                            self.time_context[session_id]["last_time"] = extracted_time
                            self.time_context[session_id]["last_meal"] = meal
                        
                        out.setdefault("user.ì‹ì‚¬", []).append({
                            "ë¼ë‹ˆ": meal, "ë©”ë‰´": menus, "ë‚ ì§œ": rel_date, "ì‹œê°„": extracted_time
                        })
                    elif m3:
                        menu_item = m3.group(1).strip()
                        
                        # ì‹œê°„ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš° ë©”ë‰´ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                        extracted_time = self._extract_time_from_text(t)
                        if extracted_time and menu_item in {"ì‹œì—", "ì‹œ", "ë¶„", "ì˜¤ì „", "ì˜¤í›„", "ìƒˆë²½", "ë°¤"}:
                            # ì‹œê°„ ì •ë³´ë§Œ ìˆëŠ” ê²½ìš° - ë©”ë‰´ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
                            # ì´ì „ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë¼ë‹ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                            if session_id in self.time_context:
                                context = self.time_context[session_id]
                                if context.get("last_meal"):
                                    meal = context["last_meal"]
                                    out.setdefault("user.ì‹ì‚¬", []).append({
                                        "ë¼ë‹ˆ": meal, "ë©”ë‰´": [], "ë‚ ì§œ": "ì˜¤ëŠ˜", "ì‹œê°„": extracted_time
                                    })
                                    # ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                                    self.time_context[session_id]["last_time"] = extracted_time
                                    return out
                        
                        # "ì•½" ë“±ì€ ì‹ì‚¬ ë©”ë‰´ì—ì„œ ì œì™¸ (ë°¥ì€ ìœ íš¨í•œ ë©”ë‰´)
                        # "ì‹í›„ì—", "ì‹ì „ì—" ê°™ì€ ì•½ ë³µìš© ê´€ë ¨ í‘œí˜„ë„ ì œì™¸
                        if menu_item not in {"ìŒì‹", "ë­”ê°€", "ë­", "ì•½", "ì•½ë¬¼", "ì•½í’ˆ", "ì‹œì—", "ì‹œ", "ë¶„", "ì˜¤ì „", "ì˜¤í›„", "ìƒˆë²½", "ë°¤", "ì‹í›„ì—", "ì‹ì „ì—", "ì‹í›„", "ì‹ì „"}: 
                            extracted_time = self._extract_time_from_text(t)
                            
                            # ì‹œê°„ëŒ€ ê¸°ë°˜ìœ¼ë¡œ ë¼ë‹ˆ ì¶”ë¡ 
                            inferred_meal = None
                            if extracted_time:
                                hour = self._extract_hour_from_time(extracted_time)
                                if hour and 6 <= hour < 11:
                                    inferred_meal = "ì•„ì¹¨"
                                elif hour and 11 <= hour < 15:
                                    inferred_meal = "ì ì‹¬"
                                elif hour and 15 <= hour < 22:
                                    inferred_meal = "ì €ë…"
                            
                            # ì‹œê°„ìœ¼ë¡œ ì¶”ë¡  ì•ˆë˜ë©´ ë¼ë‹ˆë¥¼ nullë¡œ ì„¤ì • (ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ)
                            if not inferred_meal:
                                inferred_meal = None
                            
                            out.setdefault("user.ì‹ì‚¬", []).append({
                                "ë¼ë‹ˆ": inferred_meal, "ë©”ë‰´": [menu_item], "ë‚ ì§œ": "ì˜¤ëŠ˜", "ì‹œê°„": extracted_time
                            })

            # âœ… ë¬¼ê±´ ì¶”ì¶œ (ëª…ë ¹ íŒ¨í„´ í¬í•¨)
            # âœ… ì¼ì • ì—”í‹°í‹°ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ë¬¼ê±´ ì¶”ì¶œ ê±´ë„ˆë›°ê¸° (ì¼ì • ìš°ì„ )
            if "user.ë¬¼ê±´" not in out and "user.ì¼ì •" not in out:
                try:
                    # 1. ìœ„ì¹˜ í¬í•¨ ì¼€ì´ìŠ¤ (ê¸°ì¡´)
                    item_location_result = self._extract_item_location_rule(t)
                    if item_location_result:
                        out.update(item_location_result)
                    else:
                        # 2. ëª…ë ¹ íŒ¨í„´ ì¼€ì´ìŠ¤ (ìƒˆë¡œ ì¶”ê°€)
                        item_command_result = self._extract_item_command_rule(t)
                        if item_command_result:
                            out.update(item_command_result)
                except Exception as e:
                    print(f"[WARN] ë¬¼ê±´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"[ERROR] _rule_based_extract ì „ì²´ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return out  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

        # âœ… ì¼ì • ì—”í‹°í‹°ê°€ ì €ì¥ë˜ì—ˆìœ¼ë©´ ë¬¼ê±´ ì—”í‹°í‹° ì œê±° (ìµœì¢… í™•ì¸)
        if "user.ì¼ì •" in out and "user.ë¬¼ê±´" in out:
            print(f"[DEBUG] [FINAL CHECK] ì¼ì • ì—”í‹°í‹° ì¡´ì¬ â†’ ë¬¼ê±´ ì—”í‹°í‹° ì œê±°: {out.get('user.ë¬¼ê±´')}")
            out.pop("user.ë¬¼ê±´", None)
        
        return out

    def _extract_entities_with_llm(self, user_input: str, session_id: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:
        """LLM ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ (ë¬¸ë§¥ ì´í•´ ê¸°ë°˜)"""
        try:
            # LLMì—ê²Œ ë¬¸ë§¥ì„ ì´í•´í•´ì„œ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ë„ë¡ ìš”ì²­
            prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ë°œí™”ì—ì„œ ê°œì¸ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë°œí™”: "{user_input}"

ë‹¤ìŒ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ì¶œí•˜ì„¸ìš”:
- ë‚˜ì´: "16ì‚´", "20ì„¸" ë“± (ìˆ«ì+ì‚´/ì„¸ í˜•ì‹)
- í•™êµ: "ê³¡ë°˜ ì¤‘í•™êµ", "ì„œìš¸ëŒ€í•™êµ", "ì„œìš¸ê³ ë“±í•™êµ" ë“± (í•™êµëª… ì „ì²´ ì¶”ì¶œ)
  * ë‹¤ì–‘í•œ í‘œí˜„ì„ ì´í•´í•˜ì„¸ìš”: "ë‹¤ë…€", "ë‹¤ë‹ˆê³ ", "ì¬í•™ì¤‘", "ì¡¸ì—…í–ˆì–´" ë“±
  * ì˜ˆ: "ë‚˜ëŠ” ì„œìš¸ê³ ë“±í•™êµì— ë‹¤ë…€" â†’ "ì„œìš¸ê³ ë“±í•™êµ"
  * í•™êµëª…ë§Œ ì¶”ì¶œí•˜ê³  ì¡°ì‚¬("ì—", "ì—ì„œ")ëŠ” ì œì™¸í•˜ì„¸ìš”
- ì§ì—…: "í•™ìƒ", "íšŒì‚¬ì›", "ì„ ìƒë‹˜" ë“±
- ì·¨ë¯¸: "ë…ì„œ", "ì˜í™”ê°ìƒ" ë“±

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "ì‚¬ìš©ì": [{{"ë‚˜ì´": "16ì‚´", "í•™êµ": "ì„œìš¸ê³ ë“±í•™êµ", "ì§ì—…": "í•™ìƒ", "ì·¨ë¯¸": "ë…ì„œ"}}]
}}

ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ í‘œì‹œ:
{{
    "ì‚¬ìš©ì": []
}}
"""
            
            response = self.llm.invoke(prompt)
            result_text = response.content.strip()
            print(f"[DEBUG] LLM ì›ë³¸ ì‘ë‹µ: {result_text}")
            
            # JSON íŒŒì‹± (```json ë§ˆí¬ë‹¤ìš´ ì œê±°)
            import json
            import re
            
            # ```jsonê³¼ ``` ì œê±°
            json_text = re.sub(r'```json\s*', '', result_text)
            json_text = re.sub(r'```\s*$', '', json_text).strip()
            
            try:
                entities = json.loads(json_text)
                print(f"[DEBUG] LLM ì—”í‹°í‹° ì¶”ì¶œ ê²°ê³¼: {entities}")
                
                # user. ì ‘ë‘ì‚¬ ì¶”ê°€í•˜ì—¬ ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜
                formatted_entities = {}
                for entity_type, entity_list in entities.items():
                    if entity_list:  # ë¹ˆ ë°°ì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                        formatted_entities[f"user.{entity_type}"] = entity_list
                
                return formatted_entities
                
            except json.JSONDecodeError as e:
                print(f"[DEBUG] LLM JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                return {}
                
        except Exception as e:
            print(f"[DEBUG] LLM ì—”í‹°í‹° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    # (ì‚¬ì „) ì—”í‹°í‹° ì¶”ì¶œ: LLM â†’ Rule â†’ Merge ìˆœì„œ
    def _pre_extract_entities(self, user_input: str, session_id: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:
        """ì—”í‹°í‹° ì¶”ì¶œ: LLM ìš°ì„  â†’ Rule ë³´ì™„ + Slot-filling ì²´í¬ (ë¬¸ë§¥ ì´í•´ ê¸°ë°˜)"""
        merged: Dict[str, List[Dict[str, Any]]] = {}

        # 1ï¸âƒ£ êµ¬ì¡°í™”ëœ ì—”í‹°í‹° ì¶”ì¶œ LLM ì²´ì¸ ì‚¬ìš© (ì•½, ì¼ì •, ì‹ì‚¬ ë“± ëª¨ë“  ì—”í‹°í‹°)
        print(f"[DEBUG] LLM ì—”í‹°í‹° ì¶”ì¶œ ì‹œì‘ (entity_chain): '{user_input}'")
        structured_llm_out = {}
        try:
            if hasattr(self, 'entity_chain') and self.entity_chain:
                result = self.entity_chain.invoke({"utterance": user_input})
                print(f"[DEBUG] entity_chain ì›ë³¸ ì‘ë‹µ: {result}")
                
                # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (user. ì ‘ë‘ì‚¬ ì¶”ê°€)
                if isinstance(result, dict):
                    for key, value in result.items():
                        if key.startswith("user."):
                            structured_llm_out[key] = value if isinstance(value, list) else [value]
                        else:
                            # ì•½, ì¼ì • ë“±ì€ user. ì ‘ë‘ì‚¬ ì¶”ê°€
                            entity_key = f"user.{key}" if key in ["ì•½", "ì¼ì •", "ì‹ì‚¬", "ê°€ì¡±", "ë¬¼ê±´", "ê¸°ë…ì¼", "ì·¨ë¯¸", "ì·¨í–¥", "ê±´ê°•ìƒíƒœ"] else f"user.{key}"
                            structured_llm_out[entity_key] = value if isinstance(value, list) else [value]
                    
                    print(f"[DEBUG] entity_chain ë³€í™˜ëœ ê²°ê³¼: {structured_llm_out}")
        except Exception as e:
            print(f"[WARN] entity_chain ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        # 2ï¸âƒ£ ì‚¬ìš©ì ì •ë³´ ì „ìš© LLM ì¶”ì¶œ (ì‚¬ìš©ì ì •ë³´ë§Œ í•„ìš”í•  ë•Œ)
        user_info_llm_out = {}
        try:
            user_info_llm_out = self._extract_entities_with_llm(user_input, session_id)
            print(f"[DEBUG] ì‚¬ìš©ì ì •ë³´ LLM ì¶”ì¶œ ê²°ê³¼: {user_info_llm_out}")
        except Exception as e:
            print(f"[WARN] ì‚¬ìš©ì ì •ë³´ LLM ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # 3ï¸âƒ£ ê²°ê³¼ ë³‘í•©: êµ¬ì¡°í™”ëœ ì—”í‹°í‹° ìš°ì„ , ì‚¬ìš©ì ì •ë³´ëŠ” ë³´ì™„
        if structured_llm_out:
            merged = structured_llm_out.copy()
            # ì‚¬ìš©ì ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if user_info_llm_out.get("user.ì‚¬ìš©ì"):
                merged["user.ì‚¬ìš©ì"] = user_info_llm_out["user.ì‚¬ìš©ì"]
        elif user_info_llm_out:
            merged = user_info_llm_out.copy()
        
        # 4ï¸âƒ£ LLM ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ rule-based ë³´ì™„
        if not merged or (not structured_llm_out and not user_info_llm_out):
            print(f"[DEBUG] LLM ê²°ê³¼ ì—†ìŒ ë˜ëŠ” ë¶€ì¡± â†’ rule-based fallback ì‹œë„")
            rule_out = self._rule_based_extract(user_input, session_id)
            print(f"[DEBUG] _pre_extract_entities rule_out (fallback): {rule_out}")
            
            # LLM ê²°ê³¼ì™€ rule-based ê²°ê³¼ ë³‘í•© (LLM ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ rule-basedë§Œ)
            if merged:
                # LLM ê²°ê³¼ì™€ rule-based ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±°)
                for key, value in rule_out.items():
                    if key not in merged:
                        merged[key] = value
                    else:
                        # ì¤‘ë³µ ì œê±°: ê¸°ì¡´ ì—”í‹°í‹°ì™€ ìƒˆ ì—”í‹°í‹° ë¹„êµ
                        existing = merged[key]
                        new_items = [item for item in value if item not in existing]
                        if new_items:
                            merged[key].extend(new_items)
            else:
                merged = rule_out.copy()  # rule-basedë§Œ ì‚¬ìš©
        
        # ì¬ì§ˆë¬¸ ì²´í¬
        for entity_key, entity_list in merged.items():
            for entity in entity_list:
                if isinstance(entity, dict) and "ì§ˆë¬¸" in entity:
                    print(f"[DEBUG] _pre_extract_entitiesì—ì„œ ì¬ì§ˆë¬¸ ë°œê²¬: {entity['ì§ˆë¬¸']}")
                    return {entity_key: [entity]}
        
        # 1.5ï¸âƒ£ Slot-filling ì²´í¬ (ì—”í‹°í‹° ì¶”ì¶œ ë‹¨ê³„ì—ì„œ)
        for entity_key, entity_list in merged.items():
            if entity_list:  # ì—”í‹°í‹°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²´í¬
                for entity in entity_list:
                    if isinstance(entity, dict):
                        # ì—”í‹°í‹° íƒ€ì… ì¶”ì¶œ (user.ì•½ â†’ ì•½)
                        entity_type = entity_key.replace("user.", "")
                        
                        # í•„ìˆ˜ í•„ë“œ í™•ì¸
                        missing_info = self._check_missing_fields(entity_type, entity)
                        if missing_info["has_missing"]:
                            print(f"[DEBUG] Slot-filling í•„ìš”: {entity_type} - {missing_info['missing_fields']}")
                            return {
                                "success": False,
                                "incomplete": True,
                                "entity_type": entity_type,
                                "message": missing_info["message"],
                                "pending_data": {
                                    "entity_type": entity_type,
                                    "new_data": entity,
                                    "missing_fields": missing_info["missing_fields"],
                                    "session_id": session_id
                                }
                            }
        
        # ì•½ë¬¼ íŒ¨í„´ ìš°ì„  ì²˜ë¦¬ (LLM ê²°ê³¼ë³´ë‹¤ ìš°ì„ )
        if "user.ì•½ë¬¼" in merged:
            print(f"[DEBUG] ì•½ë¬¼ íŒ¨í„´ ìš°ì„  ì²˜ë¦¬: {merged['user.ì•½ë¬¼']}")
            return merged
        
        # LLM ê²°ê³¼ ë°˜í™˜
        return merged

    def _dedup_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—”í‹°í‹° ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique = []
        for e in entities:
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ë ¬ëœ íŠœí”Œë¡œ ë³€í™˜í•˜ì—¬ ì¤‘ë³µ ì²´í¬ (ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜)
            def make_hashable(obj):
                if isinstance(obj, dict):
                    return tuple(sorted((k, make_hashable(v)) for k, v in obj.items()))
                elif isinstance(obj, list):
                    return tuple(make_hashable(item) for item in obj)
                else:
                    return obj
            
            key = make_hashable(e)
            if key not in seen:
                seen.add(key)
                unique.append(e)
        return unique

    def _dedup_drug_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì•½ ì—”í‹°í‹° ì¤‘ë³µ ì œê±° ë° ë³‘í•© (ì•½ëª… ê¸°ì¤€, ë³µìš© ì •ë³´ í¬í•¨)"""
        drug_dict = {}
        for e in entities:
            drug_name = e.get("ì•½ëª…", "")
            if not drug_name:
                continue
                
            if drug_name not in drug_dict:
                drug_dict[drug_name] = e
            else:
                # ê¸°ì¡´ ì—”í‹°í‹°ì™€ ìƒˆ ì—”í‹°í‹° ë³‘í•©
                existing = drug_dict[drug_name]
                merged = {"ì•½ëª…": drug_name}
                
                # ë³µìš© ì •ë³´ ë³‘í•©
                if existing.get("ë³µìš©") or e.get("ë³µìš©"):
                    merged["ë³µìš©"] = existing.get("ë³µìš©", []) + e.get("ë³µìš©", [])
                
                # ì‹ì‚¬ì™€ì˜ ê´€ê³„ ë³‘í•©
                if existing.get("ì‹ì‚¬ì™€ì˜ ê´€ê³„") or e.get("ì‹ì‚¬ì™€ì˜ ê´€ê³„"):
                    merged["ì‹ì‚¬ì™€ì˜ ê´€ê³„"] = e.get("ì‹ì‚¬ì™€ì˜ ê´€ê³„") or existing.get("ì‹ì‚¬ì™€ì˜ ê´€ê³„")
                
                # ë³µìš© ê¸°ê°„ ë³‘í•©
                if existing.get("ë³µìš© ê¸°ê°„") or e.get("ë³µìš© ê¸°ê°„"):
                    merged["ë³µìš© ê¸°ê°„"] = e.get("ë³µìš© ê¸°ê°„") or existing.get("ë³µìš© ê¸°ê°„")
                
                # ê¸°íƒ€ í•„ë“œ ë³‘í•©
                for key, value in existing.items():
                    if key not in merged and value:
                        merged[key] = value
                for key, value in e.items():
                    if key not in merged and value:
                        merged[key] = value
                
                drug_dict[drug_name] = merged
        
        return list(drug_dict.values())

    def _is_complete_entity(self, entity_key: str, entity: dict) -> bool:
        """ì—”í‹°í‹°ê°€ ì™„ì „í•œì§€ í™•ì¸ (í•„ìˆ˜ í•„ë“œê°€ ëª¨ë‘ ìˆëŠ”ì§€)"""
        required_fields = {
            "user.ì‚¬ìš©ì": ["ì´ë¦„"],
            "user.ì•½": ["ì•½ëª…"],
            "user.ì¼ì •": ["ì œëª©", "ë‚ ì§œ"],
            "user.ê¸°ë…ì¼": ["ì œëª©", "ë‚ ì§œ"],
            "user.ê°€ì¡±": ["ê´€ê³„"],
            "user.ê±´ê°•ìƒíƒœ": ["ì¦ìƒ"],
            "user.ë¬¼ê±´": ["ì´ë¦„"],
            "user.ì‹ì‚¬": ["ë¼ë‹ˆ"],  # ë¼ë‹ˆë§Œ í•„ìˆ˜ë¡œ ë³€ê²½
            "user.ì·¨ë¯¸": ["ì´ë¦„"],
            "user.ì·¨í–¥": ["ê°’"]
        }
        
        required = required_fields.get(entity_key, [])
        for field in required:
            if not entity.get(field) or entity.get(field) == "" or entity.get(field) is None:
                return False
        return True


    def _generate_followup_questions(self, entity_key: str, missing_fields: List[str], value: dict = None) -> List[str]:
        """ëˆ„ë½ëœ í•„ë“œì— ëŒ€í•œ ì¬ì§ˆë¬¸ ìƒì„± (ì¤‘ë³µ ë°©ì§€ ê°•í™”)"""
        questions = []
        
        for field in missing_fields:
            # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ ì§ˆë¬¸ ìŠ¤í‚µ
            if value and value.get(field):
                continue
                
            if entity_key == "user.ì‚¬ìš©ì" and field == "ì´ë¦„":
                questions.append("ì´ë¦„ì„ ì•Œë ¤ì£¼ì„¸ìš”.")
            elif entity_key == "user.ì•½" and field == "ì•½ëª…":
                questions.append("ì–´ë–¤ ì•½ì„ ë³µìš©í•˜ì…¨ë‚˜ìš”?")
            elif entity_key == "user.ì¼ì •" and field == "ì œëª©":
                questions.append("ì¼ì •ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?")
            elif entity_key == "user.ì¼ì •" and field == "ë‚ ì§œ":
                questions.append("ì–¸ì œì¸ê°€ìš”?")
            elif entity_key == "user.ê¸°ë…ì¼" and field == "ì œëª©":
                questions.append("ê¸°ë…ì¼ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€ìš”?")
            elif entity_key == "user.ê¸°ë…ì¼" and field == "ë‚ ì§œ":
                questions.append("ì–¸ì œì¸ê°€ìš”?")
            elif entity_key == "user.ê°€ì¡±" and field == "ê´€ê³„":
                questions.append("ê°€ì¡± ê´€ê³„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")
            elif entity_key == "user.ê±´ê°•ìƒíƒœ" and field == "ì¦ìƒ":
                questions.append("ì–´ë–¤ ì¦ìƒì´ ìˆìœ¼ì‹ ê°€ìš”?")
            elif entity_key == "user.ë¬¼ê±´" and field == "ì´ë¦„":
                questions.append("ì–´ë–¤ ë¬¼ê±´ì¸ê°€ìš”?")
            elif entity_key == "user.ì‹ì‚¬" and field == "ë¼ë‹ˆ":
                questions.append("ì–´ë–¤ ë¼ë‹ˆì¸ê°€ìš”? (ì•„ì¹¨/ì ì‹¬/ì €ë…)")
            elif entity_key == "user.ì‹ì‚¬" and field == "ë©”ë‰´":
                questions.append("ë¬´ì—‡ì„ ë“œì…¨ë‚˜ìš”?")
            elif entity_key == "user.ì‹ì‚¬" and field == "ì‹œê°„":
                questions.append("ëª‡ ì‹œì— ë“œì…¨ë‚˜ìš”?")
            elif entity_key == "user.ì·¨ë¯¸" and field == "ì´ë¦„":
                questions.append("ì·¨ë¯¸ê°€ ë¬´ì—‡ì¸ê°€ìš”?")
            elif entity_key == "user.ì·¨í–¥" and field == "ê°’":
                questions.append("ì–´ë–¤ ê²ƒì„ ì¢‹ì•„í•˜ì‹œë‚˜ìš”?")
        
        return questions

    def _consolidate_followup_questions(self, questions: List[str]) -> str:
        """Follow-up ì§ˆë¬¸ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©"""
        if not questions:
            return ""
        
        if len(questions) == 1:
            return questions[0]
        
        # ì—”í‹°í‹°ë³„ë¡œ ì§ˆë¬¸ ê·¸ë£¹í™”
        entity_questions = {}
        for q in questions:
            if "ì•½" in q:
                entity_questions.setdefault("ì•½", []).append(q)
            elif "ì‹ì‚¬" in q or "ë¼ë‹ˆ" in q or "ë“œì…¨" in q:
                entity_questions.setdefault("ì‹ì‚¬", []).append(q)
            elif "ì¼ì •" in q:
                entity_questions.setdefault("ì¼ì •", []).append(q)
            elif "ê¸°ë…ì¼" in q or "ìƒì¼" in q or "ê¸°ë…" in q:
                entity_questions.setdefault("ê¸°ë…ì¼", []).append(q)
            elif "ê°€ì¡±" in q or "ì•„ë¹ " in q or "ì—„ë§ˆ" in q or "í˜•" in q or "ëˆ„ë‚˜" in q or "ì–¸ë‹ˆ" in q or "ë™ìƒ" in q:
                entity_questions.setdefault("ê°€ì¡±", []).append(q)
            else:
                entity_questions.setdefault("ê¸°íƒ€", []).append(q)
        
        # ê° ì—”í‹°í‹°ë³„ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í†µí•©
        consolidated = []
        for entity, qs in entity_questions.items():
            if entity == "ì•½":
                if len(qs) == 1:
                    consolidated.append(qs[0])
                else:
                    # ì—¬ëŸ¬ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ í†µí•© (ì¶”ê°€ ì •ë³´ ìš”ì²­ ì œê±°)
                    if qs:
                        consolidated.extend(qs)  # ê°œë³„ ì§ˆë¬¸ë“¤ì„ ê·¸ëŒ€ë¡œ ì¶”ê°€
            elif entity == "ì‹ì‚¬":
                if len(qs) == 1:
                    consolidated.append(qs[0])
                else:
                    # ë¼ë‹ˆ, ë©”ë‰´, ì‹œê°„ì´ ëª¨ë‘ ë¹ ì§„ ê²½ìš°
                    has_meal_type = any("ë¼ë‹ˆ" in q or "ì•„ì¹¨" in q or "ì ì‹¬" in q or "ì €ë…" in q for q in qs)
                    has_menu = any("ë¬´ì—‡" in q for q in qs)
                    has_time = any("ëª‡ ì‹œ" in q or "ì‹œê°„" in q for q in qs)
                    
                    if has_meal_type and has_menu and has_time:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì–´ë–¤ ë¼ë‹ˆì— ë¬´ì—‡ì„ ëª‡ ì‹œì— ë“œì…¨ë‚˜ìš”?")
                    elif has_menu and has_time:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ë¬´ì—‡ì„ ë“œì…¨ê³ , ëª‡ ì‹œì— ë“œì…¨ë‚˜ìš”?")
                    elif has_meal_type and has_menu:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì–´ë–¤ ë¼ë‹ˆì— ë¬´ì—‡ì„ ë“œì…¨ë‚˜ìš”?")
                    elif has_meal_type and has_time:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì–´ë–¤ ë¼ë‹ˆì— ëª‡ ì‹œì— ë“œì…¨ë‚˜ìš”?")
                    elif has_menu:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ë¬´ì—‡ì„ ë“œì…¨ë‚˜ìš”?")
                    elif has_time:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ëª‡ ì‹œì— ë“œì…¨ë‚˜ìš”?")
                    elif has_meal_type:
                        consolidated.append("ì‹ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì–´ë–¤ ë¼ë‹ˆì¸ê°€ìš”?")
                    else:
                        consolidated.extend(qs)
            elif entity == "ê¸°ë…ì¼":
                if len(qs) == 1:
                    consolidated.append(qs[0])
                else:
                    consolidated.append("ê¸°ë…ì¼ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì¶”ê°€ë¡œ ë‚ ì§œë‚˜ ê´€ê³„ ì •ë³´ë„ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?")
            elif entity == "ê°€ì¡±":
                if len(qs) == 1:
                    consolidated.append(qs[0])
                else:
                    consolidated.append("ê°€ì¡±ì— ëŒ€í•´ ì•Œë ¤ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”. ì¶”ê°€ë¡œ ì´ë¦„ì´ë‚˜ ê´€ê³„ ì •ë³´ë„ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?")
            else:
                consolidated.extend(qs)
        
        return " ".join(consolidated)

    def _get_confirmed_user_name(self, session_id: str) -> str:
        """í™•ì •ëœ ì‚¬ìš©ì ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ë³„ì¹­ ì§€ì›) - ëª¨ë“  ì„¸ì…˜ì—ì„œ ì¡°íšŒ"""
        try:
            # VectorStore ì „ì²´ì—ì„œ user.ì‚¬ìš©ì í•„í„°ë§ (ëª¨ë“  ì„¸ì…˜ì—ì„œ ì¡°íšŒ)
            docs = self.vectorstore.get()
            for i, doc_id in enumerate(docs.get("ids", [])):
                # user.ì‚¬ìš©ì íŒ¨í„´ì´ í¬í•¨ëœ doc_idë§Œ ì„ íƒ (ëª¨ë“  ì„¸ì…˜)
                if "_user.ì‚¬ìš©ì_" in doc_id:
                    data = json.loads(docs["documents"][i])
                    # í™•ì¸ëœ ì‚¬ìš©ì ì´ë¦„ì´ ìˆìœ¼ë©´ ë°˜í™˜
                    if (data.get("ì´ë¦„") and data.get("í™•ì¸ë¨")):
                        # ë³„ì¹­ì´ ìˆìœ¼ë©´ ë³„ì¹­ ë°˜í™˜, ì—†ìœ¼ë©´ ì´ë¦„ ë°˜í™˜
                        if data.get("ë³„ì¹­"):
                            return data["ë³„ì¹­"]
                        return data["ì´ë¦„"]
        except Exception as e:
            print(f"[WARN] ì‚¬ìš©ì ì´ë¦„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return "ì‚¬ìš©ì"

    def _analyze_entity_context(self, user_input: str, existing_entity: dict, new_entity: dict, entity_key: str) -> dict:
        """LLMì„ í™œìš©í•œ ë¬¸ë§¥ ë¶„ì„ìœ¼ë¡œ ê°™ì€ ëŒ€ìƒì¸ì§€ íŒë‹¨"""
        try:
            # ë¬¸ë§¥ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ ì—”í‹°í‹°ì™€ ìƒˆ ì—”í‹°í‹°ê°€ ê°™ì€ ëŒ€ìƒì„ ê°€ë¦¬í‚¤ëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë°œí™”: "{user_input}"

ê¸°ì¡´ ì—”í‹°í‹°: {existing_entity}
ìƒˆ ì—”í‹°í‹°: {new_entity}

ë¶„ì„ ê¸°ì¤€:
1. ì‚¬ìš©ìê°€ "ë‹¤ë¥¸", "ìƒˆë¡œìš´", "ë˜ ë‹¤ë¥¸" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í–ˆëŠ”ê°€?
2. ì‚¬ìš©ìê°€ "ê°™ì€", "ê·¸", "ì´ì „ì— ë§í•œ" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í–ˆëŠ”ê°€?
3. ë¬¸ë§¥ìƒ ê°™ì€ ëŒ€ìƒì„ ê°€ë¦¬í‚¤ëŠ” ê²ƒ ê°™ì€ê°€?

ì‘ë‹µ í˜•ì‹: {{"is_same_entity": true/false, "reason": "íŒë‹¨ ì´ìœ "}}
"""
            
            response = self.llm.invoke(prompt)
            result = json.loads(response.content)
            
            print(f"[DEBUG] ë¬¸ë§¥ ë¶„ì„ ê²°ê³¼: {result}")
            return result
            
        except Exception as e:
            print(f"[WARN] ë¬¸ë§¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ê°™ì€ ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼
            return {"is_same_entity": True, "reason": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ê°’"}

    def _find_item_location(self, user_input: str, session_id: str) -> dict:
        """ë¬¼ê±´ ìœ„ì¹˜ ê²€ìƒ‰ (ëª…ë ¹/ì§ˆë¬¸ ì²˜ë¦¬ìš©) - dict ë°˜í™˜"""
        try:
            # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¬¼ê±´ëª… ì¶”ì¶œ (ë” ìœ ì—°í•œ ë°©ì‹)
            item_keywords = []
            
            # ë¬¼ê±´ ê´€ë ¨ ì§ˆë¬¸ íŒ¨í„´ì—ì„œ ë¬¼ê±´ëª… ì¶”ì¶œ
            patterns = [
                r"(.+?)\s*(?:ì–´ë””|ìœ„ì¹˜|ìˆì–´|ë‘ì—ˆ|ë†“ì•˜)",
                r"(.+?)\s*(?:ê°€ì ¸ë‹¤|ê°€ì ¸ì™€|ì°¾ì•„)",
                r"(.+?)\s*(?:ì°¾ì•„|ì°¾ì•„ì¤˜)"
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, user_input)
                for match in matches:
                    item = match.strip()
                    if len(item) >= 1 and item not in ["ì–´ë””", "ìœ„ì¹˜", "ìˆì–´", "ë‘ì—ˆ", "ë†“ì•˜", "ê°€ì ¸ë‹¤", "ê°€ì ¸ì™€", "ì°¾ì•„", "ì°¾ì•„ì¤˜"]:
                        item_keywords.append(item)
            
            if not item_keywords:
                return None
            
            # VectorStoreì—ì„œ ë¬¼ê±´ ê²€ìƒ‰ (í•„í„° ì—†ì´)
            docs = self.vectorstore.similarity_search(" ".join(item_keywords), k=20)
            
            if not docs:
                return None
            
            # ìœ„ì¹˜ ì •ë³´ê°€ ìˆëŠ” ë¬¼ê±´ ì°¾ê¸° (ì„¸ì…˜ í•„í„°ë§)
            for doc in docs:
                try:
                    data = json.loads(doc.page_content)
                    
                    # ì—”í‹°í‹° í‚¤ í™•ì¸ (ëª¨ë“  ì„¸ì…˜ì—ì„œ ê²€ìƒ‰)
                    if data.get("entity_key") == "user.ë¬¼ê±´":
                        item_name = data.get("ì´ë¦„", "")
                        location = data.get("ìœ„ì¹˜", "")
                        
                        if location and any(keyword in item_name for keyword in item_keywords):
                            # ì•ˆì „ì„±ì„ ìœ„í•´ normalize ì¬ì ìš© (ì´ì „ ë°ì´í„° ëŒ€ë¹„)
                            normalized_location = self._normalize_location(location)
                            return {"ì´ë¦„": item_name, "ìœ„ì¹˜": normalized_location}
                except Exception:
                    continue
            
            return None
            
        except Exception as e:
            print(f"[WARN] ë¬¼ê±´ ìœ„ì¹˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def _handle_location_query(self, user_input: str, session_id: str) -> str:
        """ìœ„ì¹˜ ì§ˆë¬¸ ì²˜ë¦¬ (cognitive ì¹´í…Œê³ ë¦¬ìš©)"""
        location_info = self._find_item_location(user_input, session_id)
        if location_info:
            return f"{location_info['ì´ë¦„']}ì€ {location_info['ìœ„ì¹˜']}ì— ìˆì–´ìš”."
        else:
            return "ì£„ì†¡í•´ìš”, ê·¸ ë¬¼ê±´ì˜ ìœ„ì¹˜ë¥¼ ëª¨ë¥´ê² ì–´ìš”. ì–´ë””ì— ë‘ì—ˆëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•´ë‘˜ê²Œìš”!"


    def _build_personalized_emotional_reply(self, user_input: str, session_id: str) -> str:
        """ê°œì¸í™”ëœ ê°ì • ì‘ë‹µ ìƒì„± (ì—”í‹°í‹° ì •ë³´ í™œìš©)"""
        try:
            # ì‚¬ìš©ì ì´ë¦„ê³¼ VectorStore ê¸°ë°˜ ì‚¬ì‹¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            user_name = self._get_confirmed_user_name(session_id)
            facts_text = self._get_facts_text(session_id)
            
            # ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            context_info = []
            if user_name:
                context_info.append(f"ì‚¬ìš©ìì˜ ì´ë¦„ì€ {user_name}ì…ë‹ˆë‹¤.")
            if facts_text:
                context_info.append(f"ì €ì¥ëœ ì •ë³´: {facts_text}")
            
            context_text = "\n".join(context_info) if context_info else ""
            
            # ê°œì¸í™”ëœ ê°ì • ì‘ë‹µ ìƒì„±
            if context_text:
                prompt = (
                    "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°ì •ì„ ê¹Šì´ ì´í•´í•˜ê³  ê³µê°í•˜ëŠ” ìƒí™œ ì§€ì› ë¡œë´‡ì…ë‹ˆë‹¤.\n"
                    "ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ê³ , ê·¸ ê°ì •ì— ë§ëŠ” ë”°ëœ»í•˜ê³  ì§„ì‹¬ ì–´ë¦° ì‘ë‹µì„ í•´ì£¼ì„¸ìš”.\n"
                    "ì¡°ì–¸ë³´ë‹¤ëŠ” ë¨¼ì € ê³µê°í•˜ê³ , ì‚¬ìš©ìê°€ í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ëŠë¼ë„ë¡ í•´ì£¼ì„¸ìš”.\n"
                    "ë‹µë³€ì€ 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ, **í•­ìƒ ì¡´ëŒ“ë§ë¡œ** ì‘ë‹µí•´ì£¼ì„¸ìš”.\n"
                    "ì €ì¥ëœ ì •ë³´ëŠ” ì‹¤ì œ VectorStoreì— ì €ì¥ëœ ì‚¬ì‹¤ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n\n"
                    f"[ì‚¬ìš©ì ì •ë³´]\n{context_text}\n\n"
                    f"ì‚¬ìš©ì: {user_input}\n"
                    "ë¡œë´‡:"
                )
            else:
                # ê¸°ë³¸ ê°ì • ì‘ë‹µ - ì‚¬ìš©ì ì´ë¦„ í™•ì¸ ìƒíƒœ ì „ë‹¬
                user_name_confirmed = bool(self._get_confirmed_user_name(session_id))
                return build_emotional_reply(user_input, llm=self.llm, user_name_confirmed=user_name_confirmed)
            
            response = self.llm.invoke(prompt)
            return response
            
        except Exception as e:
            print(f"[WARN] ê°œì¸í™”ëœ ê°ì • ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback: ê¸°ë³¸ ê°ì • ì‘ë‹µ - ì‚¬ìš©ì ì´ë¦„ í™•ì¸ ìƒíƒœ ì „ë‹¬
            user_name_confirmed = bool(self._get_confirmed_user_name(session_id))
            return build_emotional_reply(user_input, llm=self.llm, user_name_confirmed=user_name_confirmed)

    def _prevent_name_family_conflict(self, entities: Dict[str, List[Dict[str, Any]]]) -> None:
        """ì´ë¦„/ê°€ì¡± ì •ë³´ ì¶©ëŒ ë°©ì§€"""
        # ê°€ì¡± ì •ë³´ì—ì„œ ì´ë¦„ ì¶”ì¶œ
        family_names = set()
        for family_entity in entities.get("user.ê°€ì¡±", []):
            if "ì´ë¦„" in family_entity:
                family_names.add(family_entity["ì´ë¦„"])
        
        # ì‚¬ìš©ì ì´ë¦„ì´ ê°€ì¡± ì´ë¦„ê³¼ ì¶©ëŒí•˜ëŠ”ì§€ í™•ì¸
        for user_entity in entities.get("user.ì‚¬ìš©ì", []):
            if "ì´ë¦„" in user_entity:
                user_name = user_entity["ì´ë¦„"]
                if user_name in family_names:
                    # ì¶©ëŒ ì‹œ ì‚¬ìš©ì ì´ë¦„ ì œê±° (ê°€ì¡± ì´ë¦„ì´ ìš°ì„ )
                    # print(f"[INFO] ì´ë¦„ ì¶©ëŒ ë°©ì§€: '{user_name}'ì€ ê°€ì¡± ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ë¨")  # í…ŒìŠ¤íŠ¸ ì‹œ ë¡œê·¸ ì œê±°
                    user_entity.pop("ì´ë¦„", None)

    def _normalize_name(self, name: str) -> str:
        """ì´ë¦„ í›„ë³´ ì •ê·œí™” (ê³µë°± ì œê±°, ì¡°ì‚¬ ì œê±°)"""
        if not name: 
            return name
        
        # ê³µë°± ì œê±° (ê¹€ ì² ìˆ˜ â†’ ê¹€ì² ìˆ˜)
        name = name.strip().replace(" ", "")
        
        # ì¸ìš© íŒ¨í„´ ì œê±° (ì´ë¼ê³  í•´, ë¼ê³  í•´, ë¼ í•´ ë“±)
        name = re.sub(r"(ì´ë¼ê³ \s*í•´|ë¼ê³ \s*í•´|ë¼\s*í•´|ì´ë¼ê³ \s*ë¶ˆëŸ¬|ë¼ê³ \s*ë¶ˆëŸ¬|ë¼\s*ë¶ˆëŸ¬)$", "", name).strip()
        
        # ì¢…ê²°ì–´ ì œê±° (ì´ì•¼, ì´ì—ìš”, ì…ë‹ˆë‹¤, ì˜ˆìš”, ì´ê³ , ì´ê³ ìš” ë“±)
        name = re.sub(r"(ì´ì•¼|ì´ì—ìš”|ì…ë‹ˆë‹¤|ì˜ˆìš”|ì´ê³ |ì´ê³ ìš”|ì•¼|ë‹¤|ì–´|ì•„)$", "", name).strip()
        
        # í˜¸ì¹­ ì œê±° (ë‹˜, ì”¨)
        name = re.sub(r"(ë‹˜|ì”¨)$", "", name).strip()
        
        return name

    def _normalize_location(self, location: str) -> str:
        """ìœ„ì¹˜ì—ì„œ ì¡°ì‚¬ ì œê±°í•˜ê³  ë³€í˜•ì–´ ì •ê·œí™”í•˜ì—¬ ìˆœìˆ˜ ëª…ì‚¬êµ¬ë§Œ ë°˜í™˜ (ìƒëŒ€ ìœ„ì¹˜ ë³´ì¡´)"""
        if not location:
            return location
        
        # ì¡°ì‚¬ íŒ¨í„´ ì œê±° (ì—, ì—ì„œ, ìœ¼ë¡œ, ìª½ì—, ì•ˆì— ë“±) - + ë¶™ì—¬ì„œ ì¤‘ë³µ ì œê±°
        location = re.sub(r"(ì—|ì—ì„œ|ìœ¼ë¡œ|ìª½ì—|ì•ˆì—|ë°–ì—|ì˜†ì—|ì•ì—|ë’¤ì—|ì•„ë˜ì—)+$", "", location).strip()
        
        # ìƒëŒ€ ìœ„ì¹˜ íŒ¨í„´ ì¶”ì¶œ (ìœ„/ì•„ë˜/ì˜† ë“±)
        relative_position_pattern = r"(.+?)(ìœ„|ì•„ë˜|ì˜†|ì•|ë’¤|ì™¼ìª½|ì˜¤ë¥¸ìª½|ê°€ìš´ë°|ì¤‘ì•™|ì¤‘ê°„)$"
        m = re.match(relative_position_pattern, location)
        
        if m:
            base_location = m.group(1).strip()
            relative_pos = m.group(2)
            
            # ê¸°ë³¸ ìœ„ì¹˜ ì •ê·œí™”
            base_normalized = self._normalize_base_location(base_location)
            
            # ìƒëŒ€ ìœ„ì¹˜ ë³´ì¡´í•˜ì—¬ ë°˜í™˜
            return f"{base_normalized}({relative_pos})"
        
        # ìƒëŒ€ ìœ„ì¹˜ê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ì •ê·œí™”
        return self._normalize_base_location(location)
    
    def _normalize_base_location(self, location: str) -> str:
        """ê¸°ë³¸ ìœ„ì¹˜ ì •ê·œí™” (ìƒëŒ€ ìœ„ì¹˜ ì œì™¸)"""
        # ë³€í˜•ì–´ ì •ê·œí™” ì‚¬ì „
        location_normalize_map = {
            # ë°©/ê³µê°„ ê´€ë ¨
            "ê±°ì‹¤": "ê±°ì‹¤", "ë°©": "ê±°ì‹¤", "ì‘ì ‘ì‹¤": "ê±°ì‹¤", "ë¼ìš´ì§€": "ê±°ì‹¤",
            "ì¹¨ì‹¤": "ì¹¨ì‹¤", "ìê¸°ë°©": "ì¹¨ì‹¤", "ê°œì¸ë°©": "ì¹¨ì‹¤",
            "ë¶€ì—Œ": "ë¶€ì—Œ", "ì£¼ë°©": "ë¶€ì—Œ", "ìš”ë¦¬ì‹¤": "ë¶€ì—Œ",
            "í™”ì¥ì‹¤": "í™”ì¥ì‹¤", "ìš•ì‹¤": "í™”ì¥ì‹¤", "ì„¸ë©´ì‹¤": "í™”ì¥ì‹¤",
            "ë‹¤ìš©ë„ì‹¤": "ë‹¤ìš©ë„ì‹¤", "ì„œì¬": "ë‹¤ìš©ë„ì‹¤", "ì‘ì—…ì‹¤": "ë‹¤ìš©ë„ì‹¤",
            "ë² ë€ë‹¤": "ë² ë€ë‹¤", "ë°œì½”ë‹ˆ": "ë² ë€ë‹¤", "í…Œë¼ìŠ¤": "ë² ë€ë‹¤",
            "ì§€í•˜": "ì§€í•˜", "ì§€í•˜ì‹¤": "ì§€í•˜", "ì§€í•˜ì¸µ": "ì§€í•˜",
            "ì˜¥ìƒ": "ì˜¥ìƒ", "ë£¨í”„íƒ‘": "ì˜¥ìƒ",
            
            # ê°€êµ¬/ë¬¼ê±´ ê´€ë ¨
            "í™”ì¥ì§€": "í™”ì¥ì§€", "íœ´ì§€": "í™”ì¥ì§€", "ë‘ë£¨ë§ˆë¦¬": "í™”ì¥ì§€",
            "ëƒ‰ì¥ê³ ": "ëƒ‰ì¥ê³ ", "ëƒ‰ë™ê³ ": "ëƒ‰ì¥ê³ ",
            "ì±…ìƒ": "ì±…ìƒ", "ë°ìŠ¤í¬": "ì±…ìƒ", "ì‘ì—…ëŒ€": "ì±…ìƒ",
            "ì¹¨ëŒ€": "ì¹¨ëŒ€", "ë² ë“œ": "ì¹¨ëŒ€", "ë§¤íŠ¸ë¦¬ìŠ¤": "ì¹¨ëŒ€",
            "ì†ŒíŒŒ": "ì†ŒíŒŒ", "ì‡¼íŒŒ": "ì†ŒíŒŒ", "ì˜ì": "ì†ŒíŒŒ",
            "í…Œì´ë¸”": "í…Œì´ë¸”", "íƒì": "í…Œì´ë¸”", "ì‹íƒ": "í…Œì´ë¸”",
            "ì˜·ì¥": "ì˜·ì¥", "ì¥ë¡±": "ì˜·ì¥", "ë“œë ˆìŠ¤ë£¸": "ì˜·ì¥",
            "ì„œë": "ì„œë", "ì„œëì¥": "ì„œë", "ìˆ˜ë‚©í•¨": "ì„œë",
            "ì„ ë°˜": "ì„ ë°˜", "ì±…ì¥": "ì„ ë°˜", "ìˆ˜ë‚©ì¥": "ì„ ë°˜",
            
            # ë°©í–¥/ìœ„ì¹˜ ê´€ë ¨ (ìƒëŒ€ ìœ„ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°)
            "ì•": "ì•", "ì•ìª½": "ì•", "ì •ë©´": "ì•",
            "ë’¤": "ë’¤", "ë’¤ìª½": "ë’¤", "í›„ë©´": "ë’¤",
            "ì™¼ìª½": "ì™¼ìª½", "ì¢Œì¸¡": "ì™¼ìª½", "ì™¼í¸": "ì™¼ìª½",
            "ì˜¤ë¥¸ìª½": "ì˜¤ë¥¸ìª½", "ìš°ì¸¡": "ì˜¤ë¥¸ìª½", "ì˜¤ë¥¸í¸": "ì˜¤ë¥¸ìª½",
            "ìœ„": "ìœ„", "ìœ„ìª½": "ìœ„", "ìƒë‹¨": "ìœ„",
            "ì•„ë˜": "ì•„ë˜", "ì•„ë˜ìª½": "ì•„ë˜", "í•˜ë‹¨": "ì•„ë˜",
            "ê°€ìš´ë°": "ê°€ìš´ë°", "ì¤‘ì•™": "ê°€ìš´ë°", "ì¤‘ê°„": "ê°€ìš´ë°",
            "ì˜†": "ì˜†", "ì˜†ìª½": "ì˜†", "ì¸¡ë©´": "ì˜†",
            
            # ì¼ë°˜ì ì¸ ìœ„ì¹˜
            "ì—¬ê¸°": "ì—¬ê¸°", "ì´ê³³": "ì—¬ê¸°", "í˜„ì¬ìœ„ì¹˜": "ì—¬ê¸°",
            "ì €ê¸°": "ì €ê¸°", "ê·¸ê³³": "ì €ê¸°", "ì €ìª½": "ì €ê¸°",
            "ì–´ë””": "ì–´ë””", "ì–´ë””ì„ ê°€": "ì–´ë””", "ì–´ë”˜ê°€": "ì–´ë””",
        }
        
        # ë³€í˜•ì–´ ì •ê·œí™” ì ìš©
        return location_normalize_map.get(location, location)

    def _merge_entity_values(self, old_value: dict, new_value: dict, entity_key: str) -> dict:
        """ì¤‘ë³µ ì—”í‹°í‹° ë¨¸ì§€ ë¡œì§ ê°œì„  (ê¸°ì¡´ ê°’ ìœ ì§€ + ìƒˆ ê°’ ì¶”ê°€)"""
        if not old_value:
            return new_value
        if not new_value:
            return old_value
        
        # ê¸°ë³¸ ë¨¸ì§€: ê¸°ì¡´ ê°’ ìœ ì§€ + ìƒˆ ê°’ ì¶”ê°€
        merged = {**old_value, **new_value}
        
        # ì—”í‹°í‹°ë³„ íŠ¹ìˆ˜ ë¨¸ì§€ ë¡œì§
        if entity_key.endswith("ì‚¬ìš©ì"):
            # ì‚¬ìš©ì: ì´ë¦„ì€ ìƒˆ ê°’ ìš°ì„ , ë³„ì¹­ì€ ëˆ„ì 
            if "ë³„ì¹­" in new_value and "ë³„ì¹­" in old_value:
                # ë³„ì¹­ì´ ë‹¤ë¥´ë©´ ë‘˜ ë‹¤ ìœ ì§€ (ë¦¬ìŠ¤íŠ¸ë¡œ)
                if old_value["ë³„ì¹­"] != new_value["ë³„ì¹­"]:
                    merged["ë³„ì¹­"] = [old_value["ë³„ì¹­"], new_value["ë³„ì¹­"]]
                else:
                    merged["ë³„ì¹­"] = new_value["ë³„ì¹­"]
            elif "ë³„ì¹­" in old_value and "ë³„ì¹­" not in new_value:
                merged["ë³„ì¹­"] = old_value["ë³„ì¹­"]
            elif "ë³„ì¹­" in new_value and "ë³„ì¹­" not in old_value:
                merged["ë³„ì¹­"] = new_value["ë³„ì¹­"]
        
        elif entity_key.endswith("ì•½"):
            # ì•½: ë³µìš© ì •ë³´ëŠ” ëˆ„ì , ê¸°ê°„ì€ ìƒˆ ê°’ ìš°ì„ 
            if "ë³µìš©" in old_value and "ë³µìš©" in new_value:
                merged["ë³µìš©"] = (old_value["ë³µìš©"] or []) + (new_value["ë³µìš©"] or [])
            elif "ë³µìš©" in old_value:
                merged["ë³µìš©"] = old_value["ë³µìš©"]
            elif "ë³µìš©" in new_value:
                merged["ë³µìš©"] = new_value["ë³µìš©"]
        
        elif entity_key.endswith("ì¼ì •"):
            # ì¼ì •: ì‹œê°„ ì •ë³´ëŠ” ëˆ„ì 
            if "ì‹œê°„" in old_value and "ì‹œê°„" in new_value:
                old_time = self._normalize_time_field(old_value["ì‹œê°„"])
                new_time = self._normalize_time_field(new_value["ì‹œê°„"])
                merged["ì‹œê°„"] = sorted(list(set(old_time + new_time))) if (old_time or new_time) else None
            elif "ì‹œê°„" in old_value:
                merged["ì‹œê°„"] = old_value["ì‹œê°„"]
            elif "ì‹œê°„" in new_value:
                merged["ì‹œê°„"] = new_value["ì‹œê°„"]
        
        elif entity_key.endswith("ì‹ì‚¬"):
            # ì‹ì‚¬: ë©”ë‰´ëŠ” ëˆ„ì 
            if "ë©”ë‰´" in old_value and "ë©”ë‰´" in new_value:
                old_menus = old_value["ë©”ë‰´"] if isinstance(old_value["ë©”ë‰´"], list) else [old_value["ë©”ë‰´"]]
                new_menus = new_value["ë©”ë‰´"] if isinstance(new_value["ë©”ë‰´"], list) else [new_value["ë©”ë‰´"]]
                merged["ë©”ë‰´"] = list(set(old_menus + new_menus))
            elif "ë©”ë‰´" in old_value:
                merged["ë©”ë‰´"] = old_value["ë©”ë‰´"]
            elif "ë©”ë‰´" in new_value:
                merged["ë©”ë‰´"] = new_value["ë©”ë‰´"]
        
        elif entity_key.endswith("ë¬¼ê±´"):
            # ë¬¼ê±´: ìœ„ì¹˜ëŠ” ìƒˆ ê°’ ìš°ì„ , ì„¤ëª…ì€ ëˆ„ì 
            if "ì„¤ëª…" in old_value and "ì„¤ëª…" in new_value:
                old_desc = old_value["ì„¤ëª…"] if isinstance(old_value["ì„¤ëª…"], list) else [old_value["ì„¤ëª…"]]
                new_desc = new_value["ì„¤ëª…"] if isinstance(new_value["ì„¤ëª…"], list) else [new_value["ì„¤ëª…"]]
                merged["ì„¤ëª…"] = list(set(old_desc + new_desc))
            elif "ì„¤ëª…" in old_value:
                merged["ì„¤ëª…"] = old_value["ì„¤ëª…"]
            elif "ì„¤ëª…" in new_value:
                merged["ì„¤ëª…"] = new_value["ì„¤ëª…"]
        
        return merged

    def _extract_period(self, text: str) -> Optional[str]:
        """ë³µìš© ê¸°ê°„ ì¶”ì¶œ í†µí•© í•¨ìˆ˜"""
        period_patterns = [
            r"(ì¼ì£¼ì¼ì¹˜|\d+ì¼ì¹˜|\d+ì£¼ì¼ì¹˜|\d+ê°œì›”ì¹˜|\d+ë…„ì¹˜)",
            r"(ì¼ì£¼ì¼|\d+ì¼\s*ì¹˜|\d+ì£¼\s*ì¼\s*ì¹˜|\d+ê°œ\s*ì›”\s*ì¹˜|\d+ë…„\s*ì¹˜)",
            r"(ì¼ì£¼ì¼ë¶„|\d+ì¼ë¶„|\d+ì£¼ë¶„|\d+ê°œì›”ë¶„|\d+ë…„ë¶„)",
            r"(ì¼ì£¼ì¼\s*ë¶„|\d+ì¼\s*ë¶„|\d+ì£¼\s*ë¶„|\d+ê°œ\s*ì›”\s*ë¶„|\d+ë…„\s*ë¶„)"
        ]
        
        for pattern in period_patterns:
            m = re.search(pattern, text)
            if m:
                return m.group(1)
        return None

    def _extract_meal_relation(self, text: str) -> Optional[str]:
        """ì•½ ë³µìš© ì‹œ ì‹ì „/ì‹í›„ ì •ë³´ ì¶”ì¶œ"""
        if "ì‹í›„" in text:
            return "ì‹í›„"
        if "ì‹ì „" in text:
            return "ì‹ì „"
        return None

    def _extract_drugs_with_info(self, text: str) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì•½ ë³µìš© ì •ë³´ë¥¼ ì•½ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶”ì¶œ"""
        results = []
        seen_drugs = set()  # ì¤‘ë³µ ë°©ì§€
        
        # ì•½ì´ ì•„ë‹Œ ë‹¨ì–´ë“¤ (ì•½ìœ¼ë¡œ ëë‚˜ì§€ë§Œ ì˜ì•½í’ˆì´ ì•„ë‹Œ ê²ƒë“¤)
        non_drug_words = {
            "ì˜ˆì•½", "ì•½ì†", "ì•½ì†ì‹œê°„", "ì•½ì†ì¥ì†Œ", "ì•½ì†ì¼",
            "ì¹˜ì•½", "ì„¸ì •ì•½", "ì„¸ì •ì œ", "ì„¸ì •ì•¡", "ì„¸ì •ìš©í’ˆ",
            "ì•½ì†", "ì•½ì†ì‹œê°„", "ì•½ì†ì¥ì†Œ", "ì•½ì†ì¼", "ì•½ì†ì‹œê°„", "ì•½ì†ì¥ì†Œ"
        }
        
        # ë¨¼ì € ëª¨ë“  ì•½ëª…ì„ ì°¾ê¸°
        drug_patterns = [
            r"([ê°€-í£A-Za-z]+ì•½)",  # ê¸°ì¡´ íŒ¨í„´
            r"(ì•„ìŠ¤í”¼ë¦°|íƒ€ì´ë ˆë†€|ì´ë¶€í”„ë¡œíœ|ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)",  # ì¼ë°˜ ì•½ëª…
        ]
        
        all_drugs = []
        for pattern in drug_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if match not in non_drug_words:
                    all_drugs.append(match)
        
        # ê° ì•½ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ ë³µìš© ì •ë³´ ì¶”ì¶œ
        for drug in all_drugs:
            # ì¤‘ë³µ ë°©ì§€
            if drug in seen_drugs:
                continue
            seen_drugs.add(drug)
            
            drug_info = {"ì•½ëª…": drug}
            
            # í•´ë‹¹ ì•½ëª…ì´ í¬í•¨ëœ ë¬¸ì¥ì„ ì°¾ê¸° (ë§ˆì¹¨í‘œ, ì‰¼í‘œë¡œ ë¶„ë¦¬)
            sentences = re.split(r'[.,]', text)
            
            for sentence in sentences:
                if drug in sentence:
                    sentence = sentence.strip()
                    if not sentence:
                        continue
                    
                    # ë³µìš© ì£¼ê¸° ì¶”ì¶œ
                    dosages = self._extract_dosage(sentence)
                    if dosages:
                        drug_info["ë³µìš©"] = dosages

                    # ì‹ì „/ì‹í›„ ì •ë³´ ì¶”ì¶œ
                    meal_relation = self._extract_meal_relation(sentence)
                    if meal_relation:
                        drug_info["ì‹ì‚¬ì™€ì˜ ê´€ê³„"] = meal_relation

                    # ë³µìš© ê¸°ê°„ ì¶”ì¶œ
                    period = self._extract_period(sentence)
                    if period:
                        drug_info["ë³µìš© ê¸°ê°„"] = period
                    
                    break  # í•´ë‹¹ ì•½ì˜ ë¬¸ì¥ì„ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨

            results.append(drug_info)

        return results

    def _extract_dosage(self, text: str) -> List[Dict[str, str]]:
        """ë³µìš© íšŸìˆ˜/ë°©ë²• ì¶”ì¶œ í†µí•© í•¨ìˆ˜ (ì‹¤ì œ ì–¸ê¸‰ëœ ì •ë³´ë§Œ ì¶”ì¶œ)"""
        dosage_patterns = [
            r"(í•˜ë£¨\s*ì—?\s*\d+ë²ˆ|\d+ë²ˆ\s*ë³µìš©)",
            r"(ì•„ì¹¨|ì ì‹¬|ì €ë…)",
            r"(\d+ì‹œ\s*\d+ë¶„?)",
        ]
        
        dosages = []
        seen_dosages = set()  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ set
        
        for pattern in dosage_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ë¡œ ì¤‘ë³µ ì²´í¬
                normalized_match = re.sub(r'\s+', ' ', match.strip())
                if normalized_match not in seen_dosages:
                    seen_dosages.add(normalized_match)
                    dosages.append({"ì›ë¬¸": normalized_match})
        
        # ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë³µìš© ì •ë³´ë§Œ ë°˜í™˜ (ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ)
        return dosages if dosages else None

    def _add_to_date_cache(self, date_str: str, normalized_date: str) -> None:
        """ë‚ ì§œ ìºì‹œì— ì¶”ê°€ (í¬ê¸° ì œí•œ ì ìš©)"""
        self.date_cache[date_str] = normalized_date
        
        # ìºì‹œ í¬ê¸° ì œí•œ ì ìš©
        if len(self.date_cache) > self.max_date_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
            oldest_key = next(iter(self.date_cache))
            del self.date_cache[oldest_key]
            logger.debug(f"ë‚ ì§œ ìºì‹œ í¬ê¸° ì œí•œìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°: '{oldest_key}'")

    def _normalize_date(self, date_str: str, session_id: str = None) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ë‚ ì§œ ì •ê·œí™”: Rule-based + ìºì‹œ + dateparser + LLM fallback"""
        if not date_str:
            return date_str
        
        # 0ì°¨: ìºì‹œ í™•ì¸ (ê°€ì¥ ë¹ ë¥¸ ì²˜ë¦¬)
        if date_str in self.date_cache:
            logger.debug(f"ë‚ ì§œ ìºì‹œ hit: '{date_str}' â†’ '{self.date_cache[date_str]}'")
            return self.date_cache[date_str]
        
        now = datetime.now()
        
        # 1ì°¨: Rule-based ë¹ ë¥¸ ë§¤í•‘ (ì„±ëŠ¥ ìµœì í™”)
        relative_dates = {
            "ì˜¤ëŠ˜": now,
            "í˜„ì¬": now,
            "ì§€ê¸ˆ": now,
            "ë‚´ì¼": now + timedelta(days=1),
            "ë‹¤ìŒë‚ ": now + timedelta(days=1),
            "ëª¨ë ˆ": now + timedelta(days=2),
            "ì´í‹€í›„": now + timedelta(days=2),
            "ì–´ì œ": now - timedelta(days=1),
            "í•˜ë£¨ì „": now - timedelta(days=1),
            "ê·¸ì €ê»˜": now - timedelta(days=2),
            "ì´í‹€ì „": now - timedelta(days=2),
            "ê·¸ì œ": now - timedelta(days=2),
            "3ì¼ì „": now - timedelta(days=3),
            "ì¼ì£¼ì¼ì „": now - timedelta(days=7),
            "í•œì£¼ì „": now - timedelta(days=7),
            "ì¼ì£¼ì¼í›„": now + timedelta(days=7),
            "í•œì£¼í›„": now + timedelta(days=7)
        }
        
        # ë³µì¡í•œ ë‚ ì§œ í‘œí˜„ ì²˜ë¦¬
        if "ë‹¤ìŒ ì£¼" in date_str or "ë‹¤ìŒì£¼" in date_str:
            # "ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼" ì²˜ë¦¬
            if "ê¸ˆìš”ì¼" in date_str:
                # ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ ê³„ì‚°
                days_ahead = 4 - now.weekday()  # ê¸ˆìš”ì¼ì€ 4
                if days_ahead <= 0:  # ê¸ˆìš”ì¼ì´ ì§€ë‚¬ìœ¼ë©´
                    days_ahead += 7
                days_ahead += 7  # ë‹¤ìŒ ì£¼
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "ì›”ìš”ì¼" in date_str:
                days_ahead = 0 - now.weekday()  # ì›”ìš”ì¼ì€ 0
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "í™”ìš”ì¼" in date_str:
                days_ahead = 1 - now.weekday()  # í™”ìš”ì¼ì€ 1
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "ìˆ˜ìš”ì¼" in date_str:
                days_ahead = 2 - now.weekday()  # ìˆ˜ìš”ì¼ì€ 2
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "ëª©ìš”ì¼" in date_str:
                days_ahead = 3 - now.weekday()  # ëª©ìš”ì¼ì€ 3
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "í† ìš”ì¼" in date_str:
                days_ahead = 5 - now.weekday()  # í† ìš”ì¼ì€ 5
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
            elif "ì¼ìš”ì¼" in date_str:
                days_ahead = 6 - now.weekday()  # ì¼ìš”ì¼ì€ 6
                if days_ahead <= 0:
                    days_ahead += 7
                days_ahead += 7
                return (now + timedelta(days=days_ahead)).strftime("%Y-%m-%d")
        
        # ê¸°ë³¸ ìƒëŒ€ ë‚ ì§œ ë§¤í•‘
        if date_str in relative_dates:
            result = relative_dates[date_str].strftime('%Y-%m-%d')
            self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
            return result
        
        # 1.5ì°¨: ìš”ì¼ íŒ¨í„´ ì§ì ‘ ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
        weekday_map = {
            "ì›”ìš”ì¼": 0, "í™”ìš”ì¼": 1, "ìˆ˜ìš”ì¼": 2, "ëª©ìš”ì¼": 3, 
            "ê¸ˆìš”ì¼": 4, "í† ìš”ì¼": 5, "ì¼ìš”ì¼": 6
        }
        
        # ì´ë²ˆì£¼/ë‹¤ìŒì£¼/ë‹¤ë‹¤ìŒì£¼ + ìš”ì¼ íŒ¨í„´
        weekday_pattern = r"(ì´ë²ˆì£¼|ë‹¤ìŒì£¼|ë‹¤ë‹¤ìŒì£¼)\s*(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼|í† ìš”ì¼|ì¼ìš”ì¼)"
        m = re.match(weekday_pattern, date_str.strip())
        if m:
            week_type = m.group(1)
            weekday_name = m.group(2)
            
            # ê¸°ì¤€ ë‚ ì§œ ì„¤ì •
            if week_type == "ì´ë²ˆì£¼":
                base = now
            elif week_type == "ë‹¤ìŒì£¼":
                base = now + timedelta(weeks=1)
            else:  # ë‹¤ë‹¤ìŒì£¼
                base = now + timedelta(weeks=2)
            
            target_weekday = weekday_map[weekday_name]
            
            # ëª©í‘œ ìš”ì¼ê¹Œì§€ì˜ ì¼ìˆ˜ ê³„ì‚°
            days_ahead = (target_weekday - base.weekday()) % 7
            target_date = base + timedelta(days=days_ahead)
            
            result = target_date.strftime('%Y-%m-%d')
            self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
            return result
        
        # 1.5.1ì°¨: ë‹¨ì¼ ìš”ì¼ íŒ¨í„´: "ê¸ˆìš”ì¼" (í˜„ì¬ ì£¼ ê¸°ì¤€)
        single_weekday_pattern = r"(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼|í† ìš”ì¼|ì¼ìš”ì¼)$"
        m = re.match(single_weekday_pattern, date_str.strip())
        if m:
            weekday_name = m.group(1)
            target_weekday = weekday_map[weekday_name]
            
            # í˜„ì¬ ì£¼ì˜ í•´ë‹¹ ìš”ì¼ ê³„ì‚°
            days_ahead = (target_weekday - now.weekday()) % 7
            target_date = now + timedelta(days=days_ahead)
            
            result = target_date.strftime('%Y-%m-%d')
            self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
            return result
        
        # 1.6ì°¨: ì›”/ì¼ íŒ¨í„´ ì§ì ‘ ì²˜ë¦¬ (LLM í˜¸ì¶œ ìµœì í™”)
        # ê¸°ë³¸ ì›”/ì¼ íŒ¨í„´: "10ì›” 3ì¼"
        month_day_pattern = r"(\d{1,2})ì›”\s*(\d{1,2})ì¼"
        m = re.match(month_day_pattern, date_str.strip())
        if m:
            month = int(m.group(1))
            day = int(m.group(2))
            
            # ì˜¬í•´ ê¸°ì¤€ìœ¼ë¡œ ë‚ ì§œ ìƒì„±
            try:
                target_date = datetime(now.year, month, day)
                # ì´ë¯¸ ì§€ë‚œ ë‚ ì§œë©´ ë‚´ë…„ìœ¼ë¡œ
                if target_date < now:
                    target_date = datetime(now.year + 1, month, day)
                result = target_date.strftime('%Y-%m-%d')
                self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
                return result
            except ValueError:
                pass  # ì˜ëª»ëœ ë‚ ì§œë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        
        # 1.6.1ì°¨: ì—°ë„ í¬í•¨ ì›”/ì¼ íŒ¨í„´: "ì˜¬í•´ 12ì›” 25ì¼", "ë‚´ë…„ 5ì›” 10ì¼"
        year_month_day_pattern = r"(ì˜¬í•´|ë‚´ë…„)?\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼"
        m = re.match(year_month_day_pattern, date_str.strip())
        if m:
            year_type = m.group(1)
            month = int(m.group(2))
            day = int(m.group(3))
            
            try:
                if year_type == "ë‚´ë…„":
                    target_date = datetime(now.year + 1, month, day)
                else:  # "ì˜¬í•´" ë˜ëŠ” ìƒëµ (ì˜¬í•´ ê¸°ì¤€)
                    target_date = datetime(now.year, month, day)
                    # ì´ë¯¸ ì§€ë‚œ ë‚ ì§œë©´ ë‚´ë…„ìœ¼ë¡œ
                    if target_date < now:
                        target_date = datetime(now.year + 1, month, day)
                
                result = target_date.strftime('%Y-%m-%d')
                self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
                return result
            except ValueError:
                pass  # ì˜ëª»ëœ ë‚ ì§œë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        
        # 1.6.2ì°¨: ìƒëŒ€ í‘œí˜„ íŒ¨í„´: "3ì¼ ë’¤", "2ì£¼ í›„", "1ê°œì›” í›„"
        relative_patterns = [
            # ì¼ ë‹¨ìœ„: "3ì¼ ë’¤", "5ì¼ í›„", "ì¼ì£¼ì¼ í›„"
            (r"(\d+)\s*ì¼\s*(ë’¤|í›„)", lambda m: now + timedelta(days=int(m.group(1)))),
            (r"ì¼ì£¼ì¼\s*(ë’¤|í›„)", lambda m: now + timedelta(days=7)),
            (r"í•œì£¼\s*(ë’¤|í›„)", lambda m: now + timedelta(days=7)),
            # ì£¼ ë‹¨ìœ„: "2ì£¼ í›„", "3ì£¼ ë’¤"
            (r"(\d+)\s*ì£¼\s*(ë’¤|í›„)", lambda m: now + timedelta(weeks=int(m.group(1)))),
            # ê°œì›” ë‹¨ìœ„: "1ê°œì›” í›„", "2ê°œì›” ë’¤"
            (r"(\d+)\s*ê°œì›”\s*(ë’¤|í›„)", lambda m: now + timedelta(days=int(m.group(1)) * 30)),  # ê·¼ì‚¬ì¹˜
            # ë…„ ë‹¨ìœ„: "1ë…„ í›„", "2ë…„ ë’¤"
            (r"(\d+)\s*ë…„\s*(ë’¤|í›„)", lambda m: now + timedelta(days=int(m.group(1)) * 365)),  # ê·¼ì‚¬ì¹˜
        ]
        
        for pattern, handler in relative_patterns:
            m = re.match(pattern, date_str.strip())
            if m:
                try:
                    target_date = handler(m)
                    result = target_date.strftime('%Y-%m-%d')
                    self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
                    return result
                except (ValueError, OverflowError):
                    pass  # ì˜ëª»ëœ ë‚ ì§œë©´ ë‹¤ìŒ íŒ¨í„´ ì‹œë„
        
        # 1.7ì°¨: ìì—°ì–´ ë‚ ì§œ íŒ¨í„´ ì§ì ‘ ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
        natural_date_patterns = [
            # "ì´ë²ˆ ë‹¬ 15ì¼", "ë‹¤ìŒ ë‹¬ 20ì¼" íŒ¨í„´
            (r"(ì´ë²ˆ\s*ë‹¬|ë‹¤ìŒ\s*ë‹¬|ë‹¤ë‹¤ìŒ\s*ë‹¬)\s*(\d{1,2})ì¼", self._parse_month_day_natural),
            # "ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼", "ë‹¤ìŒ ì£¼ ì›”ìš”ì¼" íŒ¨í„´ (ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)
            # "ì´ë²ˆ ë‹¬ ë§ˆì§€ë§‰ ë‚ " íŒ¨í„´
            (r"(ì´ë²ˆ\s*ë‹¬|ë‹¤ìŒ\s*ë‹¬|ë‹¤ë‹¤ìŒ\s*ë‹¬)\s*ë§ˆì§€ë§‰\s*ë‚ ", self._parse_month_last_day),
            # "ì´ë²ˆ ë‹¬ ì²«ì§¸ ì£¼ ê¸ˆìš”ì¼" íŒ¨í„´
            (r"(ì´ë²ˆ\s*ë‹¬|ë‹¤ìŒ\s*ë‹¬|ë‹¤ë‹¤ìŒ\s*ë‹¬)\s*ì²«ì§¸\s*ì£¼\s*(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼|í† ìš”ì¼|ì¼ìš”ì¼)", self._parse_month_first_week),
        ]
        
        for pattern, handler in natural_date_patterns:
            m = re.search(pattern, date_str.strip())
            if m:
                try:
                    result = handler(m, now)
                    if result:
                        logger.debug(f"ìì—°ì–´ ë‚ ì§œ ì²˜ë¦¬ ì„±ê³µ: '{date_str}' â†’ '{result}'")
                        self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
                        return result
                except Exception as e:
                    logger.debug(f"ìì—°ì–´ ë‚ ì§œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)[:50]}...")
                    pass  # ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ íŒ¨í„´ ì‹œë„
        
        # 2ì°¨: dateparserë¡œ ìì—°ì–´ ë‚ ì§œ íŒŒì‹± ì‹œë„
        try:
            parsed_date = dateparser.parse(
                date_str, 
                settings={
                    'RELATIVE_BASE': now,
                    'PREFER_DATES_FROM': 'future',
                    'DATE_ORDER': 'YMD'
                }, 
                languages=['ko', 'en']
            )
            if parsed_date:
                result = parsed_date.strftime('%Y-%m-%d')
                self._add_to_date_cache(date_str, result)  # ìºì‹œì— ì €ì¥
                return result
        except Exception:
            pass
        
        # 3ì°¨: LLM fallback (íŠ¹ìˆ˜í•œ ê²½ìš°ë‚˜ ë¬¸í™”ì  ë‚ ì§œ) - confidence ê¸°ë°˜ ê²€ì¦
        try:
            llm_prompt = f"""
ì‚¬ìš©ìê°€ ë§í•œ ë‚ ì§œ í‘œí˜„: "{date_str}"
ì˜¤ëŠ˜ ë‚ ì§œ: {now.strftime('%Y-%m-%d')}

1. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.
2. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ guessí•˜ì§€ ë§ê³  confidenceë¥¼ "low"ë¡œ í‘œì‹œí•˜ì„¸ìš”.
3. ì• ë§¤í•˜ê±°ë‚˜ ëª¨í˜¸í•œ í‘œí˜„ì€ dateë¥¼ nullë¡œ ë‘ê³  confidenceë¥¼ "low"ë¡œ ì„¤ì •í•˜ì„¸ìš”.

ì¶œë ¥ JSON í˜•ì‹:
{{
    "date": "<YYYY-MM-DD or null>",
    "confidence": "high" | "low"
}}

ì˜ˆì‹œ:
- "ë‹¤ìŒì£¼ ê¸ˆìš”ì¼" â†’ {{"date": "2025-09-26", "confidence": "high"}}
- "ë‹¤ìŒ ë‹¬ 15ì¼" â†’ {{"date": "2025-10-15", "confidence": "high"}}
- "ì˜¬í•´ í¬ë¦¬ìŠ¤ë§ˆìŠ¤" â†’ {{"date": "2025-12-25", "confidence": "high"}}
- "ì„¤ë‚ " â†’ {{"date": null, "confidence": "low"}} (ì—°ë„ ë¶ˆëª…í™•)
- "ë‹¤ìŒ ìƒì¼" â†’ {{"date": null, "confidence": "low"}} (êµ¬ì²´ì  ë‚ ì§œ ë¶ˆëª…í™•)
"""
            
            response = self.llm.invoke(llm_prompt)
            if hasattr(response, 'content'):
                # ì•ˆì „í•œ JSON íŒŒì‹± (responseê°€ stringì¼ ê²½ìš° ëŒ€ë¹„)
                try:
                    result = json.loads(str(response.content))
                    # confidenceê°€ highì´ê³  dateê°€ ìˆì„ ë•Œë§Œ ë°˜í™˜
                    if result.get("confidence") == "high" and result.get("date"):
                        self._add_to_date_cache(date_str, result["date"])  # ìºì‹œì— ì €ì¥
                        return result["date"]
                    # confidenceê°€ lowì´ë©´ None ë°˜í™˜ (ì‚¬ìš©ì ì¬ì§ˆë¬¸ í•„ìš”)
                    elif result.get("confidence") == "low":
                        return None
                except (json.JSONDecodeError, TypeError):
                    pass  # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        except Exception:
            pass
        
        # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ë°˜í™˜
        return date_str

    def _parse_month_day_natural(self, match, now: datetime) -> str:
        """ìì—°ì–´ ì›”/ì¼ íŒ¨í„´ íŒŒì‹± (ì´ë²ˆ ë‹¬ 15ì¼, ë‹¤ìŒ ë‹¬ 20ì¼)"""
        month_type = match.group(1)
        day = int(match.group(2))
        
        if "ì´ë²ˆ" in month_type:
            target_month = now.month
            target_year = now.year
        elif "ë‹¤ìŒ" in month_type:
            if now.month == 12:
                target_month = 1
                target_year = now.year + 1
            else:
                target_month = now.month + 1
                target_year = now.year
        else:  # ë‹¤ë‹¤ìŒ ë‹¬
            if now.month >= 11:
                target_month = now.month + 2 - 12
                target_year = now.year + 1
            else:
                target_month = now.month + 2
                target_year = now.year
        
        try:
            target_date = datetime(target_year, target_month, day)
            return target_date.strftime('%Y-%m-%d')
        except ValueError:
            return None

    def _parse_month_last_day(self, match, now: datetime) -> str:
        """ì›” ë§ˆì§€ë§‰ ë‚  íŒ¨í„´ íŒŒì‹± (ì´ë²ˆ ë‹¬ ë§ˆì§€ë§‰ ë‚ )"""
        month_type = match.group(1)
        
        if "ì´ë²ˆ" in month_type:
            target_month = now.month
            target_year = now.year
        elif "ë‹¤ìŒ" in month_type:
            if now.month == 12:
                target_month = 1
                target_year = now.year + 1
            else:
                target_month = now.month + 1
                target_year = now.year
        else:  # ë‹¤ë‹¤ìŒ ë‹¬
            if now.month >= 11:
                target_month = now.month + 2 - 12
                target_year = now.year + 1
            else:
                target_month = now.month + 2
                target_year = now.year
        
        # í•´ë‹¹ ì›”ì˜ ë§ˆì§€ë§‰ ë‚  ê³„ì‚°
        if target_month == 12:
            next_month = 1
            next_year = target_year + 1
        else:
            next_month = target_month + 1
            next_year = target_year
        
        last_day = datetime(next_year, next_month, 1) - timedelta(days=1)
        return last_day.strftime('%Y-%m-%d')

    def _parse_month_first_week(self, match, now: datetime) -> str:
        """ì›” ì²«ì§¸ ì£¼ ìš”ì¼ íŒ¨í„´ íŒŒì‹± (ì´ë²ˆ ë‹¬ ì²«ì§¸ ì£¼ ê¸ˆìš”ì¼)"""
        month_type = match.group(1)
        weekday_name = match.group(2)
        
        weekday_map = {
            "ì›”ìš”ì¼": 0, "í™”ìš”ì¼": 1, "ìˆ˜ìš”ì¼": 2, "ëª©ìš”ì¼": 3, 
            "ê¸ˆìš”ì¼": 4, "í† ìš”ì¼": 5, "ì¼ìš”ì¼": 6
        }
        target_weekday = weekday_map[weekday_name]
        
        if "ì´ë²ˆ" in month_type:
            target_month = now.month
            target_year = now.year
        elif "ë‹¤ìŒ" in month_type:
            if now.month == 12:
                target_month = 1
                target_year = now.year + 1
            else:
                target_month = now.month + 1
                target_year = now.year
        else:  # ë‹¤ë‹¤ìŒ ë‹¬
            if now.month >= 11:
                target_month = now.month + 2 - 12
                target_year = now.year + 1
            else:
                target_month = now.month + 2
                target_year = now.year
        
        # í•´ë‹¹ ì›”ì˜ ì²«ì§¸ ì£¼ í•´ë‹¹ ìš”ì¼ ì°¾ê¸°
        first_day = datetime(target_year, target_month, 1)
        days_ahead = (target_weekday - first_day.weekday()) % 7
        target_date = first_day + timedelta(days=days_ahead)
        
        return target_date.strftime('%Y-%m-%d')

    def _check_date_normalization_failure(self, entities: Dict[str, List[Dict[str, Any]]]) -> Optional[str]:
        """ë‚ ì§œ ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì¬ì§ˆë¬¸í•˜ëŠ” ë©”ì‹œì§€ ìƒì„± (ëª¨ë“  ë‚ ì§œ ì—”í‹°í‹° ê²€ì‚¬)"""
        if not entities:
            return None
            
        # ëª¨ë“  ë‚ ì§œ ê´€ë ¨ ì—”í‹°í‹°ì—ì„œ ë‚ ì§œ ì •ê·œí™” ì‹¤íŒ¨ í™•ì¸
        date_entity_types = ["user.ì¼ì •", "user.ì•½", "user.ì‹ì‚¬", "user.ê¸°ë…ì¼", "user.ê±´ê°•ìƒíƒœ"]
        
        for entity_type, entity_list in entities.items():
            if entity_type in date_entity_types and isinstance(entity_list, list):
                for entity in entity_list:
                    if isinstance(entity, dict) and "ë‚ ì§œ" in entity:
                        date_value = entity["ë‚ ì§œ"]
                        # ë‚ ì§œê°€ ì •ê·œí™”ë˜ì§€ ì•Šì€ ì›ë³¸ ë¬¸ìì—´ì¸ ê²½ìš°
                        if date_value and not self._is_normalized_date(date_value):
                            # ë¨¼ì € ë‚ ì§œ ì •ê·œí™” ì‹œë„
                            normalized_date = self._normalize_date(date_value)
                            # ì •ê·œí™”ê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜ ì›ë³¸ê³¼ ë™ì¼í•˜ë©´ ì¬ì§ˆë¬¸
                            if normalized_date == date_value or not self._is_normalized_date(normalized_date):
                                # ì¼ì • ì—”í‹°í‹°ì—ì„œ ì œëª©ì´ ë‚ ì§œ í•„ë“œì— ì˜ëª» ë“¤ì–´ê°„ ê²½ìš° ìŠ¤í‚µ
                                if entity_type == "user.ì¼ì •" and "ì œëª©" in entity and entity["ì œëª©"] == date_value:
                                    continue
                                # ì›”/ì¼ íŒ¨í„´ì€ ì •ê·œí™”ê°€ ê°€ëŠ¥í•˜ë¯€ë¡œ ìŠ¤í‚µ
                                if re.match(r'\d{1,2}ì›”\s*\d{1,2}ì¼', date_value):
                                    continue
                                # ì¼ì • ì—”í‹°í‹°ì—ì„œ ì œëª© íŒ¨í„´ì´ ë‚ ì§œ í•„ë“œì— ë“¤ì–´ê°„ ê²½ìš° ìŠ¤í‚µ
                                if entity_type == "user.ì¼ì •" and any(re.search(pattern, date_value) for pattern in [r'(ì—¬í–‰|íŒŒí‹°|íšŒì˜|ì•½ì†|ë¯¸íŒ…|ë°ì´íŠ¸|ì¼ì •|ìŠ¤ì¼€ì¤„|ì˜ˆì•½)', r'(ë³‘ì›|ì¹˜ê³¼|ì•½êµ­|ì€í–‰|ìš°ì²´êµ­)']):
                                    continue
                                return f"'{date_value}'ë¼ëŠ” ë‚ ì§œ í‘œí˜„ì´ ëª…í™•í•˜ì§€ ì•Šë„¤ìš”. êµ¬ì²´ì ì¸ ë‚ ì§œë¡œ ë§ì”€í•´ì£¼ì‹¤ë˜ìš”? (ì˜ˆ: 'ë‹¤ìŒì£¼ ê¸ˆìš”ì¼', '12ì›” 25ì¼' ë“±)"
        
        return None

    def _is_normalized_date(self, date_str: str) -> bool:
        """ë‚ ì§œ ë¬¸ìì—´ì´ ì •ê·œí™”ëœ í˜•ì‹ì¸ì§€ í™•ì¸ (YYYY-MM-DD)"""
        if not date_str:
            return False
        try:
            datetime.strptime(date_str, '%Y-%m-%d')
            return True
        except ValueError:
            return False

    def _extract_name_llm(self, text: str) -> Optional[Dict[str, str]]:
        """LLM ê¸°ë°˜ ì´ë¦„ ë° ë³„ì¹­ ì¶”ì¶œ (ë¬¸ë§¥ ì´í•´)"""
        try:
            llm_prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ë°œí™”ì—ì„œ **ì‚¬ìš©ì ë³¸ì¸ì˜ ì´ë¦„ê³¼ ë³„ì¹­**ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë°œí™”: "{text}"

ì¤‘ìš” ê·œì¹™:
1. **ì‚¬ìš©ì ë³¸ì¸ì˜ ì´ë¦„ë§Œ** ì¶”ì¶œ (í•œê¸€ 2-4ê¸€ì, ì˜ë¬¸ ì´ë¦„, ë³„ëª… ë“±)
2. **ë‹¤ë¥¸ ì‚¬ëŒì˜ ì´ë¦„ì€ ì ˆëŒ€ ì œì™¸** (ê°€ì¡±, ì¹œêµ¬, ë™ë£Œ, ì„ ìƒë‹˜ ë“± ëª¨ë“  ê´€ê³„ì˜ ì‚¬ëŒ ì´ë¦„)
3. **"ë‚´ ì´ë¦„ì€", "ë‚˜ëŠ”", "ì €ëŠ”", "ë‚œ", "ë‚´ê°€" ë“±ì´ í¬í•¨ëœ ê²½ìš°ë§Œ** ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ ì¸ì‹
4. **ë¬¸ë§¥ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ì‚¬ìš©ì ë³¸ì¸ ì´ë¦„ë§Œ ì¶”ì¶œ**
5. **ê´€ê³„ê°€ ì–¸ê¸‰ëœ ê²½ìš° (ë™ìƒ, ì—„ë§ˆ, ì•„ë¹ , ë‚¨ìì¹œêµ¬, ë™ë£Œ ë“±) ê·¸ ì‚¬ëŒì˜ ì´ë¦„ì€ ì‚¬ìš©ì ì´ë¦„ì´ ì•„ë‹˜**
6. **íŠ¹íˆ ì£¼ì˜í•  ê²ƒ:**
   - "ìš°ë¦¬ ì—„ë§ˆ ì´ë¦„ì€ ê¹€ì˜í¬ì•¼" â†’ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ (ê°€ì¡± ì´ë¦„)
   - "ë‚˜ëŠ” í™ê¸¸ë™ì´ì•¼" â†’ ì¶”ì¶œí•¨ (ì‚¬ìš©ì ì´ë¦„)
   - "ë™ìƒ ì² ìˆ˜" â†’ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ (ê°€ì¡± ì´ë¦„)
   - "ë‚´ ë™ìƒì€ í˜„ìš°ì•¼" â†’ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ (ê°€ì¡± ì´ë¦„)
7. ë³„ì¹­ì´ ìˆë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œ ("í¸í•˜ê²Œ ì„œì—°ì´ë¼ê³  ë¶ˆëŸ¬ë„ ë¼" â†’ ë³„ì¹­: "ì„œì—°")
8. ì‚¬ìš©ì ë³¸ì¸ ì´ë¦„ì´ ì—†ìœ¼ë©´ null ë°˜í™˜

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{"name": "ì‚¬ìš©ìë³¸ì¸ì´ë¦„", "alias": "ë³„ì¹­" ë˜ëŠ” null, "confidence": 0.0-1.0}}

confidenceëŠ” ì´ë¦„ ì¶”ì¶œì˜ í™•ì‹ ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤:
- 0.9-1.0: ë§¤ìš° í™•ì‹  (ëª…í™•í•œ ì´ë¦„ í‘œí˜„)
- 0.7-0.8: ë†’ì€ í™•ì‹  (ì´ë¦„ í‘œí˜„ì´ ìˆìŒ)
- 0.5-0.6: ì¤‘ê°„ í™•ì‹  (ì¶”ì¸¡ ê°€ëŠ¥)
- 0.0-0.4: ë‚®ì€ í™•ì‹  (ë¶ˆí™•ì‹¤)

ì˜ˆì‹œ (ì˜¬ë°”ë¥¸ ì¶”ì¶œ):
- "ë‚´ ì´ë¦„ì€ ì‚¬ì‹¤ ê¶Œì„œì—°ì¸ë°" â†’ {{"name": "ê¶Œì„œì—°", "alias": null, "confidence": 0.9}}
- "í¸í•˜ê²Œ ì„œì—°ì´ë¼ê³  ë¶ˆëŸ¬" â†’ {{"name": null, "alias": "ì„œì—°", "confidence": 0.8}}
- "ë‚˜ ê¶Œì„œì—°ì´ì•¼" â†’ {{"name": "ê¶Œì„œì—°", "alias": null, "confidence": 0.9}}
- "ë‚´ ì´ë¦„ì€ ê¶Œì„œì—°ì´ì•¼. ê·¼ë° í¸í•˜ê²Œ ì„œì—°ì´ë¼ê³  ë¶ˆëŸ¬ë„ ë¼" â†’ {{"name": "ê¶Œì„œì—°", "alias": "ì„œì—°", "confidence": 0.9}}

ì˜ˆì‹œ (ê°€ì¡± ì´ë¦„ - ì¶”ì¶œí•˜ì§€ ì•ŠìŒ):
- "ìš°ë¦¬ ë™ìƒ ì´ë¦„ì€ ì„ì„±í˜„ì´ê³ " â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ë‚´ë™ìƒì´ë¦„ì€ ì—„ì„±í˜„ì´ì•¼" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ë‚´ì—„ë§ˆì´ë¦„ì€ ì „ì§€í˜„ì´ì•¼" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ì—„ë§ˆ ì´ë¦„ì€ ì „ì§€í˜„ì´ì•¼" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ì•„ë¹ ëŠ” ê¹€ë¯¼ìˆ˜ë¼ê³  í•´" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ìš°ë¦¬ í˜•ì€ ê¹€ì² ìˆ˜ì•¼" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "ë™ìƒ í˜„ìš°" â†’ {{"name": null, "alias": null, "confidence": 0.9}}
- "í• ë¨¸ë‹ˆ ìµœì˜í¬" â†’ {{"name": null, "alias": null, "confidence": 0.9}}

ì˜ˆì‹œ (ê¸°íƒ€ - ì¶”ì¶œí•˜ì§€ ì•ŠìŒ):
- "ì‚¬ì‹¤ ì¢‹ì•„í•´" â†’ {{"name": null, "alias": null, "confidence": 0.2}}
- "í¸í•˜ê²Œ ë¶ˆëŸ¬ë„ ë¼" â†’ {{"name": null, "alias": null, "confidence": 0.1}}
"""
            
            response = self.llm.invoke(llm_prompt)
            if hasattr(response, 'content'):
                # ì•ˆì „í•œ JSON íŒŒì‹± (responseê°€ stringì¼ ê²½ìš° ëŒ€ë¹„)
                try:
                    result = json.loads(str(response.content))
                    name = result.get('name')
                    alias = result.get('alias')
                    confidence = result.get('confidence', 0.0)
                    
                    # í™•ì‹ ë„ê°€ 0.7 ì´ìƒì¼ ë•Œë§Œ LLM ê²°ê³¼ ì‚¬ìš©
                    if confidence >= 0.7 and name and self._is_valid_name(name):
                        # ì´ë¦„ ì •ê·œí™” ì ìš© (LLM ê²°ê³¼ë„ ì •ê·œí™”)
                        normalized_name = self._normalize_name(name)
                        if normalized_name and self._is_valid_name(normalized_name):
                            logger.debug(f"LLM ì´ë¦„ ì¶”ì¶œ ì„±ê³µ: name='{normalized_name}', alias='{alias}', confidence={confidence}")
                            return {"name": normalized_name, "alias": alias, "confidence": confidence}
                        else:
                            logger.debug(f"LLM ì´ë¦„ ì¶”ì¶œ ì‹¤íŒ¨: ì •ê·œí™” í›„ ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¦„ '{normalized_name}'")
                    else:
                        logger.debug(f"LLM ì´ë¦„ ì¶”ì¶œ ì‹¤íŒ¨: ë‚®ì€ í™•ì‹ ë„({confidence}) ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¦„ '{name}'")
                        
                except (json.JSONDecodeError, TypeError) as e:
                    logger.warning(f"ì´ë¦„ ì¶”ì¶œ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}...")
        except Exception as e:
            logger.warning(f"ì´ë¦„ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)[:50]}...")
        return None

    def _analyze_emotional_state(self, text: str) -> dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ìƒíƒœ ë¶„ì„"""
        negative_keywords = ["í”¼ê³¤", "í˜ë“¤", "ì–´ì§€ëŸ½", "ë°”ë‹¥", "ìŠ¬í¼", "ìš°ìš¸", "ì§œì¦", "í™”ë‚˜", "ë‹µë‹µí•´", "ê´´ë¡œì›Œ", "ì•„í””", "ìƒì²˜", "ì‹¤ë§"]
        positive_keywords = ["ì¢‹ì•„", "ê¸°ë»", "í–‰ë³µ", "ì‹ ë‚˜", "ì¦ê±°ì›Œ", "ë§Œì¡±", "ë¿Œë“¯", "ê¸°ì˜", "ì›ƒìŒ", "ì¦ê²"]
        
        text_lower = text.lower()
        negative_count = sum(1 for word in negative_keywords if word in text_lower)
        positive_count = sum(1 for word in positive_keywords if word in text_lower)
        
        if negative_count > positive_count:
            return {"mood": "negative", "intensity": min(negative_count * 0.3, 1.0)}
        elif positive_count > negative_count:
            return {"mood": "positive", "intensity": min(positive_count * 0.3, 1.0)}
        else:
            return {"mood": "neutral", "intensity": 0.5}

    def _should_maintain_emotional_context(self, session_id: str, current_category: str) -> bool:
        """ê°ì •ì  ë§¥ë½ì„ ìœ ì§€í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
        if session_id not in self.emotional_state:
            return False
        
        emotional_info = self.emotional_state[session_id]
        # ìµœê·¼ 3í„´ ì´ë‚´ì— ê°•í•œ ê°ì •ì´ ìˆì—ˆê³ , í˜„ì¬ê°€ ê¸°ëŠ¥ì  ìš”ì²­ì¸ ê²½ìš°
        if (emotional_info.get("intensity", 0) > 0.6 and 
            emotional_info.get("last_emotional_turn", 0) <= 3 and
            current_category in ["cognitive", "physical"]):
            return True
        return False

    def _is_valid_name(self, name: str) -> bool:
        """ì´ë¦„ ìœ íš¨ì„± ê²€ì¦ (ìœ ì—°í•œ ê¸¸ì´ ì œí•œ)"""
        if not name or len(name) < 2:
            return False
        
        # ë¶€ì‚¬/í˜•ìš©ì‚¬/ì¼ë°˜ ë‹¨ì–´ ì œì™¸
        invalid_words = {
            "ì‚¬ì‹¤", "í¸í•˜ê²Œ", "ê·¸ëƒ¥", "ì •ë§", "ì§„ì§œ", "ì™„ì „", "ë„ˆë¬´", "ì •ë§ë¡œ",
            "ê·¸ëŸ¬ë©´", "ê·¸ë˜ì„œ", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ¬ë‚˜",
            "ì¢‹ì•„", "ì‹«ì–´", "ì¢‹ë‹¤", "ì‹«ë‹¤", "ë§ë‹¤", "í‹€ë¦¬ë‹¤",
            "ì´ë¦„", "ë‚˜", "ë‚´", "ì €", "ì œ", "ìš°ë¦¬", "ë„ˆ", "ë‹¹ì‹ "
        }
        
        if name in invalid_words:
            return False
        
        # í•œê¸€ ì´ë¦„ íŒ¨í„´ (2-5ê¸€ì) - í˜„ìˆ˜ë¯¼, ê¹€ì² ìˆ˜ë¯¼ ë“± ê¸´ ì´ë¦„ ì§€ì›
        if re.match(r'^[ê°€-í£]{2,5}$', name):
            return True
        
        # ì˜ë¬¸ ì´ë¦„ íŒ¨í„´ (2-15ê¸€ì) - Alexander, Christopher ë“± ê¸´ ì´ë¦„ ì§€ì›
        if re.match(r'^[a-zA-Z]{2,15}$', name):
            return True
        
        return False

    def _extract_nickname(self, text: str) -> Optional[str]:
        """ì‚¬ìš©ìê°€ ì œì•ˆí•œ ë³„ì¹­ ì¶”ì¶œ (deprecated - LLM ê¸°ë°˜ ì¶”ì¶œ ì‚¬ìš©)"""
        # í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ë§¤ì¹­ ì œê±°ë¨. ë³„ëª… ì¶”ì¶œì€ entity_chainì˜ LLMì´ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        return None

    def _is_name_question(self, text: str) -> bool:
        """ì´ë¦„ í™•ì¸ ì§ˆë¬¸ íŒ¨í„´ í™•ì¸"""
        question_patterns = [
            r"ë‚´\s*ì´ë¦„ì´?\s*ë­ë¼ê³ ?",
            r"ë‚´\s*ì´ë¦„\s*ì•Œì•„?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì•¼?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì§€?",
            r"ë‚´\s*ì´ë¦„\s*ê¸°ì–µí•´?",
            r"ë‚´\s*ì´ë¦„\s*ë­”ì§€\s*ì•Œì•„?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì˜€ì§€?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì˜€ì–´?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì˜€ì£ ?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì˜€ë‚˜?",
            r"ë‚´\s*ì´ë¦„\s*ë­ì˜€ë”ë¼?"
        ]
        
        return any(re.search(pattern, text, re.IGNORECASE) for pattern in question_patterns)

    def _merge_user_entities(self, existing_entities: List[Dict], new_entity: Dict) -> List[Dict]:
        """ì‚¬ìš©ì ì—”í‹°í‹° ë³‘í•© ë¡œì§ ê°œì„ """
        if not existing_entities:
            return [new_entity]
        
        # ê¸°ì¡´ ì—”í‹°í‹°ì™€ ìƒˆ ì—”í‹°í‹° ë¹„êµ
        existing = existing_entities[0]
        new_name = new_entity.get("ì´ë¦„", "")
        new_aliases = new_entity.get("ë³„ì¹­", [])
        
        # ì´ë¦„ì´ ê°™ì€ ê²½ìš°
        if existing.get("ì´ë¦„") == new_name:
            # ë³„ì¹­ ë³‘í•©
            if new_aliases:
                existing_aliases = existing.get("ë³„ì¹­", [])
                for alias in new_aliases:
                    if alias not in existing_aliases:
                        existing_aliases.append(alias)
                existing["ë³„ì¹­"] = existing_aliases
            return existing_entities
        
        # ë³„ì¹­ê³¼ ë³¸ëª… ë§¤ì¹­ í™•ì¸
        existing_name = existing.get("ì´ë¦„", "")
        existing_aliases = existing.get("ë³„ì¹­", [])
        
        # ìƒˆ ì´ë¦„ì´ ê¸°ì¡´ ë³„ì¹­ê³¼ ê°™ì€ ê²½ìš°
        if new_name in existing_aliases:
            # ìƒˆ ì´ë¦„ì„ ë³„ì¹­ì—ì„œ ì œê±°í•˜ê³  ë³¸ëª…ìœ¼ë¡œ ì„¤ì •
            existing_aliases.remove(new_name)
            existing["ì´ë¦„"] = new_name
            existing["ë³„ì¹­"] = existing_aliases
            return existing_entities
        
        # ê¸°ì¡´ ì´ë¦„ì´ ìƒˆ ë³„ì¹­ê³¼ ê°™ì€ ê²½ìš°
        if existing_name in new_aliases:
            # ê¸°ì¡´ ì´ë¦„ì„ ë³„ì¹­ìœ¼ë¡œ ì´ë™
            existing_aliases = existing.get("ë³„ì¹­", [])
            if existing_name not in existing_aliases:
                existing_aliases.append(existing_name)
            existing["ì´ë¦„"] = new_name
            existing["ë³„ì¹­"] = existing_aliases
            return existing_entities
        
        # ë¶€ë¶„ ë§¤ì¹­ í™•ì¸ (ê¶Œì„œì—° vs ì„œì—°)
        if self._is_name_variant(existing_name, new_name):
            # ë” ê¸´ ì´ë¦„ì„ ë³¸ëª…ìœ¼ë¡œ, ì§§ì€ ì´ë¦„ì„ ë³„ì¹­ìœ¼ë¡œ
            if len(existing_name) > len(new_name):
                existing_aliases = existing.get("ë³„ì¹­", [])
                if new_name not in existing_aliases:
                    existing_aliases.append(new_name)
                existing["ë³„ì¹­"] = existing_aliases
            else:
                existing_aliases = existing.get("ë³„ì¹­", [])
                if existing_name not in existing_aliases:
                    existing_aliases.append(existing_name)
                existing["ì´ë¦„"] = new_name
                existing["ë³„ì¹­"] = existing_aliases
            return existing_entities
        
        # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ìƒˆ ì—”í‹°í‹° ì¶”ê°€
        return existing_entities + [new_entity]

    def _is_name_variant(self, name1: str, name2: str) -> bool:
        """ë‘ ì´ë¦„ì´ ë³€í˜• ê´€ê³„ì¸ì§€ í™•ì¸ (ê¶Œì„œì—° vs ì„œì—°)"""
        if not name1 or not name2:
            return False
        
        # ê³µë°± ì œê±° í›„ ë¹„êµ
        clean1 = name1.replace(" ", "")
        clean2 = name2.replace(" ", "")
        
        # í•œ ì´ë¦„ì´ ë‹¤ë¥¸ ì´ë¦„ì˜ ëë¶€ë¶„ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        return clean1.endswith(clean2) or clean2.endswith(clean1)

    def _get_existing_user_entities(self, session_id: str) -> List[Dict]:
        """ê¸°ì¡´ ì‚¬ìš©ì ì—”í‹°í‹° ì¡°íšŒ"""
        try:
            docs = self.vectorstore.get()
            existing_users = []
            
            for i, doc_id in enumerate(docs.get("ids", [])):
                if doc_id.startswith(f"{session_id}_user.ì‚¬ìš©ì"):
                    try:
                        data = json.loads(docs["documents"][i])
                        if (data.get("entity_key") == "user.ì‚¬ìš©ì" and 
                            data.get("session_id") == session_id):
                            existing_users.append(data)
                    except (json.JSONDecodeError, TypeError):
                        continue
            
            return existing_users
        except Exception as e:
            print(f"[WARN] ê¸°ì¡´ ì‚¬ìš©ì ì—”í‹°í‹° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _process_single_entity(self, entity_key: str, filtered_value: Dict, session_id: str, questions: List[str], has_schedule: bool) -> bool:
        """ë‹¨ì¼ ì—”í‹°í‹° ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ì„ ë©”ì„œë“œë¡œ ë¶„ë¦¬)"""
        try:
            # ì¼ì • ì €ì¥ í™•ì¸
            if entity_key.endswith("ì¼ì •"):
                has_schedule = True
            
            # ì‹ì‚¬ ì—”í‹°í‹°ì—ì„œ ì‹œê°„ì´ ì—†ìœ¼ë©´ ê°•ì œë¡œ ì§ˆë¬¸ ì¶”ê°€ (í•„ìˆ˜ í•„ë“œ ì²´í¬ì—ì„œ ì²˜ë¦¬ë¨)
            
            # ì•½ì„ ì‹ì‚¬ë¡œ ì°©ê°í•œ ê²½ìš° ì œê±°
            if entity_key.endswith("ì‹ì‚¬") and "ë©”ë‰´" in filtered_value:
                menus = filtered_value["ë©”ë‰´"]
                if isinstance(menus, list):
                    # ì•½ëª…ì´ í¬í•¨ëœ ë©”ë‰´ ì œê±°
                    filtered_menus = [menu for menu in menus if not menu.endswith("ì•½")]
                    if not filtered_menus:
                        # ëª¨ë“  ë©”ë‰´ê°€ ì•½ì´ë©´ ì´ ì‹ì‚¬ ì—”í‹°í‹° ì œê±°
                        print(f"[INFO] ì•½ì„ ì‹ì‚¬ë¡œ ì°©ê°í•œ ì—”í‹°í‹° ì œê±°: {entity_key} - {filtered_value}")
                        return has_schedule
                    filtered_value["ë©”ë‰´"] = filtered_menus
            
            # í•„ìˆ˜ í•„ë“œ ì²´í¬
            missing_fields = self._check_missing_fields(entity_key, filtered_value)

            if missing_fields:
                # 3ï¸âƒ£ í•„ìˆ˜ í•„ë“œê°€ ë¹„ë©´ follow-up ì§ˆë¬¸ ìƒì„± (ì €ì¥ì€ ë³´ë¥˜)
                logger.debug(f"ëˆ„ë½ëœ í•„ë“œ ê°ì§€: {entity_key} - {missing_fields}, ê°’: {filtered_value}")
                followup_questions = self._generate_followup_questions(entity_key, missing_fields, filtered_value)
                questions.extend(followup_questions)
                
                # ì‹ì‚¬ ì—”í‹°í‹°ëŠ” ë©”ë‰´ë‚˜ ì‹œê°„ì´ ì—†ì–´ë„ ì €ì¥ (ì ì§„ì  ì •ë³´ ìˆ˜ì§‘)
                if entity_key.endswith("ì‹ì‚¬") and (
                    ("ë©”ë‰´" in missing_fields and filtered_value.get("ë©”ë‰´") == []) or
                    ("ì‹œê°„" in missing_fields and not filtered_value.get("ì‹œê°„"))
                ):
                    # ë©”ë‰´ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ê±°ë‚˜ ì‹œê°„ì´ ì—†ëŠ” ê²½ìš°ì—ë„ ì €ì¥
                    final_value = self._add_to_vstore(
                        entity_key, filtered_value,
                        {"session_id": session_id, "entity_key": entity_key, "type": "entity", "created_at": datetime.now().isoformat()},
                        strategy="merge",
                        session_id=session_id
                    )
                    logger.debug(f"ì‹ì‚¬ ì—”í‹°í‹° ì„ì‹œ ì €ì¥ (ë©”ë‰´/ì‹œê°„ ëˆ„ë½): {filtered_value}")
                    
                    # ì‹œê°„ì´ ëˆ„ë½ëœ ê²½ìš° ì¬ì§ˆë¬¸ ìƒíƒœ ì„¤ì •
                    if "ì‹œê°„" in missing_fields and not filtered_value.get("ì‹œê°„"):
                        self.pending_question[session_id] = {
                            "ê¸°ì¡´_ì—”í‹°í‹°": final_value,
                            "ìƒˆ_ì—”í‹°í‹°": final_value,
                            "entity_key": entity_key
                        }
                        print(f"[DEBUG] ì¬ì§ˆë¬¸ ìƒíƒœ ì„¤ì •: {entity_key} - ì‹œê°„ ëˆ„ë½")
                else:
                    return has_schedule

            # 2ï¸âƒ£ ëª¨ë“  í•„ìˆ˜ í•„ë“œê°€ ìˆìœ¼ë©´ ì €ì¥ (merge ì •ì±… ì ìš©)
            final_value = self._add_to_vstore(
                entity_key, filtered_value,
                {"session_id": session_id, "entity_key": entity_key, "type": "entity", "created_at": datetime.now().isoformat()},
                strategy="merge"
            )

            # ì•½ì€ ë³µìš© ì •ë³´ ì„¸ë¶€ í•„ë“œ í™•ì¸ í›„ ì¶”ê°€ ì§ˆë¬¸
            if entity_key.endswith(".ì•½"):
                if final_value.get("ë³µìš©"):
                    enriched = [self._enrich_dose_dict(d) for d in final_value["ë³µìš©"]]
                    final_value["ë³µìš©"] = enriched
                    
                    # enrichëœ ì •ë³´ë¥¼ VectorStoreì— ì—…ë°ì´íŠ¸
                    try:
                        self._add_to_vstore(
                            entity_key=entity_key,
                            value=final_value,
                            metadata={"session_id": session_id, "type": "entity"},
                            strategy="merge",
                            identity=final_value.get("ì•½ëª…"),
                            session_id=session_id
                        )
                        # print(f"[DEBUG] ë³µìš© ì •ë³´ enrich í›„ VectorStore ì—…ë°ì´íŠ¸ ì™„ë£Œ: {final_value.get('ì•½ëª…')}")
                    except Exception as e:
                        print(f"[WARN] ë³µìš© ì •ë³´ enrich í›„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                    
                    # ë³µìš© ì •ë³´ê°€ ì´ë¯¸ ìˆëŠ” ê²½ìš° ì¶”ê°€ ì§ˆë¬¸í•˜ì§€ ì•ŠìŒ
                    # "ë³µìš©" í•„ë“œê°€ ìˆìœ¼ë©´ ì¶©ë¶„í•œ ì •ë³´ë¡œ ê°„ì£¼
                    pass
            
            return has_schedule
            
        except Exception as e:
            print(f"[ERROR] ì—”í‹°í‹° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return has_schedule

    def _get_cached_classification(self, text: str, similarity_threshold: float = 0.85) -> Optional[Dict]:
        """ì„ë² ë”© ê¸°ë°˜ ìºì‹œì—ì„œ ìœ ì‚¬í•œ ë¶„ë¥˜ ê²°ê³¼ ì°¾ê¸°"""
        if not self.cache_texts or self.cache_embeddings is None:
            return None
        
        try:
            # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            input_embedding = self.vectorizer.transform([text])
            
            # ê¸°ì¡´ ìºì‹œì™€ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(input_embedding, self.cache_embeddings)[0]
            
            # ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼ ì°¾ê¸°
            max_similarity_idx = np.argmax(similarities)
            max_similarity = similarities[max_similarity_idx]
            
            if max_similarity >= similarity_threshold:
                cached_text = self.cache_texts[max_similarity_idx]
                cached_result = self.classification_cache.get(cached_text)
                if cached_result:
                    logger.debug(f"ìœ ì‚¬ë„ {max_similarity:.3f}ë¡œ ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©: '{cached_text}' â†’ '{text}'")
                    return cached_result.to_dict()
        
        except Exception as e:
            logger.warning(f"ìºì‹œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return None

    def _add_to_cache(self, text: str, result: Dict) -> None:
        """ë¶„ë¥˜ ê²°ê³¼ë¥¼ ìºì‹œì— ì¶”ê°€"""
        try:
            # ìºì‹œì— ê²°ê³¼ ì €ì¥
            self.classification_cache[text] = result
            
            # í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            self.cache_texts.append(text)
            
            # ì„ë² ë”© ì—…ë°ì´íŠ¸ (ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ ìœ ì§€)
            if len(self.cache_texts) > 100:
                # ì˜¤ë˜ëœ ê²ƒ ì œê±°
                old_text = self.cache_texts.pop(0)
                self.classification_cache.pop(old_text, None)
            
            # ì„ë² ë”© ì¬ê³„ì‚°
            if self.cache_texts:
                self.cache_embeddings = self.vectorizer.fit_transform(self.cache_texts)
            
        except Exception as e:
            logger.warning(f"ìºì‹œ ì¶”ê°€ ì‹¤íŒ¨: {e}")

    def _sync_to_exact_cache(self, user_input: str, result_dict: Dict, pre_entities: Dict = None) -> None:
        """ì •í™• ìºì‹œì— ë™ê¸°í™” (task_classifier.pyì˜ LRU ìºì‹œ)"""
        try:
            # task_classifierì˜ ìºì‹œ í•¨ìˆ˜ë“¤ì„ ë™ì ìœ¼ë¡œ import
            from .task_classifier import _add_to_cache as add_exact_cache, ClassificationResult
            
            # ì…ë ¥ ì •ê·œí™” (task_classifierì™€ ë™ì¼í•œ ë°©ì‹)
            import re
            norm_text = re.sub(r"\s+", " ", user_input.strip().lower())
            
            # ClassificationResult ê°ì²´ ìƒì„±
            category = result_dict.get("category", "query")
            confidence = result_dict.get("confidence", 0.5)
            probabilities = result_dict.get("probabilities", {category: 0.5})
            
            # Confidence threshold ì ìš© (task_classifier.pyì™€ ì¼ê´€ì„± ìœ ì§€)
            if confidence < CONFIDENCE_THRESHOLD:
                logger.warning(f"ë‚®ì€ confidenceë¡œ ì¸í•œ fallback: {confidence:.2f} < {CONFIDENCE_THRESHOLD}")
                # ë‚®ì€ confidenceì¼ ë•ŒëŠ” ê¸°ë³¸ ë¶„ë¥˜ ì‚¬ìš©
                from .task_classifier import classify
                category, _ = classify_hybrid(user_input, pre_entities)
                confidence = 0.5
                probabilities = {category: 0.5}
            
            classification_result = ClassificationResult(category, confidence, probabilities)
            
            # ì •í™• ìºì‹œì— ì¶”ê°€
            add_exact_cache(norm_text, classification_result)
            logger.debug(f"ì •í™• ìºì‹œ ë™ê¸°í™”: '{norm_text[:30]}...'")
            
        except Exception as e:
            logger.error(f"ì •í™• ìºì‹œ ë™ê¸°í™” ì‹¤íŒ¨: {str(e)[:50]}...")

    def _classify_with_cache(self, user_input: str, pre_entities: Dict[str, List[Dict[str, Any]]] = None) -> Dict:
        """ë‹¤ì¸µ ìºì‹œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ (ìºì‹œ ë™ê¸°í™”)"""
        # 1ì°¨: ì •í™• ìºì‹± (task_classifier.pyì—ì„œ ì²˜ë¦¬ë¨)
        # 2ì°¨: ìœ ì‚¬ ìºì‹± (ì„ë² ë”© ê¸°ë°˜)
        cached_result = self._get_cached_classification(user_input)
        if cached_result:
            logger.debug(f"ìœ ì‚¬ ìºì‹œ hit: '{user_input[:30]}...'")
            # ìœ ì‚¬ ìºì‹œ hit ì‹œ ì •í™• ìºì‹œì—ë„ ë™ê¸°í™”
            self._sync_to_exact_cache(user_input, cached_result, pre_entities)
            return cached_result
        
        # 3ì°¨: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ ì‹¤í–‰ (ì •í™• ìºì‹± í¬í•¨)
        try:
            classification_result = classify_hybrid(user_input, pre_entities)
            result_dict = classification_result.to_dict()
            
            # ì–‘ìª½ ìºì‹œì— ë™ê¸°í™”í•˜ì—¬ ì €ì¥
            self._add_to_cache(user_input, classification_result)  # ìœ ì‚¬ ìºì‹œ
            self._sync_to_exact_cache(user_input, result_dict, pre_entities)      # ì •í™• ìºì‹œ
            
            return result_dict
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ë¥˜ ì‚¬ìš©: {e}")
            # 4ì°¨: ê¸°ë³¸ ë¶„ë¥˜ fallback
            category, _ = classify_hybrid(user_input, pre_entities)
            fallback_result = {
                "category": category,
                "confidence": 0.5,
                "probabilities": {category: 0.5}
            }
            
            # fallback ê²°ê³¼ë„ ìºì‹œì— ì €ì¥
            self._sync_to_exact_cache(user_input, fallback_result)
            return fallback_result

    def _normalize_duration(self, duration_str: str) -> str:
        """ë³µìš© ê¸°ê°„ì„ ì •ê·œí™”ëœ í˜•íƒœë¡œ ë³€í™˜"""
        if not duration_str:
            return duration_str
        
        # ì •ê·œí™” ë§¤í•‘
        duration_mapping = {
            "ì¼ì£¼ì¼ì¹˜": "7ì¼ì¹˜",
            "ì¼ì£¼ì¼": "7ì¼ì¹˜", 
            "1ì£¼ì¼ì¹˜": "7ì¼ì¹˜",
            "1ì£¼ì¼": "7ì¼ì¹˜",
            "ì´ì£¼ì¼ì¹˜": "14ì¼ì¹˜",
            "2ì£¼ì¼ì¹˜": "14ì¼ì¹˜",
            "í•œë‹¬ì¹˜": "30ì¼ì¹˜",
            "1ê°œì›”ì¹˜": "30ì¼ì¹˜",
            "ë‘ë‹¬ì¹˜": "60ì¼ì¹˜",
            "2ê°œì›”ì¹˜": "60ì¼ì¹˜",
            "ì„¸ë‹¬ì¹˜": "90ì¼ì¹˜",
            "3ê°œì›”ì¹˜": "90ì¼ì¹˜",
            "ë°˜ë…„ì¹˜": "180ì¼ì¹˜",
            "6ê°œì›”ì¹˜": "180ì¼ì¹˜",
            "ì¼ë…„ì¹˜": "365ì¼ì¹˜",
            "1ë…„ì¹˜": "365ì¼ì¹˜"
        }
        
        # ì •í™•í•œ ë§¤ì¹­
        if duration_str in duration_mapping:
            return duration_mapping[duration_str]
        
        # íŒ¨í„´ ë§¤ì¹­ (ìˆ«ì + ë‹¨ìœ„)
        import re
        patterns = [
            (r"(\d+)ì£¼ì¼ì¹˜", r"\1ì£¼ì¼ì¹˜"),
            (r"(\d+)ì£¼ì¼", r"\1ì£¼ì¼ì¹˜"),
            (r"(\d+)ê°œì›”ì¹˜", r"\1ê°œì›”ì¹˜"),
            (r"(\d+)ë…„ì¹˜", r"\1ë…„ì¹˜"),
            (r"(\d+)ì¼ì¹˜", r"\1ì¼ì¹˜"),
            (r"(\d+)ì¼ë¶„", r"\1ì¼ì¹˜"),
            (r"(\d+)ì£¼ë¶„", r"\1ì£¼ì¼ì¹˜"),
            (r"(\d+)ê°œì›”ë¶„", r"\1ê°œì›”ì¹˜"),
            (r"(\d+)ë…„ë¶„", r"\1ë…„ì¹˜")
        ]
        
        for pattern, replacement in patterns:
            if re.match(pattern, duration_str):
                return re.sub(pattern, replacement, duration_str)
        
        # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        return duration_str

    def _extract_duration_from_dosage(self, dosage_list: List[dict]) -> Tuple[List[dict], str]:
        """ë³µìš© ë°°ì—´ì—ì„œ ê¸°ê°„ ì •ë³´ë¥¼ ë¶„ë¦¬í•˜ì—¬ ë³µìš© ê¸°ê°„ìœ¼ë¡œ ì¶”ì¶œ"""
        if not dosage_list:
            return dosage_list, None
        
        period_patterns = [
            r"(ì¼ì£¼ì¼ì¹˜|\d+ì¼ì¹˜|\d+ì£¼ì¼ì¹˜|\d+ê°œì›”ì¹˜|\d+ë…„ì¹˜)",
            r"(ì¼ì£¼ì¼|\d+ì¼\s*ì¹˜|\d+ì£¼\s*ì¼\s*ì¹˜|\d+ê°œ\s*ì›”\s*ì¹˜|\d+ë…„\s*ì¹˜)",
            r"(ì¼ì£¼ì¼ë¶„|\d+ì¼ë¶„|\d+ì£¼ë¶„|\d+ê°œì›”ë¶„|\d+ë…„ë¶„)",
            r"(ì¼ì£¼ì¼\s*ë¶„|\d+ì¼\s*ë¶„|\d+ì£¼\s*ë¶„|\d+ê°œ\s*ì›”\s*ë¶„|\d+ë…„\s*ë¶„)"
        ]
        
        filtered_dosage = []
        extracted_period = None
        
        for dosage in dosage_list:
            if isinstance(dosage, dict) and "ì›ë¬¸" in dosage:
                text = dosage["ì›ë¬¸"]
                is_period = False
                
                for pattern in period_patterns:
                    if re.search(pattern, text):
                        if not extracted_period:  # ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ ê¸°ê°„ë§Œ ì‚¬ìš©
                            extracted_period = self._normalize_duration(text)
                        is_period = True
                        break
                
                if not is_period:
                    filtered_dosage.append(dosage)
            else:
                filtered_dosage.append(dosage)
        
        return filtered_dosage, extracted_period

    def _is_valid_entity(self, entity_key: str, value: dict) -> bool:
        """ì—”í‹°í‹° ìœ íš¨ì„± ê²€ì‚¬ (ì˜ëª»ëœ ë°ì´í„° ì €ì¥ ë°©ì§€)"""
        if entity_key.endswith("ì‚¬ìš©ì") and "ì´ë¦„" in value:
            name = value["ì´ë¦„"]
            # ì´ë¦„ì´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬´íš¨
            if name in NAME_BLACKLIST or len(name) < 2:
                return False
            # í•œ ê¸€ì ì´ë¦„ë„ ë¬´íš¨ (ì˜ˆ: "í™”")
            if len(name) == 1:
                return False
        
        if entity_key.endswith("ë¬¼ê±´") and "ì´ë¦„" in value:
            item_name = value["ì´ë¦„"]
            # ë¬¼ê±´ ì´ë¦„ì´ ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ì§§ìœ¼ë©´ ë¬´íš¨
            if item_name in {"ë¬¼ê±´", "ê±°", "ê²ƒ", "ë­", "ë­”ê°€", "í™”", "ì•Œê³ ", "ë‹¤ì‹œ"} or len(item_name) < 1:
                return False
        
        if entity_key.endswith("ì‹ì‚¬") and "ë©”ë‰´" in value:
            menus = value["ë©”ë‰´"]
            if isinstance(menus, list):
                # ë©”ë‰´ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ë§Œ ìˆìœ¼ë©´ ë¬´íš¨ (ë°¥ì€ ìœ íš¨í•œ ë©”ë‰´)
                valid_menus = [m for m in menus if m and m not in STOPWORDS and (len(m) > 1 or m == "ë°¥")]
                if not valid_menus:
                    return False
        
        return True

    def maintenance_dedup_user(self, session_id: str):
        """ì˜ëª»ëœ ì‚¬ìš©ì ì—”í‹°í‹° ì •ë¦¬ (1íšŒì„± ë§ˆì´ê·¸ë ˆì´ì…˜)"""
        try:
            # í˜„ì¬ ì„¸ì…˜ì˜ ì‚¬ìš©ì ì—”í‹°í‹° ì¡°íšŒ (í•„í„° ì—†ì´)
            docs = self.vectorstore.similarity_search("ì‚¬ìš©ì ì´ë¦„", k=100)
            
            valid_docs = []
            invalid_ids = []
            
            for doc in docs:
                try:
                    data = json.loads(doc.page_content)
                    # ì„¸ì…˜ IDì™€ ì—”í‹°í‹° í‚¤ í™•ì¸
                    if (data.get("session_id") == session_id and 
                        data.get("entity_key") == "user.ì‚¬ìš©ì" and
                        self._is_valid_entity("user.ì‚¬ìš©ì", data)):
                        valid_docs.append(doc)
                    elif (data.get("session_id") == session_id and 
                          data.get("entity_key") == "user.ì‚¬ìš©ì"):
                        invalid_ids.append(doc.metadata.get("id"))
                except Exception:
                    invalid_ids.append(doc.metadata.get("id"))
            
            # ì˜ëª»ëœ ì—”í‹°í‹° ì‚­ì œ
            if invalid_ids:
                self.vectorstore.delete(ids=invalid_ids)
                print(f"[MAINT] ì˜ëª»ëœ ì‚¬ìš©ì ì—”í‹°í‹° {len(invalid_ids)}ê°œ ì‚­ì œ")
            
            print(f"[MAINT] ìœ íš¨í•œ ì‚¬ìš©ì ì—”í‹°í‹° {len(valid_docs)}ê°œ ìœ ì§€")
            
        except Exception as e:
            print(f"[WARN] ì‚¬ìš©ì ì—”í‹°í‹° ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _extract_time_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì¶”ì¶œ (_normalize_datetimeê³¼ í†µì¼)"""
        time_patterns = [
            r"(\d{1,2}ì‹œ\s*ë°˜)",
            r"(\d{1,2}ì‹œ\s*\d{1,2}ë¶„)",
            r"(\d{1,2}:\d{2})",  # 7:30 ê°™ì€ í˜•ì‹ ìš°ì„ 
            r"(\d{1,2}ì‹œ)",
            r"(ì˜¤ì „\s*\d{1,2}ì‹œ)",
            r"(ì˜¤í›„\s*\d{1,2}ì‹œ)",
            r"(ìƒˆë²½\s*\d{1,2}ì‹œ)",
            r"(ë°¤\s*\d{1,2}ì‹œ)"
        ]
        for pattern in time_patterns:
            time_match = re.search(pattern, text)
            if time_match:
                return time_match.group(1)
        return None

    def _extract_menu_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ë©”ë‰´ ì •ë³´ ì¶”ì¶œ (ë‹¨ìˆœí•œ ë©”ë‰´ëª…ë§Œ)"""
        # ë©”ë‰´ íŒ¨í„´ë“¤ (ìŒì‹ëª… ì¶”ì¶œ)
        menu_patterns = [
            r"([ê°€-í£]{2,10})",  # í•œê¸€ 2-10ê¸€ì (ìŒì‹ëª…)
        ]
        
        # ë¶ˆìš©ì–´ ì œì™¸
        stopwords = {
             "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì£„ì†¡", "ë¯¸ì•ˆ", "ì•Œê² ", "ë„¤", "ì•„ë‹ˆ", "ê·¸ë˜", "ë§ì•„",
            "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ì‹œê°„", "ëª‡ì‹œ", "ì–¸ì œ",
            "ë¨¹ì—ˆ", "ë¨¹ì–´", "ë“œì…¨", "ë“œì…”", "ì‹ì‚¬", "ë°¥", "ìŒì‹", "ë©”ë‰´"
        }
        
        for pattern in menu_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if match not in stopwords and len(match) >= 2:
                    return match.strip()

        return None


    def _extract_hour_from_time(self, time_str: str) -> Optional[int]:
        """ì‹œê°„ ë¬¸ìì—´ì—ì„œ ì‹œê°„(ì‹œ) ì¶”ì¶œ"""
        if not time_str:
            return None
        
        try:
            if ":" in time_str:
                hour = int(time_str.split(":")[0])
                return hour
            elif "ì‹œ" in time_str:
                hour = int(re.search(r"(\d{1,2})ì‹œ", time_str).group(1))
                return hour
            else:
                return int(time_str)
        except (ValueError, IndexError, AttributeError):
            return None

    def _normalize_time_format(self, time_str: str) -> str:
        """ì‹œê°„ í˜•ì‹ ì •ê·œí™” (7:30 â†’ 7ì‹œ 30ë¶„)"""
        if not time_str:
            return time_str
        
        # 7:30 â†’ 7ì‹œ 30ë¶„ ë³€í™˜
        if re.match(r"\d{1,2}:\d{2}", time_str):
            hour, minute = time_str.split(":")
            return f"{hour}ì‹œ {minute}ë¶„"
        
        return time_str

    def _normalize_time_field(self, time_value) -> List[str]:
        """ì‹œê°„ í•„ë“œ ì •ê·œí™” (í•­ìƒ listë¡œ ë³€í™˜)"""
        if not time_value:
            return []
        if isinstance(time_value, list):
            return [str(t) for t in time_value if t]
        return [str(time_value)]

    def _entity_identity(self, entity_key: str, v: dict) -> str:
        """ì—”í‹°í‹° identity ìƒì„±"""
        if entity_key.endswith("ì‚¬ìš©ì"): return "user_name"
        if entity_key.endswith("ì¼ì •"):  return f"{v.get('ì œëª©')}|{v.get('ë‚ ì§œ')}"
        if entity_key.endswith("ë¬¼ê±´"):  return v.get("ì´ë¦„")
        if entity_key.endswith("ì‹ì‚¬"):  return f"{v.get('ë‚ ì§œ')}|{v.get('ë¼ë‹ˆ')}"
        if entity_key.endswith("ì•½"):    return v.get("ì•½ëª…")
        if entity_key.endswith("ê°€ì¡±"):  return f"{v.get('ê´€ê³„')}|{v.get('ì´ë¦„')}"
        if entity_key.endswith("ê¸°ë…ì¼"):return f"{v.get('ê´€ê³„')}|{v.get('ì œëª©')}|{v.get('ë‚ ì§œ')}"
        if entity_key.endswith("ì·¨ë¯¸"):  return v.get("ì´ë¦„")
        if entity_key.endswith("ì·¨í–¥"):  return f"{v.get('ì¢…ë¥˜')}|{v.get('ê°’')}"
        if entity_key.endswith("ê±´ê°•ìƒíƒœ"):
            return f"{v.get('ì§ˆë³‘')}|{v.get('ì¦ìƒ')}|{v.get('ê¸°ê°„')}"
        return json.dumps(v, ensure_ascii=False)

    def _squash_entities(self, session_id: str, entities: Dict[str, List[Dict[str, Any]]], user_input: str = None) -> Dict[str, List[Dict[str, Any]]]:
        """ì—”í‹°í‹° ìŠ¤ì¿¼ì‹œ (ì¤‘ë³µ/ë¶ˆì™„ì „ ì—”í‹°í‹° ì •ë¦¬)"""
        out = {}
        for k, vals in entities.items():
            by_id: Dict[str, dict] = {}
            for v in vals:
                # N/A ê°’ í•„í„°ë§
                filtered_v = self._filter_meaningful_data(v, user_input)
                if not filtered_v:
                    continue
                    
                id_ = self._entity_identity(k, filtered_v)
                base = by_id.get(id_, {})
                # í•„ë“œ ì±„ìš°ê¸°(ìƒˆ ê°’ì´ ë” êµ¬ì²´ì ì´ë©´ êµì²´)
                for fk, fv in filtered_v.items():
                    if fv in (None, "", []): 
                        continue
                    if isinstance(fv, list) and isinstance(base.get(fk), list):
                        # ë”•ì…”ë„ˆë¦¬ê°€ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸ëŠ” ì¤‘ë³µ ì œê±° í›„ í•©ì¹˜ê¸°
                        combined = base[fk] + fv
                        base[fk] = self._dedup_entities(combined) if all(isinstance(item, dict) for item in combined) else list({*base[fk], *fv})
                    else:
                        # ê¸¸ì´ê°€ ë” ê¸´ ë¬¸ìì—´/ë” ë§ì€ ì •ë³´ ìš°ì„ 
                        if not base.get(fk) or (isinstance(fv, str) and len(str(fv)) > len(str(base.get(fk)))):
                            base[fk] = fv
                by_id[id_] = base
            
            # ì‹ì‚¬ëŠ” ë¶ˆì™„ì „í•´ë„ ì„ì‹œ ì €ì¥ (ì ì§„ì  merge ì§€ì›)
            if k.endswith("ì‹ì‚¬"):
                # ì‹ì‚¬ ì—”í‹°í‹° ì¤‘ë³µ ì œê±° - ê°™ì€ ë¼ë‹ˆì™€ ë‚ ì§œê°€ ìˆìœ¼ë©´ í•˜ë‚˜ë§Œ ìœ ì§€
                unique_meals = []
                seen_combinations = set()
                for v in by_id.values():
                    meal_key = f"{v.get('ë¼ë‹ˆ', '')}_{v.get('ë‚ ì§œ', '')}_{v.get('ì‹œê°„', '')}"
                    if meal_key not in seen_combinations or not meal_key.strip('_'):
                        unique_meals.append(v)
                        seen_combinations.add(meal_key)
                out[k] = unique_meals
            else:
                # ì™„ì„±ëœ ê²ƒë§Œ ë‚¨ê¹€(í•„ìˆ˜í•„ë“œ ì±„ì›Œì§„ ê²ƒ ìœ„ì£¼)
                filtered = []
                for v in by_id.values():
                    missing = self._check_missing_fields(k, v)
                    if not missing:
                        filtered.append(v)
                    else:
                        # ì „ë¶€ ë¹ ì§€ë©´ ì§ˆë¬¸ ìœ ë„ìš©ìœ¼ë¡œ í•˜ë‚˜ëŠ” ë‚¨ê¸¸ ìˆ˜ë„ ìˆì§€ë§Œ,
                        # ì´ë²ˆ ì´ìŠˆ(ë¶ˆí•„ìš” ì¬ì§ˆë¬¸) ë°©ì§€ë¥¼ ìœ„í•´ ì™„ì„±ëœ ê²ƒë§Œ ìš°ì„  ì €ì¥
                        pass
                out[k] = filtered if filtered else list(by_id.values())
        
        # ì•½ ì—”í‹°í‹°ì— íŠ¹ë³„íˆ ì¤‘ë³µ ì œê±° ì ìš©
        if "user.ì•½" in out:
            out["user.ì•½"] = self._dedup_drug_entities(out["user.ì•½"])
        
        return out


    def _enrich_dose_dict(self, d: dict) -> dict:
        """ì•½ ë³µìš© ì •ë³´ íŒŒì„œ ê°•í™”"""
        txt = d.get("ì›ë¬¸","") or ""
        # íšŸìˆ˜: ìˆ«ì/í•œê¸€ ìˆ˜ì‚¬
        m = re.search(r"í•˜ë£¨\s*(\d+)\s*ë²ˆ", txt)
        if m: d["íšŸìˆ˜"] = int(m.group(1))
        kor = {"í•œ":1,"ë‘":2,"ì„¸":3,"ë„¤":4,"ë‹¤ì„¯":5}
        m = re.search(r"í•˜ë£¨\s*([í•œë‘ì„¸ë„¤ë‹¤ì„¯])\s*ë²ˆ", txt)
        if m: d["íšŸìˆ˜"] = kor[m.group(1)]
        # ì‹ì „/ì‹í›„
        if "ì‹í›„" in txt: d["ì‹ì „í›„"] = "ì‹í›„"
        elif "ì‹ì „" in txt: d["ì‹ì „í›„"] = "ì‹ì „"
        # ì‹œê°„ëŒ€ íŒíŠ¸(ì•„ì¹¨/ì ì‹¬/ì €ë…)
        if any(k in txt for k in ["ì•„ì¹¨","ì ì‹¬","ì €ë…"]):
            d.setdefault("ì‹œê°„ëŒ€", [])  # ììœ  í•„ë“œ
            for k in ["ì•„ì¹¨","ì ì‹¬","ì €ë…"]:
                if k in txt and k not in d["ì‹œê°„ëŒ€"]:
                    d["ì‹œê°„ëŒ€"].append(k)
        return d

    # VectorStore ì €ì¥ (merge í¬í•¨)
    def _filter_meaningful_data(self, value: dict, user_input: str = None) -> dict:
        """N/A ê°’ì´ë‚˜ ì˜ë¯¸ì—†ëŠ” ë°ì´í„°ë¥¼ í•„í„°ë§"""
        if not value:
            return {}
        
        # íƒ€ì… ì•ˆì „ì„± ì²´í¬
        if not isinstance(value, dict):
            print(f"[ERROR] _filter_meaningful_data: ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì… {type(value)}: {value}")
            return {}
        
        print(f"[DEBUG] _filter_meaningful_data í˜¸ì¶œ: {value}")
        
        filtered = {}
        for key, val in value.items():
            if val is None or val == "" or val == "N/A" or val == "null":
                continue
            if isinstance(val, str) and val.strip() in ["", "N/A", "null", "ì—†ìŒ", "ëª¨ë¦„", "ëª¨ë¥´ê² ì–´", "N/A", "null"]:
                continue
            if isinstance(val, list) and not val:
                continue
            if isinstance(val, list) and all(item in ["", "N/A", "null", "ì—†ìŒ", "ëª¨ë¦„"] for item in val):
                continue
            filtered[key] = val
        
        # ì•½ ì—”í‹°í‹°ì˜ ê²½ìš° ë³µìš© ì •ë³´ê°€ ìˆìœ¼ë©´ ìœ íš¨í•œ ì—”í‹°í‹°ë¡œ ì¸ì •
        if "ì•½ëª…" in filtered and ("ë³µìš©" in filtered or "ì‹ì‚¬ì™€ì˜ ê´€ê³„" in filtered):
            return filtered
        
        # ì•½ ë³µìš© ì—”í‹°í‹°ì˜ ê²½ìš° ì‹œê°„ëŒ€, ë³µìš©, ë‚ ì§œ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìœ íš¨í•œ ì—”í‹°í‹°ë¡œ ì¸ì •
        if any(key in filtered for key in ["ì‹œê°„ëŒ€", "ë³µìš©", "ë‚ ì§œ"]) and any(key in filtered for key in ["ì‹œê°„ëŒ€", "ë³µìš©", "ë‚ ì§œ"]):
            return filtered
        
        # ëª¨ë“  í•„ë“œê°€ í•„í„°ë§ë˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        if not filtered:
            return {}
        
        return filtered

    def _merge_meal_entity(self, existing: dict, new: dict) -> dict:
        """ì‹ì‚¬ ì—”í‹°í‹° ë³‘í•© - ê°™ì€ ë‚ ì§œ/ë¼ë‹ˆ/ì‹œê°„ì´ë©´ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ë§Œ ê°±ì‹ """
        # âœ… merge ë³´í˜¸ ë¡œì§: existingì´ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹ˆë©´ ìƒˆ ê°’ ë°˜í™˜
        if existing is None or not isinstance(existing, dict):
            return new
        merged = existing.copy()
        
        # ë©”ë‰´ ë³‘í•©
        if "ë©”ë‰´" in new and new["ë©”ë‰´"]:
            existing_menus = existing.get("ë©”ë‰´", [])
            new_menus = new["ë©”ë‰´"] if isinstance(new["ë©”ë‰´"], list) else [new["ë©”ë‰´"]]
            
            # ê¸°ì¡´ ë©”ë‰´ì™€ ìƒˆ ë©”ë‰´ í•©ì¹˜ê¸° (ì¤‘ë³µ ì œê±°)
            all_menus = list(set(existing_menus + new_menus))
            merged["ë©”ë‰´"] = all_menus
        
        # ë‹¤ë¥¸ í•„ë“œë“¤ë„ ì—…ë°ì´íŠ¸ (ìƒˆ ê°’ì´ ìˆìœ¼ë©´)
        for key, val in new.items():
            if key != "ë©”ë‰´" and val and val not in ["", "N/A", "null"]:
                merged[key] = val
        
        return merged

    def _add_to_vstore(self, entity_key: str, value: dict, metadata: dict, strategy: str = "merge", identity: Optional[str] = None, user_input: str = None, session_id: Optional[str] = None) -> dict:
        try:
            # N/A ê°’ í•„í„°ë§ - ì˜ë¯¸ìˆëŠ” ë°ì´í„°ë§Œ ì €ì¥
            filtered_value = self._filter_meaningful_data(value, user_input)
            if not filtered_value:
                logger.debug(f"ì˜ë¯¸ì—†ëŠ” ë°ì´í„° í•„í„°ë§: {entity_key} - {value}")
                return value
        except Exception as e:
            if str(e).startswith("QUESTION:"):
                question = str(e)[9:]  # "QUESTION:" ì œê±°
                print(f"[DEBUG] _add_to_vstoreì—ì„œ ì¬ì§ˆë¬¸ ì˜ˆì™¸ ì²˜ë¦¬: {question}")
                return {"ì§ˆë¬¸": question}
            raise e
        
        # ì¬ì§ˆë¬¸ì´ ë°˜í™˜ëœ ê²½ìš°
        if isinstance(filtered_value, dict) and "ì§ˆë¬¸" in filtered_value:
            print(f"[DEBUG] _add_to_vstoreì—ì„œ ì¬ì§ˆë¬¸ ë°˜í™˜: {filtered_value['ì§ˆë¬¸']}")
            # ì¬ì§ˆë¬¸ì„ ì „ì—­ ìƒíƒœì— ì €ì¥í•˜ê³  ì¦‰ì‹œ ë°˜í™˜
            if session_id:
                self.current_question[session_id] = filtered_value["ì§ˆë¬¸"]
            return filtered_value
        
        # ì™„ì „ì„± ê²€ì‚¬ - í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ì €ì¥í•˜ì§€ ì•ŠìŒ (ì‹ì‚¬ ì œì™¸)
        if not entity_key.endswith("ì‹ì‚¬") and not self._is_complete_entity(entity_key, filtered_value):
            logger.debug(f"ë¶ˆì™„ì „í•œ ì—”í‹°í‹° ì €ì¥ ê±°ë¶€: {entity_key} - {filtered_value}")
            return filtered_value
        
        base_key = f"{metadata.get('session_id', '')}_{entity_key}"
        if identity is None:
            # 1ì°¨ ëª©í‘œ: Identity ì •ì±… ë‹¨ìˆœí™”
            if entity_key.endswith("ì‚¬ìš©ì"):
                identity = "user_name"  # ì‚¬ìš©ìëŠ” ê³ ì •
            elif entity_key.endswith("ì¼ì •"):
                identity = f"{filtered_value.get('ì œëª©')}|{filtered_value.get('ë‚ ì§œ')}"  # ì œëª©+ë‚ ì§œë§Œ
            elif entity_key.endswith("ë¬¼ê±´"):
                identity = filtered_value.get("ì´ë¦„")  # ì´ë¦„ë§Œ
            elif entity_key.endswith("ì‹ì‚¬"):
                identity = f"{filtered_value.get('ë‚ ì§œ')}|{filtered_value.get('ë¼ë‹ˆ')}"
            elif entity_key.endswith("ì•½"):
                identity = filtered_value.get("ì•½ëª…")
            elif entity_key.endswith("ê°€ì¡±"):
                identity = f"{filtered_value.get('ê´€ê³„')}|{filtered_value.get('ì´ë¦„')}"
            elif entity_key.endswith("ê¸°ë…ì¼"):
                identity = f"{filtered_value.get('ê´€ê³„')}|{filtered_value.get('ì œëª©')}|{filtered_value.get('ë‚ ì§œ')}"
            elif entity_key.endswith("ì·¨ë¯¸"):
                identity = filtered_value.get("ì´ë¦„")
            elif entity_key.endswith("ì·¨í–¥"):
                identity = f"{filtered_value.get('ì¢…ë¥˜')}|{filtered_value.get('ê°’')}"
            elif entity_key.endswith("ê±´ê°•ìƒíƒœ"):
                parts = [filtered_value.get("ì§ˆë³‘"), filtered_value.get("ì¦ìƒ"), filtered_value.get("ê¸°ê°„")]
                identity = "|".join([p for p in parts if p]) or hashlib.md5(json.dumps(filtered_value, ensure_ascii=False).encode()).hexdigest()

        unique_key = f"{base_key}_{hashlib.md5(str(identity).encode()).hexdigest()}"

        # ë‚ ì§œ ì •ê·œí™” ê°•ì œ ì ìš© (ëª¨ë“  ì—”í‹°í‹°)
        session_id = metadata.get('session_id', 'default')
        if "ë‚ ì§œ" in filtered_value and filtered_value["ë‚ ì§œ"]:
            filtered_value["ë‚ ì§œ"] = self._normalize_date(filtered_value["ë‚ ì§œ"], session_id)
        elif entity_key.endswith(("ì¼ì •", "ì‹ì‚¬", "ê¸°ë…ì¼", "ì•½", "ê±´ê°•ìƒíƒœ", "ì·¨ë¯¸", "ì·¨í–¥")):
            # ë‚ ì§œ í•„ë“œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ë¡œ ìë™ ì‚½ì…
            filtered_value["ë‚ ì§œ"] = self._normalize_date("ì˜¤ëŠ˜", session_id)
        
        # ë¬¼ê±´ ìœ„ì¹˜ ì •ê·œí™” ì ìš© (ì €ì¥ ì‹œì ì—ì„œ ê°•ì œ ì •ê·œí™”)
        if entity_key.endswith("ë¬¼ê±´") and "ìœ„ì¹˜" in filtered_value:
            filtered_value["ìœ„ì¹˜"] = self._normalize_location(filtered_value["ìœ„ì¹˜"])

        try:
            # ì‚¬ìš©ì ì •ë³´ ì¤‘ë³µ ë°©ì§€ - ê°™ì€ ì„¸ì…˜ ë‚´ì—ì„œë§Œ ì¤‘ë³µ ì²´í¬
            if entity_key.endswith("ì‚¬ìš©ì") and "ì´ë¦„" in filtered_value:
                filtered_value["ì´ë¦„"] = self._normalize_name(filtered_value["ì´ë¦„"])
                
                # ì—‘ì…€ ìºì‹œì—ì„œ ì¤‘ë³µ ì²´í¬ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
                if hasattr(self, 'excel_cache') and session_id in self.excel_cache:
                    cache_entities = self.excel_cache[session_id].get("ì‚¬ìš©ì", [])
                    for cached_entity in cache_entities:
                        if isinstance(cached_entity, dict) and cached_entity.get("ì´ë¦„") == filtered_value.get("ì´ë¦„"):
                            logger.debug(f"ì‚¬ìš©ì ì •ë³´ ì¤‘ë³µ ë°©ì§€: '{filtered_value.get('ì´ë¦„')}' ì´ë¯¸ ì¡´ì¬ (ì„¸ì…˜: {session_id})")
                            return self._merge_entity_values(cached_entity, filtered_value, "user.ì‚¬ìš©ì")
                
                # VectorStore ë¹„í™œì„±í™” - ì—‘ì…€ ìºì‹œ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ë¡œ ëŒ€ì²´ë¨ (ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬)
            
            # ê°€ì¡± ì •ë³´ ì¤‘ë³µ ë°©ì§€ - ê°™ì€ ì„¸ì…˜ ë‚´ì—ì„œë§Œ ì¤‘ë³µ ì²´í¬
            if entity_key.endswith("ê°€ì¡±") and "ì´ë¦„" in filtered_value and "ê´€ê³„" in filtered_value:
                filtered_value["ì´ë¦„"] = self._normalize_name(filtered_value["ì´ë¦„"])
                
                # ì—‘ì…€ ìºì‹œì—ì„œ ì¤‘ë³µ ì²´í¬ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
                if hasattr(self, 'excel_cache') and session_id in self.excel_cache:
                    cache_entities = self.excel_cache[session_id].get("ê°€ì¡±", [])
                    for cached_entity in cache_entities:
                        if (isinstance(cached_entity, dict) and 
                            cached_entity.get("ì´ë¦„") == filtered_value.get("ì´ë¦„") and
                            cached_entity.get("ê´€ê³„") == filtered_value.get("ê´€ê³„")):
                            logger.debug(f"ê°€ì¡± ì •ë³´ ì¤‘ë³µ ë°©ì§€: '{filtered_value.get('ê´€ê³„')} {filtered_value.get('ì´ë¦„')}' ì´ë¯¸ ì¡´ì¬ (ì„¸ì…˜: {session_id})")
                            return self._merge_entity_values(cached_entity, filtered_value, "user.ê°€ì¡±")
                
                # VectorStore ë¹„í™œì„±í™” - ì—‘ì…€ ìºì‹œ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ë¡œ ëŒ€ì²´ë¨
            
            # ë™ì  ì¤‘ë³µ ê²€ì‚¬ - ë¬¼ê±´ì€ ì „ì—­, ë‚˜ë¨¸ì§€ëŠ” ì„¸ì…˜ë³„
            if "ì´ë¦„" in filtered_value and filtered_value.get("ì´ë¦„"):
                print(f"[DEBUG] ë™ì  ì¤‘ë³µ ê²€ì‚¬ ì‹œì‘: entity_key={entity_key}, session_id={session_id}, ì´ë¦„={filtered_value.get('ì´ë¦„')}")
                
                entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
                existing_entities = []
                
                # ì—‘ì…€ ìºì‹œì—ì„œ ì¤‘ë³µ ì²´í¬ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
                if hasattr(self, 'excel_cache'):
                    # ë¬¼ê±´ì€ ì „ì—­ ì²´í¬ (ëª¨ë“  ì„¸ì…˜), ë‚˜ë¨¸ì§€ëŠ” ì„¸ì…˜ë³„ ì²´í¬
                    if entity_key.endswith("ë¬¼ê±´"):
                        # ëª¨ë“  ì„¸ì…˜ì˜ ìºì‹œ í™•ì¸
                        for sess_id, cache_data in self.excel_cache.items():
                            cache_entities = cache_data.get(entity_type, [])
                            for cached_entity in cache_entities:
                                if isinstance(cached_entity, dict) and cached_entity.get("ì´ë¦„") == filtered_value.get("ì´ë¦„"):
                                    existing_entities.append(cached_entity)
                                    print(f"[DEBUG] ê¸°ì¡´ ì—”í‹°í‹° ë°œê²¬: {cached_entity}")
                    else:
                        # ì„¸ì…˜ë³„ ì²´í¬
                        if session_id in self.excel_cache:
                            cache_entities = self.excel_cache[session_id].get(entity_type, [])
                            for cached_entity in cache_entities:
                                if isinstance(cached_entity, dict):
                                    existing_entities.append(cached_entity)
                                    print(f"[DEBUG] ê¸°ì¡´ ì—”í‹°í‹° ë°œê²¬: {cached_entity}")
                
                # ë™ì¼í•œ ì—”í‹°í‹° íƒ€ì…ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ìµœì‹  ì •ë³´ë¡œ ìë™ ì—…ë°ì´íŠ¸ (ì¬ì§ˆë¬¸ ì œê±°)
                if existing_entities:
                    existing_name = existing_entities[0].get("ì´ë¦„", "")
                    new_name = filtered_value.get("ì´ë¦„", "")
                    entity_type = entity_key.replace("user.", "")
                    
                    print(f"[DEBUG] ì¤‘ë³µ ì—”í‹°í‹° ë°œê²¬: ê¸°ì¡´='{existing_name}', ìƒˆ='{new_name}' - ìµœì‹  ì •ë³´ë¡œ ìë™ ì—…ë°ì´íŠ¸")
                    
                    # ê°™ì€ ì´ë¦„ì´ë©´ ìµœì‹  ì •ë³´ë¡œ ìë™ ë³‘í•© (ì¬ì§ˆë¬¸ ì—†ì´)
                    if existing_name == new_name:
                        # ê¸°ì¡´ ì—”í‹°í‹°ì™€ ìƒˆ ì—”í‹°í‹° ë³‘í•©í•˜ì—¬ ìµœì‹  ì •ë³´ ë°˜ì˜
                        merged = self._merge_entity_values(existing_entities[0], filtered_value, entity_key)
                        print(f"[DEBUG] ì¤‘ë³µ ì—”í‹°í‹° ìë™ ë³‘í•© ì™„ë£Œ: {merged}")
                        # ë³‘í•©ëœ ì—”í‹°í‹°ë¡œ filtered_value ì—…ë°ì´íŠ¸ (ì•„ë˜ ì—‘ì…€ ì €ì¥ ë¡œì§ ì‹¤í–‰ë˜ë„ë¡)
                        filtered_value = merged
                        # ë³‘í•©ëœ ì—”í‹°í‹°ë¥¼ ìºì‹œì—ì„œ ì—…ë°ì´íŠ¸
                        if session_id in self.excel_cache:
                            cache_entities = self.excel_cache[session_id].get(entity_type, [])
                            for i, cached_entity in enumerate(cache_entities):
                                if isinstance(cached_entity, dict) and cached_entity.get("ì´ë¦„") == existing_name:
                                    cache_entities[i] = merged
                                    break
                        # return í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰í•˜ì—¬ ì—‘ì…€ì—ë„ ì €ì¥ë˜ë„ë¡ í•¨
                    else:
                        # ë‹¤ë¥¸ ì´ë¦„ì´ë©´ ìƒˆ ì—”í‹°í‹°ë¡œ ì €ì¥ (ê¸°ì¡´ ì—”í‹°í‹°ëŠ” ìœ ì§€)
                        print(f"[DEBUG] ë‹¤ë¥¸ ì´ë¦„ì˜ ì—”í‹°í‹° - ìƒˆ ì—”í‹°í‹°ë¡œ ì €ì¥: {new_name}")
                        # ê³„ì† ì§„í–‰í•˜ì—¬ ìƒˆ ì—”í‹°í‹° ì €ì¥
            
             # ì•½ ì •ë³´ ì¤‘ë³µ ë°©ì§€ - ìµœì‹  ì •ë³´ë¡œ ìë™ ì—…ë°ì´íŠ¸ (ì¬ì§ˆë¬¸ ì œê±°)
            if entity_key.endswith("ì•½") and "ì•½ëª…" in filtered_value:
                # ì—‘ì…€ ìºì‹œì—ì„œ ë™ì¼í•œ ì•½ ì •ë³´ í™•ì¸ (ì•½ëª… ê¸°ì¤€)
                if hasattr(self, 'excel_cache') and session_id in self.excel_cache:
                    cache_entities = self.excel_cache[session_id].get("ì•½", [])
                    for cached_entity in cache_entities:
                        if isinstance(cached_entity, dict) and cached_entity.get("ì•½ëª…") == filtered_value.get("ì•½ëª…"):
                            logger.debug(f"ì•½ ì •ë³´ ì¤‘ë³µ ë°œê²¬: '{filtered_value.get('ì•½ëª…')}' ì´ë¯¸ ì¡´ì¬ - ìµœì‹  ì •ë³´ë¡œ ìë™ ë³‘í•© (ì„¸ì…˜: {session_id})")
                            # ìµœì‹  ì •ë³´ë¡œ ìë™ ë³‘í•©
                            merged = self._merge_entity_values(cached_entity, filtered_value, "user.ì•½")
                            # ë³‘í•©ëœ ì—”í‹°í‹°ë¡œ filtered_value ì—…ë°ì´íŠ¸ (ì•„ë˜ ì—‘ì…€ ì €ì¥ ë¡œì§ ì‹¤í–‰ë˜ë„ë¡)
                            filtered_value = merged
                            # ë³‘í•©ëœ ì—”í‹°í‹°ë¥¼ ìºì‹œì—ì„œ ì—…ë°ì´íŠ¸
                            for i, entity in enumerate(cache_entities):
                                if isinstance(entity, dict) and entity.get("ì•½ëª…") == filtered_value.get("ì•½ëª…"):
                                    cache_entities[i] = merged
                                    break
                            # return í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰í•˜ì—¬ ì—‘ì…€ì—ë„ ì €ì¥ë˜ë„ë¡ í•¨
                            break
            
            # ì‹ì‚¬ ì •ë³´ ì¤‘ë³µ ë°©ì§€ - ì—‘ì…€ ìºì‹œ ê¸°ë°˜ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
            if entity_key.endswith("ì‹ì‚¬"):
                # ì—‘ì…€ ìºì‹œì—ì„œ ë™ì¼í•œ ì‹ì‚¬ ì •ë³´ í™•ì¸
                if hasattr(self, 'excel_cache') and session_id in self.excel_cache:
                    cache_entities = self.excel_cache[session_id].get("ì‹ì‚¬", [])
                    for cached_entity in cache_entities:
                        if not isinstance(cached_entity, dict):
                            continue
                        
                        # ì¤‘ë³µ ê²€ì‚¬ ê¸°ì¤€: ë‚ ì§œ+ë¼ë‹ˆê°€ ëª¨ë‘ ìˆìœ¼ë©´ ê·¸ê²ƒìœ¼ë¡œ, ì—†ìœ¼ë©´ ë©”ë‰´ë¡œ
                        # ë‚ ì§œ+ë¼ë‹ˆê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°
                        if (filtered_value.get("ë‚ ì§œ") and filtered_value.get("ë¼ë‹ˆ") and 
                            cached_entity.get("ë‚ ì§œ") == filtered_value.get("ë‚ ì§œ") and
                            cached_entity.get("ë¼ë‹ˆ") == filtered_value.get("ë¼ë‹ˆ")):
                            logger.debug(f"ì‹ì‚¬ ì •ë³´ ì¤‘ë³µ ë°©ì§€: '{filtered_value.get('ë‚ ì§œ')} {filtered_value.get('ë¼ë‹ˆ')}' ì´ë¯¸ ì¡´ì¬ (ì„¸ì…˜: {session_id})")
                            merged_meal = self._merge_meal_entity(cached_entity, filtered_value)
                            # ìºì‹œ ì—…ë°ì´íŠ¸
                            cache_entities.remove(cached_entity)
                            cache_entities.append(merged_meal)
                            return merged_meal
                        
                        # ë©”ë‰´ë§Œ ìˆëŠ” ê²½ìš° (ë¼ë‹ˆ/ë‚ ì§œê°€ ì—†ëŠ” ê²½ìš°)
                        elif (filtered_value.get("ë©”ë‰´") and cached_entity.get("ë©”ë‰´") and
                              not filtered_value.get("ë¼ë‹ˆ") and not cached_entity.get("ë¼ë‹ˆ") and
                              filtered_value.get("ë©”ë‰´") == cached_entity.get("ë©”ë‰´")):
                            logger.debug(f"ì‹ì‚¬ ì •ë³´ ì¤‘ë³µ ë°©ì§€: ë©”ë‰´ '{filtered_value.get('ë©”ë‰´')}' ì´ë¯¸ ì¡´ì¬ (ì„¸ì…˜: {session_id})")
                            merged_meal = self._merge_meal_entity(cached_entity, filtered_value)
                            # ìºì‹œ ì—…ë°ì´íŠ¸
                            cache_entities.remove(cached_entity)
                            cache_entities.append(merged_meal)
                            return merged_meal
                        
                        # ì‹œê°„ë§Œ ìˆëŠ” ê²½ìš° - ê¸°ì¡´ ì‹ì‚¬ì— ì‹œê°„ ì¶”ê°€
                        elif (filtered_value.get("ì‹œê°„") and not filtered_value.get("ë©”ë‰´") and 
                              not filtered_value.get("ë¼ë‹ˆ") and cached_entity.get("ë¼ë‹ˆ")):
                            logger.debug(f"ì‹ì‚¬ ì‹œê°„ ì—…ë°ì´íŠ¸: ê¸°ì¡´ ì‹ì‚¬ì— ì‹œê°„ '{filtered_value.get('ì‹œê°„')}' ì¶”ê°€ (ì„¸ì…˜: {session_id})")
                            merged_meal = self._merge_meal_entity(cached_entity, filtered_value)
                            # ìºì‹œ ì—…ë°ì´íŠ¸
                            cache_entities.remove(cached_entity)
                            cache_entities.append(merged_meal)
                            return merged_meal
            
            # strategy == "merge" - ì—‘ì…€ ìºì‹œ ê¸°ë°˜ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
            if strategy == "merge":
                # ì—‘ì…€ ìºì‹œì—ì„œ ê¸°ì¡´ ì—”í‹°í‹° í™•ì¸
                entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
                old_val = None
                
                if hasattr(self, 'excel_cache') and session_id in self.excel_cache:
                    cache_entities = self.excel_cache[session_id].get(entity_type, [])
                    # identity ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¡´ ì—”í‹°í‹° ì°¾ê¸°
                    if identity and cache_entities:
                        for cached_entity in cache_entities:
                            if isinstance(cached_entity, dict) and str(identity) in str(cached_entity):
                                old_val = cached_entity
                                break
                    
                    if old_val:
                        # ì‚¬ìš©ì ì •ë³´ ì¤‘ë³µ ë°©ì§€ ê°•í™”
                        if entity_key.endswith("ì‚¬ìš©ì"):
                            # ë™ì¼í•œ ì´ë¦„ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            if old_val.get("ì´ë¦„") and old_val.get("ì´ë¦„") == value.get("ì´ë¦„"):
                                # ë™ì¼í•œ ì´ë¦„ì´ë©´ ê¸°ì¡´ ì •ë³´ ì—…ë°ì´íŠ¸ë§Œ í•˜ê³  ìƒˆë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ
                                logger.debug(f"ì‚¬ìš©ì ì •ë³´ ì¤‘ë³µ ë°©ì§€: '{value.get('ì´ë¦„')}' ì´ë¯¸ ì¡´ì¬")
                                return self._merge_entity_values(old_val, value, "user.ì‚¬ìš©ì")
                            
                            if old_val.get("ì´ë¦„") and old_val.get("ì´ë¦„") != value.get("ì´ë¦„"):
                                # ì‚¬ìš©ì ì´ë¦„ ì¶©ëŒ - ì¬ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
                                print(f"[WARN] ì‚¬ìš©ì ì´ë¦„ ì¶©ëŒ: ê¸°ì¡´ '{old_val.get('ì´ë¦„')}' vs ìƒˆ '{filtered_value.get('ì´ë¦„')}' - ì¬ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬")
                                return old_val
                            # ê¸°ì¡´ ì´ë¦„ì´ ì—†ê±°ë‚˜ ê°™ìœ¼ë©´ ìƒˆ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸
                            filtered_value = self._merge_entity_values(old_val, filtered_value, entity_key)
                        
                        # ì•½ - ë³µìš© ì •ë³´ ëˆ„ì , ê¸°ê°„ì€ ìƒˆë¡œìš´ ê°’ ìš°ì„ 
                        elif entity_key.endswith("ì•½"):
                            # ë³µìš© ì •ë³´ ë³‘í•©
                            combined_dosage = (old_val.get("ë³µìš©") or []) + (filtered_value.get("ë³µìš©") or [])
                        # ë³µìš© ì •ë³´ì—ì„œ ê¸°ê°„ ì •ë³´ ë¶„ë¦¬
                        filtered_dosage, extracted_period = self._extract_duration_from_dosage(combined_dosage)
                        filtered_value["ë³µìš©"] = filtered_dosage
                        
                        # ë³µìš© ê¸°ê°„ ìš°ì„ ìˆœìœ„: ì¶”ì¶œëœ ê¸°ê°„ > ìƒˆë¡œìš´ ê°’ > ê¸°ì¡´ ê°’ (ì •ê·œí™” ì ìš©)
                        if extracted_period:
                            filtered_value["ë³µìš© ê¸°ê°„"] = extracted_period
                        elif filtered_value.get("ë³µìš© ê¸°ê°„"):
                            filtered_value["ë³µìš© ê¸°ê°„"] = self._normalize_duration(filtered_value["ë³µìš© ê¸°ê°„"])
                        elif old_val.get("ë³µìš© ê¸°ê°„"):
                            filtered_value["ë³µìš© ê¸°ê°„"] = self._normalize_duration(old_val["ë³µìš© ê¸°ê°„"])
                        
                        # ìƒˆë¡œìš´ ë¨¸ì§€ ë¡œì§ ì ìš©
                        filtered_value = self._merge_entity_values(old_val, filtered_value, entity_key)
                    
                    # ì¼ì • - ì œëª©+ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ merge, ì‹œê°„ í•„ë“œ ì •ê·œí™”
                    elif entity_key.endswith("ì¼ì •"):
                        if old_val.get("ì œëª©") == filtered_value.get("ì œëª©") and old_val.get("ë‚ ì§œ") == filtered_value.get("ë‚ ì§œ"):
                            # ìƒˆë¡œìš´ ë¨¸ì§€ ë¡œì§ ì ìš©
                            filtered_value = self._merge_entity_values(old_val, filtered_value, entity_key)
                    
                    # ê¸°ë…ì¼ - ê´€ê³„+ì œëª©+ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ merge
                    elif entity_key.endswith("ê¸°ë…ì¼"):
                        if (old_val.get("ê´€ê³„") == filtered_value.get("ê´€ê³„") and 
                            old_val.get("ì œëª©") == filtered_value.get("ì œëª©") and 
                            old_val.get("ë‚ ì§œ") == filtered_value.get("ë‚ ì§œ")):
                            filtered_value = {**old_val, **filtered_value}
                    
                    # ì‹ì‚¬ - ë‚ ì§œ+ë¼ë‹ˆ ê¸°ì¤€ìœ¼ë¡œ merge, ë©”ë‰´ëŠ” ëˆ„ì , ì‹œê°„ í•„ë“œ ì •ê·œí™”
                    elif entity_key.endswith("ì‹ì‚¬"):
                        if (old_val.get("ë‚ ì§œ") == filtered_value.get("ë‚ ì§œ") and 
                            old_val.get("ë¼ë‹ˆ") == filtered_value.get("ë¼ë‹ˆ")):
                            # ë©”ë‰´ ëˆ„ì  (ì¤‘ë³µ ì œê±°)
                            old_menus = old_val.get("ë©”ë‰´", [])
                            new_menus = filtered_value.get("ë©”ë‰´", [])
                            filtered_value["ë©”ë‰´"] = list(set(old_menus + new_menus))
                            
                            # ì‹œê°„ í•„ë“œ ì •ê·œí™” ë° ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ ì‹œê°„ì´ ìˆìœ¼ë©´ ìš°ì„ )
                            if filtered_value.get("ì‹œê°„"):
                                # ìƒˆë¡œìš´ ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
                                filtered_value["ì‹œê°„"] = self._normalize_time_field(filtered_value.get("ì‹œê°„"))
                            elif old_val.get("ì‹œê°„"):
                                # ê¸°ì¡´ ì‹œê°„ ì •ë³´ ìœ ì§€
                                filtered_value["ì‹œê°„"] = self._normalize_time_field(old_val.get("ì‹œê°„"))
                            
                            filtered_value = {**old_val, **filtered_value}
                    
                    # ë¬¼ê±´ - ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ merge, ìœ„ì¹˜ëŠ” ìµœì‹ /ë” êµ¬ì²´ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    elif entity_key.endswith("ë¬¼ê±´"):
                        if old_val.get("ì´ë¦„") == filtered_value.get("ì´ë¦„"):
                            # ìœ„ì¹˜ê°€ ë” êµ¬ì²´ì ì´ë©´ ì—…ë°ì´íŠ¸
                            if filtered_value.get("ìœ„ì¹˜") and (
                                not old_val.get("ìœ„ì¹˜") or 
                                len(str(filtered_value.get("ìœ„ì¹˜"))) > len(str(old_val.get("ìœ„ì¹˜")))
                            ):
                                old_val["ìœ„ì¹˜"] = filtered_value.get("ìœ„ì¹˜")
                            filtered_value = {**old_val, **filtered_value}
                    
                    # ê±´ê°•ìƒíƒœ - ì¦ìƒ ê¸°ì¤€ìœ¼ë¡œ merge, ì •ë„ëŠ” ë” ì‹¬í•œ ê²ƒìœ¼ë¡œ ì„ íƒ
                    elif entity_key.endswith("ê±´ê°•ìƒíƒœ"):
                        if old_val.get("ì¦ìƒ") == filtered_value.get("ì¦ìƒ"):
                            # ì •ë„ê°€ ë” ì‹¬í•˜ë©´ ì—…ë°ì´íŠ¸
                            severity_order = {"ê²½ë¯¸": 1, "ë³´í†µ": 2, "ì‹¬í•¨": 3, "ë§¤ìš°ì‹¬í•¨": 4}
                            old_sev = severity_order.get(old_val.get("ì •ë„"), 0)
                            new_sev = severity_order.get(filtered_value.get("ì •ë„"), 0)
                            if new_sev > old_sev:
                                old_val["ì •ë„"] = filtered_value.get("ì •ë„")
                            filtered_value = {**old_val, **filtered_value}
        except Exception as e:
            print("[WARN] merge ì‹¤íŒ¨:", e)

        # ğŸ”„ ì—‘ì…€ ë°±ì—”ë“œë¡œ ì €ì¥ (VectorStore ë¹„í™œì„±í™” ëŒ€ì‘)
        session_id = metadata.get('session_id', 'default')
        try:
            user_name = self.user_names.get(session_id or "default")
            if not user_name or user_name == "ì‚¬ìš©ì":
                print(f"[WARN] ì‚¬ìš©ì ì´ë¦„ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì—”í‹°í‹°ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (session_id: {session_id})")
                return filtered_value
            
            # entity_keyì—ì„œ entity_type ì¶”ì¶œ (ì˜ˆ: "user.ì·¨í–¥" â†’ "ì·¨í–¥")
            entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
            
            # ì—‘ì…€ ì €ì¥ í•¸ë“¤ëŸ¬ (ë²„í¼ë§ êµ¬ì¡° - ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
            # save_entity_data()ëŠ” sheet_mapping.get(entity_type, "ì‚¬ìš©ìì •ë³´KV")ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ
            # ë§¤í•‘ë˜ì§€ ì•Šì€ ì—”í‹°í‹° íƒ€ì…ë„ ì‚¬ìš©ìì •ë³´KVë¡œ ì €ì¥ë¨ (ê¸°íƒ€ ì‹œíŠ¸ ì œê±°)
            self.excel_manager.save_entity_data(user_name, entity_type, filtered_value)
            
            # ì„¸ì…˜ ìºì‹œ ë°˜ì˜ (ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ)
            if not hasattr(self, 'excel_cache'):
                self.excel_cache = {}
            session_cache = self.excel_cache.setdefault(session_id, {})
            
            # entity_typeë³„ ìºì‹œ ì—…ë°ì´íŠ¸
            if entity_type not in session_cache:
                session_cache[entity_type] = []
            
            # ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€ (ê°™ì€ identityê°€ ì—†ì„ ë•Œë§Œ)
            existing = None
            for item in session_cache[entity_type]:
                if isinstance(item, dict):
                    # identity ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ (ê°„ë‹¨í•œ ë¬¸ìì—´ ë§¤ì¹­)
                    if identity and str(identity) in str(item):
                        existing = item
                        break
            
            if existing and strategy == "merge":
                # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
                merged = self._merge_entity_values(existing, filtered_value, entity_key)
                session_cache[entity_type] = [
                    merged if (isinstance(item, dict) and str(identity) in str(item)) else item
                    for item in session_cache[entity_type]
                ]
                filtered_value = merged
            elif not existing:
                # ìƒˆ í•­ëª© ì¶”ê°€
                session_cache[entity_type].append(filtered_value)
            
            print(f"[INFO] ì—‘ì…€ ë°±ì—”ë“œë¡œ ì—”í‹°í‹° ì €ì¥ ì™„ë£Œ: ({entity_type}) â†’ {user_name}.xlsx")
        except Exception as e:
            print(f"[ERROR] _add_to_vstore ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        return filtered_value

    def _get_facts_text(self, session_id: str) -> str:
        """Excel ê¸°ë°˜ ì‚¬ì‹¤ ìš”ì•½ë¬¸"""
        if not hasattr(self, "excel_cache"):
            return ""
        sess = self.excel_cache.get(session_id, {})
        facts = []
        if sess.get("ì‚¬ìš©ì"):
            u = sess["ì‚¬ìš©ì"][0]
            facts.append(f"ì´ë¦„ì€ {u.get('ì´ë¦„')}ì´ê³ , ë‚˜ì´ëŠ” {u.get('ë‚˜ì´')}ì…ë‹ˆë‹¤.")
        if sess.get("ë¬¼ê±´"):
            for it in sess["ë¬¼ê±´"][-3:]:
                facts.append(f"{it.get('ì´ë¦„')}ì€ {it.get('ìœ„ì¹˜')}ì— ìˆìŠµë‹ˆë‹¤.")
        if sess.get("ì‹ì‚¬"):
            for meal in sess["ì‹ì‚¬"][-3:]:
                facts.append(f"{meal.get('ë‚ ì§œ')} {meal.get('ë¼ë‹ˆ')}ì—ëŠ” {', '.join(meal.get('ë©”ë‰´', []))}ì„ ë¨¹ì—ˆìŠµë‹ˆë‹¤.")
        return "\n".join(facts)

    # ì—”í‹°í‹° ì—…ì„œíŠ¸ ë° ëˆ„ë½ í•„ë“œì— ëŒ€í•œ follow-up ì§ˆë¬¸ ìƒì„±
    def _upsert_entities_and_get_confirms(self, session_id: str, entities: Dict[str, List[Dict[str, Any]]], user_input: str = None) -> Tuple[List[str], bool]:
        """ì—”í‹°í‹° ì—…ì„œíŠ¸ ë° ëˆ„ë½ í•„ë“œì— ëŒ€í•œ follow-up ì§ˆë¬¸ ìƒì„±"""
        questions: List[str] = []
        has_schedule = False  # ì¼ì • ì €ì¥ ì—¬ë¶€ í™•ì¸
        
        # íƒ€ì… ì•ˆì „ì„± ì²´í¬
        if not isinstance(entities, dict):
            print(f"[ERROR] _upsert_entities_and_get_confirms: entitiesê°€ dictê°€ ì•„ë‹˜ {type(entities)}: {entities}")
            return [], False
        
        # ì¬ì§ˆë¬¸ ì²˜ë¦¬
        for entity_key, entity_list in entities.items():
            for entity in entity_list:
                if isinstance(entity, dict) and "ì§ˆë¬¸" in entity:
                    print(f"[DEBUG] ì¬ì§ˆë¬¸ ì²˜ë¦¬ (ìƒìœ„): {entity['ì§ˆë¬¸']}")
                    questions.append(entity["ì§ˆë¬¸"])
                    return questions, has_schedule
        
        # ì „ì—­ ì¬ì§ˆë¬¸ ì²´í¬
        if session_id in self.current_question:
            question = self.current_question[session_id]
            print(f"[DEBUG] _upsert_entities_and_get_confirmsì—ì„œ ì „ì—­ ì¬ì§ˆë¬¸ ë°œê²¬: {question}")
            questions.append(question)
            return questions, has_schedule

        # ì •ì • ìš”ì²­ ê°ì§€ (ì‚¬ìš©ìê°€ ì´ë¯¸ ë‹µë³€í–ˆë‹¤ê³  ëª…ì‹œí•œ ê²½ìš°)
        correction_keywords = ["ì´ë¯¸ ë§í–ˆ", "ì´ë¯¸ ë§í–ˆëŠ”ë°", "ì´ë¯¸ ë‹µí–ˆ", "ì´ë¯¸ ë‹µí–ˆëŠ”ë°", "ì•„ê¹Œ ë§í–ˆ", "ì•„ê¹Œ ë§í–ˆëŠ”ë°"]
        is_correction = any(keyword in user_input for keyword in correction_keywords)
        
        # ëª¨ë¦„/ì—†ìŒ ì‘ë‹µ ê°ì§€ (ì‚¬ìš©ìê°€ ëª¨ë¥´ê±°ë‚˜ ì—†ë‹¤ê³  ë‹µí•œ ê²½ìš°)
        skip_keywords = ["ëª¨ë¥´ê² ", "ì—†ì–´", "ëª°ë¼", "ì—†ë‹¤", "ëª¨ë¦„", "ê¸°ì–µ ì•ˆë‚˜", "ê¸°ì–µì•ˆë‚˜", "ì˜ ëª¨ë¥´", "ì˜ëª¨ë¥´"]
        is_skip_response = any(keyword in user_input for keyword in skip_keywords)
        
        if is_correction:
            logger.debug("ì •ì • ìš”ì²­ ê°ì§€: ì‚¬ìš©ìê°€ ì´ë¯¸ ë‹µë³€í–ˆë‹¤ê³  ëª…ì‹œí•¨")
            # ì •ì • ìš”ì²­ì¸ ê²½ìš° ì¶”ê°€ ì§ˆë¬¸ ìƒì„±í•˜ì§€ ì•ŠìŒ
            return [], has_schedule
        
        if is_skip_response:
            logger.debug("ëª¨ë¦„/ì—†ìŒ ì‘ë‹µ ê°ì§€: ì‚¬ìš©ìê°€ ëª¨ë¥´ê±°ë‚˜ ì—†ë‹¤ê³  ë‹µí•¨")
            # ëª¨ë¦„/ì—†ìŒ ì‘ë‹µì¸ ê²½ìš° ëˆ„ë½ëœ í•„ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê³  ì €ì¥
            for entity_key, values in entities.items():
                for value in values:
                    try:
                        # N/A ê°’ í•„í„°ë§
                        filtered_value = self._filter_meaningful_data(value, user_input)
                        if not filtered_value:
                            continue
                        
                        # ì¬ì§ˆë¬¸ì´ ë°˜í™˜ëœ ê²½ìš°
                        if isinstance(filtered_value, dict) and "ì§ˆë¬¸" in filtered_value:
                            print(f"[DEBUG] ì¬ì§ˆë¬¸ ì²˜ë¦¬: {filtered_value['ì§ˆë¬¸']}")
                            questions.append(filtered_value["ì§ˆë¬¸"])
                            return questions, has_schedule
                    except Exception as e:
                        if str(e).startswith("QUESTION:"):
                            question = str(e)[9:]  # "QUESTION:" ì œê±°
                            print(f"[DEBUG] _upsert_entities_and_get_confirmsì—ì„œ ì¬ì§ˆë¬¸ ì˜ˆì™¸ ì²˜ë¦¬: {question}")
                            questions.append(question)
                            return questions, has_schedule
                        raise e
                    
                    missing_fields = self._check_missing_fields(entity_key, filtered_value)
                    if missing_fields:
                        # ëˆ„ë½ëœ í•„ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                        for field in missing_fields:
                            if field == "ì‹œê°„":
                                filtered_value[field] = "ë¯¸ì •"
                            elif field == "ë‚ ì§œ":
                                filtered_value[field] = "ì˜¤ëŠ˜"
                            elif field == "ì•½ëª…":
                                filtered_value[field] = "ë¯¸ì •"
                            elif field == "ì œëª©":
                                filtered_value[field] = "ë¯¸ì •"
                            else:
                                filtered_value[field] = "ë¯¸ì •"
                        
                        # ìˆ˜ì •ëœ ì—”í‹°í‹° ì €ì¥
                        self._add_to_vstore(
                            entity_key, filtered_value,
                            {"session_id": session_id, "entity_key": entity_key, "type": "entity", "created_at": datetime.now().isoformat()},
                            session_id=session_id,
                            strategy="merge"
                        )
                        
                        if entity_key.endswith("ì¼ì •"):
                            has_schedule = True
            
            return [], has_schedule

        self._prevent_name_family_conflict(entities)

        for entity_key, values in entities.items():
            # print(f"[DEBUG] ì—”í‹°í‹° ì²˜ë¦¬ ì‹œì‘: {entity_key} - {values}")
            
            # ì‚¬ìš©ì ì—”í‹°í‹°ì˜ ê²½ìš° ë³‘í•© ë¡œì§ ì ìš©
            if entity_key == "user.ì‚¬ìš©ì":
                # ê¸°ì¡´ ì‚¬ìš©ì ì—”í‹°í‹° ì¡°íšŒ
                existing_users = self._get_existing_user_entities(session_id)
                
                # ìƒˆ ì—”í‹°í‹°ë“¤ê³¼ ê¸°ì¡´ ì—”í‹°í‹°ë“¤ ë³‘í•©
                merged_users = existing_users
                for value in values:
                    filtered_value = self._filter_meaningful_data(value)
                    if not filtered_value:
                        continue
                    
                    if not self._is_valid_entity(entity_key, filtered_value):
                        continue
                    
                    # ë³‘í•© ë¡œì§ ì ìš©
                    merged_users = self._merge_user_entities(merged_users, filtered_value)
                
                # ë³‘í•©ëœ ì‚¬ìš©ì ì—”í‹°í‹°ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
                for user_entity in merged_users:
                    # N/A ê°’ í•„í„°ë§
                    filtered_value = self._filter_meaningful_data(user_entity)
                    if not filtered_value:
                        continue
                    
                    # ì—”í‹°í‹° ìœ íš¨ì„± ê²€ì‚¬
                    if not self._is_valid_entity(entity_key, filtered_value):
                        continue
                    
                    # ì‚¬ìš©ì ì—”í‹°í‹° ì²˜ë¦¬ ê³„ì†...
                    self._process_single_entity(entity_key, filtered_value, session_id, questions, has_schedule)
            else:
                # ë‹¤ë¥¸ ì—”í‹°í‹°ë“¤ì€ ê¸°ì¡´ ë¡œì§ ìœ ì§€
                for value in values:
                    # N/A ê°’ í•„í„°ë§
                    filtered_value = self._filter_meaningful_data(value)
                    if not filtered_value:
                        print(f"[INFO] ì˜ë¯¸ì—†ëŠ” ë°ì´í„° í•„í„°ë§: {entity_key} - {value}")
                        continue
                    
                    # ì—”í‹°í‹° ìœ íš¨ì„± ê²€ì‚¬
                    if not self._is_valid_entity(entity_key, filtered_value):
                        print(f"[INFO] ìœ íš¨í•˜ì§€ ì•Šì€ ì—”í‹°í‹° ìŠ¤í‚µ: {entity_key} - {filtered_value}")
                        continue
                        
                    # ì—”í‹°í‹° ì²˜ë¦¬ ê³„ì†...
                    self._process_single_entity(entity_key, filtered_value, session_id, questions, has_schedule)
                
                # ì¼ì • ì €ì¥ í™•ì¸
                if entity_key.endswith("ì¼ì •"):
                    has_schedule = True
                
                # ì‹ì‚¬ ì—”í‹°í‹°ì—ì„œ ì‹œê°„ì´ ì—†ìœ¼ë©´ ê°•ì œë¡œ ì§ˆë¬¸ ì¶”ê°€ (í•„ìˆ˜ í•„ë“œ ì²´í¬ì—ì„œ ì²˜ë¦¬ë¨)
                
                # ì•½ì„ ì‹ì‚¬ë¡œ ì°©ê°í•œ ê²½ìš° ì œê±°
                if entity_key.endswith("ì‹ì‚¬") and "ë©”ë‰´" in filtered_value:
                    menus = filtered_value["ë©”ë‰´"]
                    if isinstance(menus, list):
                        # ì•½ëª…ì´ í¬í•¨ëœ ë©”ë‰´ ì œê±°
                        filtered_menus = [menu for menu in menus if not menu.endswith("ì•½")]
                        if not filtered_menus:
                            # ëª¨ë“  ë©”ë‰´ê°€ ì•½ì´ë©´ ì´ ì‹ì‚¬ ì—”í‹°í‹° ì œê±°
                            print(f"[INFO] ì•½ì„ ì‹ì‚¬ë¡œ ì°©ê°í•œ ì—”í‹°í‹° ì œê±°: {entity_key} - {filtered_value}")
                            continue
                        filtered_value["ë©”ë‰´"] = filtered_menus
                
                # í•„ìˆ˜ í•„ë“œ ì²´í¬
                missing_fields = self._check_missing_fields(entity_key, filtered_value)

                if missing_fields:
                    # 3ï¸âƒ£ í•„ìˆ˜ í•„ë“œê°€ ë¹„ë©´ follow-up ì§ˆë¬¸ ìƒì„± (ì €ì¥ì€ ë³´ë¥˜)
                    logger.debug(f"ëˆ„ë½ëœ í•„ë“œ ê°ì§€: {entity_key} - {missing_fields}, ê°’: {filtered_value}")
                    followup_questions = self._generate_followup_questions(entity_key, missing_fields, filtered_value)
                    questions.extend(followup_questions)
                    
                    # ì‹ì‚¬ ì—”í‹°í‹°ëŠ” ë©”ë‰´ë‚˜ ì‹œê°„ì´ ì—†ì–´ë„ ì €ì¥ (ì ì§„ì  ì •ë³´ ìˆ˜ì§‘)
                    if entity_key.endswith("ì‹ì‚¬") and (
                        ("ë©”ë‰´" in missing_fields and filtered_value.get("ë©”ë‰´") == []) or
                        ("ì‹œê°„" in missing_fields and not filtered_value.get("ì‹œê°„"))
                    ):
                        # ë©”ë‰´ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ê±°ë‚˜ ì‹œê°„ì´ ì—†ëŠ” ê²½ìš°ì—ë„ ì €ì¥
                        final_value = self._add_to_vstore(
                            entity_key, filtered_value,
                            {"session_id": session_id, "entity_key": entity_key, "type": "entity", "created_at": datetime.now().isoformat()},
                            strategy="merge"
                        )
                        logger.debug(f"ì‹ì‚¬ ì—”í‹°í‹° ì„ì‹œ ì €ì¥ (ë©”ë‰´/ì‹œê°„ ëˆ„ë½): {filtered_value}")
                        
                        # ì‹œê°„ì´ ëˆ„ë½ëœ ê²½ìš° ì¬ì§ˆë¬¸ ìƒíƒœ ì„¤ì •
                        if "ì‹œê°„" in missing_fields and not filtered_value.get("ì‹œê°„"):
                            self.pending_question[session_id] = {
                                "ê¸°ì¡´_ì—”í‹°í‹°": final_value,
                                "ìƒˆ_ì—”í‹°í‹°": final_value,
                                "entity_key": entity_key
                            }
                            print(f"[DEBUG] ì¬ì§ˆë¬¸ ìƒíƒœ ì„¤ì •: {entity_key} - ì‹œê°„ ëˆ„ë½")
                    else:
                        continue

                # 2ï¸âƒ£ ëª¨ë“  í•„ìˆ˜ í•„ë“œê°€ ìˆìœ¼ë©´ ì €ì¥ (merge ì •ì±… ì ìš©)
                final_value = self._add_to_vstore(
                    entity_key, filtered_value,
                    {"session_id": session_id, "entity_key": entity_key, "type": "entity", "created_at": datetime.now().isoformat()},
                    strategy="merge"
                )

                # ì•½ì€ ë³µìš© ì •ë³´ ì„¸ë¶€ í•„ë“œ í™•ì¸ í›„ ì¶”ê°€ ì§ˆë¬¸
                if entity_key.endswith(".ì•½"):
                    if final_value.get("ë³µìš©"):
                        enriched = [self._enrich_dose_dict(d) for d in final_value["ë³µìš©"]]
                        final_value["ë³µìš©"] = enriched
                        
                        # enrichëœ ì •ë³´ë¥¼ VectorStoreì— ì—…ë°ì´íŠ¸
                        try:
                            self._add_to_vstore(
                                entity_key=entity_key,
                                value=final_value,
                                session_id=session_id,
                                metadata={"session_id": session_id, "type": "entity"},
                                strategy="merge",
                                identity=final_value.get("ì•½ëª…")
                            )
                            # print(f"[DEBUG] ë³µìš© ì •ë³´ enrich í›„ VectorStore ì—…ë°ì´íŠ¸ ì™„ë£Œ: {final_value.get('ì•½ëª…')}")
                        except Exception as e:
                            print(f"[WARN] ë³µìš© ì •ë³´ enrich í›„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                        
                        # ë³µìš© ì •ë³´ê°€ ì´ë¯¸ ìˆëŠ” ê²½ìš° ì¶”ê°€ ì§ˆë¬¸í•˜ì§€ ì•ŠìŒ
                        # "ë³µìš©" í•„ë“œê°€ ìˆìœ¼ë©´ ì¶©ë¶„í•œ ì •ë³´ë¡œ ê°„ì£¼
                        has_complete_info = True
                        
                        # ë³µìš© ì •ë³´ê°€ ì™„ì „í•˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì§ˆë¬¸ (í•˜ì§€ë§Œ ê¸°ë³¸ì ì¸ ë³µìš© ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶©ë¶„)
                        # if not has_complete_info:
                        #     questions.append(f"{final_value.get('ì•½ëª…','ì•½')}ì€ í•˜ë£¨ì— ëª‡ ë²ˆ ë³µìš©í•˜ë‚˜ìš”?")

                    # ë³µìš© ì •ë³´ê°€ ì—†ê±°ë‚˜ ë¶ˆì™„ì „í•œ ê²½ìš°ì—ë§Œ ì§ˆë¬¸
                    if not final_value.get("ë³µìš©") and not final_value.get("ì‹ì‚¬ì™€ì˜ ê´€ê³„"):
                        questions.append(f"{final_value.get('ì•½ëª…','ì•½')}ì€ ì–¸ì œ, í•˜ë£¨ ëª‡ ë²ˆ ë³µìš©í•˜ë‚˜ìš”?")
                    # ë³µìš© ê¸°ê°„ ì§ˆë¬¸ì€ ì œê±° (ì´ë¯¸ ë³µìš© ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶©ë¶„)

        # ì¤‘ë³µ ì œê±°
        return list(dict.fromkeys(questions)), has_schedule

    # ìš”ì•½ ì €ì¥ (ì„¸ì…˜ ë‹¨ìœ„ ê²©ë¦¬)
    def save_final_summary(self, session_id: str):
        print(f"[DEBUG] save_final_summary ì‹œì‘: session_id={session_id}")
        print(f"[DEBUG] auto_export_enabled: {self.cfg.auto_export_enabled}")
        
        # message_storeì—ì„œ ëŒ€í™” ê¸°ë¡ ì§ì ‘ ì¡°íšŒ
        try:
            import sqlite3
            conn = sqlite3.connect(self.sqlite_path)
            c = conn.cursor()
            c.execute("SELECT id, session_id, role, content, message FROM message_store WHERE session_id = ? ORDER BY id", (session_id,))
            messages = c.fetchall()
            conn.close()
            
            print(f"[DEBUG] message_storeì—ì„œ ì¡°íšŒëœ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
            
            if len(messages) == 0:
                print(f"[INFO] ì„¸ì…˜ {session_id}ì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            # texts ìƒì„± (message ì»¬ëŸ¼ì—ì„œ JSON íŒŒì‹±í•˜ì—¬ ì¶”ì¶œ)
            texts = []
            for msg in messages:
                role = msg[2]  # role ì»¬ëŸ¼
                content = msg[3]  # content ì»¬ëŸ¼
                message = msg[4]  # message ì»¬ëŸ¼
                
                # contentê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ messageì—ì„œ JSON íŒŒì‹±
                if content:
                    texts.append(content)
                elif message:
                    try:
                        import json
                        msg_data = json.loads(message)
                        if 'data' in msg_data and 'content' in msg_data['data']:
                            texts.append(msg_data['data']['content'])
                    except (json.JSONDecodeError, KeyError):
                        pass
            
            print(f"[DEBUG] texts ê¸¸ì´: {len(texts)}")
            
        except Exception as e:
            print(f"[ERROR] message_store ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return
        
        # ìë™ ì¶”ì¶œ ì‹¤í–‰
        if self.cfg.auto_export_enabled:
            print(f"[DEBUG] ìë™ ì¶”ì¶œ ì‹œì‘: session_id={session_id}")
            try:
                self.export_conversation_to_excel(session_id)
                print(f"[INFO] ëŒ€í™” ê¸°ë¡ì´ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: conversation_extract/{session_id}.xlsx")
            except Exception as e:
                print(f"[ERROR] ì—‘ì…€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì‚¬ìš©ì ì´ë¦„ í™•ì •ê°’ ê°€ì ¸ì˜¤ê¸° (hallucination ë°©ì§€)
        confirmed_name = self._get_confirmed_user_name(session_id)
        
        # ê°ì • ìƒíƒœ ì •ë³´ ì¶”ê°€
        emotional_context = ""
        if session_id in self.emotional_state:
            emotional_info = self.emotional_state[session_id]
            if emotional_info.get("mood") and emotional_info.get("intensity", 0) > 0.5:
                mood = emotional_info["mood"]
                intensity = emotional_info["intensity"]
                if mood == "negative":
                    emotional_context = f" ì‚¬ìš©ìëŠ” í”¼ê³¤í•¨, ì–´ì§€ëŸ¬ì›€, ìš°ìš¸í•¨ ë“±ì˜ ë¶€ì •ì  ê°ì •ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤."
                elif mood == "positive":
                    emotional_context = f" ì‚¬ìš©ìëŠ” ê¸°ì¨, ë§Œì¡±ê° ë“±ì˜ ê¸ì •ì  ê°ì •ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤."
        
        # ì„¸ì…˜ë³„ ìš”ì•½ ìƒì„± (ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸)
        system_prompt = (
            "ë‹¤ìŒ ëŒ€í™”ë¥¼ ì •í™•íˆ ìš”ì•½í•˜ì„¸ìš”.\n\n"
            "ì˜ˆì‹œ:\n"
            "ì‚¬ìš©ì: 'ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼'\n"
            "AI: 'ê¹€ì² ìˆ˜ë‹˜ì˜ ì´ë¦„ì„ ì €ì¥í–ˆì–´ìš”'\n"
            "ìš”ì•½: ì‚¬ìš©ìê°€ ìì‹ ì˜ ì´ë¦„ì„ 'ê¹€ì² ìˆ˜'ë¼ê³  ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\n\n"
            "ê·œì¹™:\n"
            "- ëŒ€í™”ì— ìˆëŠ” ë‚´ìš©ë§Œ ê¸°ë¡í•˜ì„¸ìš”\n"
            "- ì´ë¦„, ì•½ëª…, ìŒì‹ëª…ì€ ì •í™•íˆ ê·¸ëŒ€ë¡œ ê¸°ë¡í•˜ì„¸ìš”\n"
            "- 'ì˜¤ëŠ˜'ì€ í˜„ì¬ ë‚ ì§œë¡œ ë³€í™˜í•˜ì„¸ìš”\n"
        )
        
        if confirmed_name:
            system_prompt += f"5) ì‚¬ìš©ìì˜ ì´ë¦„ì€ '{confirmed_name}'ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n"
        
        system_prompt += f"ì„¸ì…˜ ID: {session_id}"
        
        # JSON ë³€ìˆ˜ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        escaped_texts = []
        for text in texts:
            # JSON í˜•íƒœì˜ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„
            escaped_text = text.replace("{", "{{").replace("}", "}}")
            escaped_texts.append(escaped_text)
        
        summary_prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", f"ì„¸ì…˜ {session_id}ì˜ ëŒ€í™” ë‚´ìš©{emotional_context}:\n" + "\n".join(escaped_texts)),
        ])
        chain = summary_prompt | self.llm | StrOutputParser()
        summary_text = chain.invoke({})
        
        conn = sqlite3.connect(self.sqlite_path)
        c = conn.cursor()
        
        # í•­ìƒ ìƒˆë¡œìš´ ìš”ì•½ì„ ì‚½ì… (ëˆ„ì  ë°©ì‹)
        c.execute("INSERT INTO conversation_summary (session_id, summary, created_at, updated_at) VALUES (?, ?, ?, ?)", 
                 (session_id, summary_text, datetime.now().isoformat(), datetime.now().isoformat()))
        # print(f"[DEBUG] SQLite ìš”ì•½ ì €ì¥ ì™„ë£Œ (ì„¸ì…˜: {session_id}) - ëˆ„ì  ë°©ì‹")
        
        conn.commit()
        conn.close()
        
        # ìë™ ì¶”ì¶œ ì‹¤í–‰
        print(f"[DEBUG] ìë™ ì¶”ì¶œ ì‹œì‘: session_id={session_id}, auto_export_enabled={self.cfg.auto_export_enabled}")
        self.auto_export_conversation(session_id)

    # ëŒ€í™” ì‹œìŠ¤í…œ ì²´ì¸
    def build_chain(self) -> Runnable:
        system_tmpl = (
            "ë‹¹ì‹ ì€ ìƒí™œ ì§€ì› ë¡œë´‡ì…ë‹ˆë‹¤.\n"
            "ìµœê·¼ ëŒ€í™” ìš”ì•½: {summary}\n"
            "ì €ì¥ëœ ì—”í‹°í‹°: {entities}\n"
            "ì´ë²ˆ í„´ ì—”í‹°í‹°: {staged_entities}\n"
            "ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸:\n{retrieved}\n\n"
            "ê·œì¹™:\n"
            "- ì €ì¥ëœ ì •ë³´ë¥¼ ìš°ì„  í™œìš©.\n"
            "- ëª¨ë¥´ëŠ” ì •ë³´ê°€ ìˆìœ¼ë©´ 'ì•„ì§ ê·¸ ì •ë³´ëŠ” ëª°ë¼ìš”. ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•´ë‘˜ê²Œìš”!'ë¼ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€.\n"
            "- ë‹µë³€ì€ ê°„ê²°í•œ í•œêµ­ì–´."
        )
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_tmpl),
            MessagesPlaceholder("history"),
            ("human", "{input}"),
        ])
        return (
            {
                "summary": lambda x: x.get("summary", "(ìš”ì•½ ì—†ìŒ)"),
                "entities": lambda x: x.get("entities", "[]"),
                "staged_entities": lambda x: x.get("staged_entities", "[]"),
                "retrieved": lambda x: x.get("retrieved", ""),
                "history": lambda x: x.get("history", []),
                "input": lambda x: x["input"],
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

    def _get_all_medications(self, session_id: str) -> List[dict]:
        """Excel ê¸°ë°˜ ì•½ ëª©ë¡ ì¡°íšŒ"""
        try:
            user_name = self.user_names.get(session_id or "default")
            if not user_name:
                return []
            df = self.excel_manager.load_sheet_data(user_name, "ë³µì•½ì •ë³´")
            if df is None or df.empty:
                return []
            return df.to_dict("records")
        except Exception as e:
            print(f"[ERROR] ì•½ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    # ì¶œë ¥ í¬ë§· (2ì°¨ ëª©í‘œ: ì¼ì •/ì•½/ì‹ì‚¬ë„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥í™”)
    def _format_entities_for_output(self, user_input: str, ents: List[Document], session_id: str = "default") -> str:
        if not ents:
            # ì‚¬ìš©ì ì´ë¦„ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í˜¸ì¹­
            user_name = self._get_confirmed_user_name(session_id)
            if user_name and user_name != "ì‚¬ìš©ì":
                return f"ì•„ì§ ê·¸ ì •ë³´ëŠ” ëª°ë¼ìš”, {user_name}ë‹˜. ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•´ë‘˜ê²Œìš”!"
            else:
                return "ì•„ì§ ê·¸ ì •ë³´ëŠ” ëª°ë¼ìš”. ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•´ë‘˜ê²Œìš”!"
        lines = []
        for d in ents:
            try:
                val = json.loads(d.page_content)
                # print(f"[DEBUG] ë¬¸ì„œ ì²˜ë¦¬: {val}")
            except Exception as e:
                print(f"[DEBUG] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
            etype = d.metadata.get("entity_key", "")
            # print(f"[DEBUG] ì—”í‹°í‹° íƒ€ì…: {etype}")
            
            # ì‚¬ìš©ì
            if etype.endswith("ì‚¬ìš©ì") and val.get("ì´ë¦„"):
                # print(f"[DEBUG] ì‚¬ìš©ì ì´ë¦„ ì¶”ê°€: {val['ì´ë¦„']}")
                lines.append(f"ë„¤, {val['ì´ë¦„']}ë‹˜ì´ì—ìš”.")
            
            # ë¬¼ê±´
            elif etype.endswith("ë¬¼ê±´"):
                if val.get("ìœ„ì¹˜"):
                    # ì €ì¥ ì‹œì ì—ì„œ ì´ë¯¸ ì •ê·œí™”ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¨ìˆœíˆ "ì— ìˆì–´ìš”"ë§Œ ë¶™ì„
                    lines.append(f"{val.get('ì´ë¦„')}ì€ {val.get('ìœ„ì¹˜')}ì— ìˆì–´ìš”.")
                else:
                    lines.append(f"{val.get('ì´ë¦„')}ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
            
            # ì¼ì •
            elif etype.endswith("ì¼ì •"):
                title = val.get("ì œëª©", "ì¼ì •")
                date = val.get("ë‚ ì§œ", "")
                time = val.get("ì‹œê°„", "")
                location = val.get("ì¥ì†Œ", "")
                
                # ë‚ ì§œ ì •ê·œí™” ì ìš© (ê¸°ì¡´ ë°ì´í„°ë„ ì •ê·œí™”)
                if date:
                               date = self._normalize_date(date, session_id)
                
                parts = [title]
                if date:
                    parts.append(f"{date}ì—")
                if time:
                    # ì‹œê°„ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(time, list):
                        time = ', '.join(time)
                    parts.append(f"{time}ì—")
                if location:
                    parts.append(f"{location}ì—ì„œ")
                
                lines.append(" ".join(parts) + " ì˜ˆì •ì´ì—ìš”.")
            
            # ì•½
            elif etype.endswith("ì•½"):
                drug_name = val.get("ì•½ëª…", "ì•½")
                doses = val.get("ë³µìš©", [])
                period = val.get("ë³µìš© ê¸°ê°„", "")
                
                if doses:
                    dose_info = []
                    for dose in doses:
                        if dose.get("ì›ë¬¸"):
                            dose_info.append(dose["ì›ë¬¸"])
                    if dose_info:
                        lines.append(f"{drug_name}ì„ {', '.join(dose_info)} ë³µìš©í•˜ì‹œëŠ”êµ°ìš”.")
                else:
                    lines.append(f"{drug_name}ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
                
                if period:
                    lines.append(f"ë³µìš© ê¸°ê°„ì€ {period}ì´ì—ìš”.")
                else:
                    lines.append("ë³µìš© ê¸°ê°„ì€ ì•„ì§ ì•ˆ ì•Œë ¤ì£¼ì…¨ì–´ìš”.")
            
            # ì‹ì‚¬
            elif etype.endswith("ì‹ì‚¬"):
                meal = val.get("ë¼ë‹ˆ", "")
                menus = val.get("ë©”ë‰´", [])
                date = val.get("ë‚ ì§œ", "")
                time = val.get("ì‹œê°„", "")
                
                # ë‚ ì§œ ì •ê·œí™” ì ìš© (ê¸°ì¡´ ë°ì´í„°ë„ ì •ê·œí™”)
                if date:
                               date = self._normalize_date(date, session_id)
                
                parts = []
                if date:
                    parts.append(f"{date}")
                if meal:
                    parts.append(f"{meal}ì—")
                if time:
                    # ì‹œê°„ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(time, list):
                        time = ', '.join(time)
                    parts.append(f"{time}ì—")
                if menus:
                    parts.append(f"{', '.join(menus)}ì„ ë“œì…¨ì–´ìš”.")
                
                if parts:
                    lines.append(" ".join(parts))
                else:
                    lines.append("ì‹ì‚¬ ì •ë³´ë¥¼ ì•Œê³  ìˆì–´ìš”.")
            
            # ê°€ì¡±
            elif etype.endswith("ê°€ì¡±"):
                relation = val.get("ê´€ê³„", "")
                name = val.get("ì´ë¦„", "")
                if relation and name:
                    lines.append(f"{relation} {name}ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
                elif relation:
                    lines.append(f"{relation}ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
            
            # ë™ì  ê´€ê³„ ì—”í‹°í‹° ì²˜ë¦¬ (í•˜ë“œì½”ë”© ì œê±°)
            # ê¸°ë³¸ ì—”í‹°í‹° íƒ€ì…ì´ ì•„ë‹Œ ê²½ìš° ë™ì ìœ¼ë¡œ ì²˜ë¦¬
            elif not etype.endswith(("ì‚¬ìš©ì", "ë¬¼ê±´", "ì¼ì •", "ì•½", "ì‹ì‚¬", "ê°€ì¡±", "ê¸°ë…ì¼", "ì·¨ë¯¸", "ì·¨í–¥", "ê±´ê°•ìƒíƒœ")):
                name = val.get("ì´ë¦„", "")
                relation_type = etype.replace("user.", "")
                if name:
                    lines.append(f"{relation_type} {name}ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
                else:
                    lines.append(f"{relation_type}ì— ëŒ€í•´ ì•Œê³  ìˆì–´ìš”.")
            
            # ê¸°ë…ì¼
            elif etype.endswith("ê¸°ë…ì¼"):
                title = val.get("ì œëª©", "")
                date = val.get("ë‚ ì§œ", "")
                relation = val.get("ê´€ê³„", "")
                
                # ë‚ ì§œ ì •ê·œí™” ì ìš© (ê¸°ì¡´ ë°ì´í„°ë„ ì •ê·œí™”)
                if date:
                               date = self._normalize_date(date, session_id)
                
                parts = []
                if relation:
                    parts.append(f"{relation}ì˜")
                if title:
                    parts.append(f"{title}")
                if date:
                    parts.append(f"{date}ì—")
                
                if parts:
                    lines.append(" ".join(parts) + " ê¸°ë…ì¼ì´ì—ìš”.")
            
            # ê±´ê°•ìƒíƒœ
            elif etype.endswith("ê±´ê°•ìƒíƒœ"):
                symptom = val.get("ì¦ìƒ", "")
                severity = val.get("ì •ë„", "")
                period = val.get("ê¸°ê°„", "")
                
                parts = []
                if symptom:
                    parts.append(f"{symptom} ì¦ìƒ")
                if severity:
                    parts.append(f"{severity}í•œ ì •ë„")
                if period:
                    parts.append(f"{period} ë™ì•ˆ")
                
                if parts:
                    lines.append(" ".join(parts) + "ì´ ìˆìœ¼ì‹œêµ°ìš”.")
            
            # ì·¨ë¯¸
            elif etype.endswith("ì·¨ë¯¸"):
                hobby = val.get("ì´ë¦„", "")
                if hobby:
                    lines.append(f"{hobby} ì·¨ë¯¸ë¥¼ ê°€ì§€ê³  ê³„ì‹œëŠ”êµ°ìš”.")
            
            # ì·¨í–¥
            elif etype.endswith("ì·¨í–¥"):
                category = val.get("ì¢…ë¥˜", "")
                value = val.get("ê°’", "")
                if category and value:
                    lines.append(f"{category}ì—ì„œ {value}ì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”.")
                elif value:
                    lines.append(f"{value}ì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”.")
        
        # print(f"[DEBUG] _format_entities_for_output ìµœì¢… lines: {lines}")
        result = " ".join(lines) if lines else "ì•„ì§ ê·¸ê±´ ëª°ë¼ìš”."
        # print(f"[DEBUG] _format_entities_for_output ìµœì¢… ê²°ê³¼: {result}")
        return result

    # generate
    def process_user_input(self, user_text: str, session_id: str = "default") -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        print(f"[DEBUG] process_user_input í˜¸ì¶œë¨: '{user_text}'")
        try:
            # âœ… 0. ì„¸ì…˜ ì´ˆê¸°í™” (ì²« ë°œí™”ì¸ ê²½ìš° ì´ì „ ëŒ€í™” ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸°)
            if not hasattr(self, '_session_initialized'):
                self._session_initialized = set()
            
            if session_id not in self._session_initialized:
                print(f"[DEBUG] ì„¸ì…˜ {session_id} ì´ˆê¸°í™” ì™„ë£Œ")
                self._session_initialized.add(session_id)
            
            # âœ… 1. pending_question í™•ì¸ â†’ ì¬ì§ˆë¬¸ ë‹µë³€ ì²˜ë¦¬
            if session_id in self.pending_question:
                print(f"[DEBUG] pending_question ë°œê²¬: {self.pending_question[session_id]}")
                # âœ… í™•ì¸ ì‘ë‹µì¸ì§€ ë¨¼ì € ì²´í¬ (ì•ˆì „ ê°€ë“œ)
                import re
                yes_pattern = re.compile(r"^(ì‘|ë„¤|ì¢‹ì•„|ê·¸ë˜|ã…‡ã…‡|ì›…|ë§ì•„)\s*$", re.IGNORECASE)
                no_pattern = re.compile(r"^(ì•„ë‹ˆ|ê´œì°®ì•„|ëì–´|ã„´ã„´|ì‹«ì–´)\s*$", re.IGNORECASE)
                
                if yes_pattern.match(user_text.strip()) or no_pattern.match(user_text.strip()):
                    followup = handle_pending_answer(user_text, self, session_id)
                    if followup:
                        return followup
                else:
                    print(f"[DEBUG] pending_questionì´ ìˆì§€ë§Œ í™•ì¸ ì‘ë‹µì´ ì•„ë‹˜: '{user_text}' - ì¼ë°˜ ì²˜ë¦¬ë¡œ ì§„í–‰")

            # âœ… 2. ë¶„ë¥˜ (ìœ ì‚¬ ìºì‹± ìš°ì„  ì ìš©) - ì—”í‹°í‹° ì¶”ì¶œì€ ê° í•¸ë“¤ëŸ¬ì—ì„œ ì²˜ë¦¬
            print(f"[DEBUG] ë¶„ë¥˜ ì‹œì‘")
            
            # ë¨¼ì € ìœ ì‚¬ ìºì‹œ í™•ì¸
            cached_result = self._get_cached_classification(user_text)
            if cached_result:
                print(f"[DEBUG] ìœ ì‚¬ ìºì‹œ ì‚¬ìš©: {cached_result['category']} (ì‹ ë¢°ë„: {cached_result['confidence']:.2f})")
                from .task_classifier import ClassificationResult
                result = ClassificationResult(
                    category=cached_result["category"],
                    confidence=cached_result["confidence"],
                    probabilities=cached_result.get("probabilities", {}),
                    reasoning=cached_result["reasoning"]
                )
            else:
                # ìºì‹œì— ì—†ìœ¼ë©´ LLM í˜¸ì¶œ (ì—”í‹°í‹° ì—†ì´ ë¶„ë¥˜ë§Œ)
                from .task_classifier import classify_hybrid
                result = classify_hybrid(user_text, None)  # ì—”í‹°í‹°ëŠ” Noneìœ¼ë¡œ ì „ë‹¬
                print(f"[DEBUG] LLM ë¶„ë¥˜ ê²°ê³¼: '{user_text}' -> {result.category} (ì‹ ë¢°ë„: {result.confidence:.2f})")
                
                # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
                self._add_to_cache(user_text, {
                    "category": result.category,
                    "confidence": result.confidence,
                    "probabilities": result.probabilities,
                    "reasoning": result.reasoning
                })
        except Exception as e:
            print(f"[ERROR] process_user_input ì´ˆê¸° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return "ì£„ì†¡í•´ìš”, ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."

        # âœ… 4. ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬
        print(f"[DEBUG] ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ ì‹œì‘: {result.category}")
        
        # LCEL ì²´ì¸ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        self.conversation_memory.chat_memory.add_user_message(user_text)
        
        if result.category == "cognitive":
            print(f"[DEBUG] cognitive ì²˜ë¦¬ í˜¸ì¶œ")
            try:
                from .support_chains import handle_cognitive_task_with_lcel
                response = handle_cognitive_task_with_lcel(user_text, self, session_id)
                # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥
                self.conversation_memory.chat_memory.add_ai_message(response)
                # ìš”ì•½ ìƒì„±ì€ ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ ìˆ˜í–‰
                return response
            except Exception as e:
                import traceback
                print(f"[ERROR] cognitive ì²˜ë¦¬ ì‹¤íŒ¨: {traceback.format_exc()}")
                # ì‚¬ìš©ì ì¹œí™”ì  í•œê¸€ ë©”ì‹œì§€ (rqt fix ì ìš© ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë¨)
                error_response = "ì£„ì†¡í•´ìš”, ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ìˆì—ˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
                # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥
                self.conversation_memory.chat_memory.add_ai_message(error_response)
                return error_response
        elif result.category == "emotional":
            print(f"[DEBUG] emotional ì²˜ë¦¬ í˜¸ì¶œ")
            try:
                response = self._handle_emotional_task(user_text, session_id)
                # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥
                self.conversation_memory.chat_memory.add_ai_message(response)
                # SQLite ë°±ì—”ë“œê°€ ìë™ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ ë³„ë„ ì €ì¥ ë¶ˆí•„ìš”
                # ìš”ì•½ ìƒì„±ì€ ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ ìˆ˜í–‰
                return response
            except Exception as e:
                import traceback
                print(f"[ERROR] emotional ì²˜ë¦¬ ì‹¤íŒ¨: {traceback.format_exc()}")
                # ì‚¬ìš©ì ì¹œí™”ì  í•œê¸€ ë©”ì‹œì§€ (rqt fix ì ìš© ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë¨)
                error_response = "ì§€ê¸ˆ ë§ì´ í˜ë“œì…¨ì£ . ê³ì—ì„œ ê°™ì´ ì´ì•¼ê¸° ë“¤ì–´ë“œë¦´ê²Œìš”. ì–´ë–¤ ì ì´ ê°€ì¥ í˜ë“¤ì—ˆë‚˜ìš”?"
                # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥
                self.conversation_memory.chat_memory.add_ai_message(error_response)
                return error_response
        elif result.category == "physical":
            print(f"[DEBUG] physical ì²˜ë¦¬ í˜¸ì¶œ")
            
            response = handle_physical_task(user_text, self, session_id)
            
            # ë”•ì…”ë„ˆë¦¬ ì‘ë‹µ ì²˜ë¦¬
            if isinstance(response, dict):
                message = response.get("message", str(response))
                # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥ (ë¬¸ìì—´ë§Œ)
                self.conversation_memory.chat_memory.add_ai_message(message)
                # íˆìŠ¤í† ë¦¬ ì €ì¥: LCEL ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš© (SQLite ë¹„ì‚¬ìš©)
                # ìš”ì•½ ìƒì„±ì€ ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ ìˆ˜í–‰
                return response  # ì „ì²´ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
            else:
                # ë¬¸ìì—´ ì‘ë‹µ
                self.conversation_memory.chat_memory.add_ai_message(response)
                # SQLite ë°±ì—”ë“œê°€ ìë™ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ ë³„ë„ ì €ì¥ ë¶ˆí•„ìš”
                # ìš”ì•½ ìƒì„±ì€ ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ ìˆ˜í–‰
                return response
        elif result.category == "query":
            print(f"[DEBUG] query ì²˜ë¦¬ í˜¸ì¶œ")
            from .support_chains import handle_query_with_lcel
            response = handle_query_with_lcel(user_text, self, session_id)
            # LCEL ì²´ì¸ì— AI ì‘ë‹µ ì €ì¥
            self.conversation_memory.chat_memory.add_ai_message(response)
            # SQLite ë°±ì—”ë“œê°€ ìë™ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ ë³„ë„ ì €ì¥ ë¶ˆí•„ìš”
            # ìš”ì•½ ìƒì„±ì€ ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ ìˆ˜í–‰
            return response
        else:
            print(f"[DEBUG] ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {result.category}")
            return "ì£„ì†¡í•´ìš”, ì˜ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."

    
    def _handle_emotional_task(self, user_text: str, session_id: str) -> str:
        """ì •ì„œì  ì‘ì—… ì²˜ë¦¬ - ì¸ì‚¬, ê°ì • í‘œí˜„, ë‚ ì”¨, ì‹œê°„ ë“±"""
        try:
            # 1ï¸âƒ£ ì¤‘ë³µ ì‘ë‹µ ì²˜ë¦¬ ì²´í¬
            if hasattr(self, 'pending_question') and self.pending_question.get(session_id):
                pending_data = self.pending_question[session_id]
                print(f"[DEBUG] ì¤‘ë³µ ì‘ë‹µ ì²˜ë¦¬ (emotional): {user_text}")
                result = self.handle_duplicate_answer(user_text, pending_data)
                
                # ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ í›„ pending_question ì œê±°
                if session_id in self.pending_question:
                    del self.pending_question[session_id]
                
                return result["message"]
            
            # LCEL ConversationBufferì—ì„œ ëŒ€í™” ë§¥ë½ ë¡œë“œ
            memory_vars = self.conversation_memory.load_memory_variables({})
            conversation_history = memory_vars.get('history', '')
            print(f"[DEBUG] Emotional LCEL history ê¸¸ì´: {len(conversation_history)}")
            
            # ë©”ì‹œì§€ ì €ì¥ (ì§ì ‘ message_storeì— ì €ì¥)
            self._save_message(session_id, "human", user_text)
            
            # conversation_historyë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            conversation_history = self._convert_conversation_history_to_string(conversation_history)
            
            # ì—”í‹°í‹° ì¶”ì¶œ ë° ì €ì¥ (Slot-filling ì²´í¬ í¬í•¨)
            entities = self._pre_extract_entities(user_text, session_id)
            print(f"[DEBUG] emotionalì—ì„œ ì¶”ì¶œëœ ì—”í‹°í‹°: {entities}")
            
            # Slot-filling ì‘ë‹µ ì²˜ë¦¬
            if isinstance(entities, dict) and entities.get("success") == False and entities.get("incomplete"):
                print(f"[DEBUG] Slot-filling í•„ìš” (emotional): {entities['message']}")
                # pending_questionì— ì €ì¥
                self.pending_question[session_id] = entities.get("pending_data", {})
                return entities["message"]
            
            if entities:
                # ì‚¬ìš©ì ì´ë¦„ ì—”í‹°í‹° ì²˜ë¦¬
                if "user.ì‚¬ìš©ì" in entities:
                    for user_entity in entities["user.ì‚¬ìš©ì"]:
                        name = user_entity.get("ì´ë¦„", "")
                        if name:
                            save_result = self.save_entity_to_vectorstore(
                                entity_type="ì‚¬ìš©ì",
                                data={"ì´ë¦„": name, "í™•ì¸ë¨": user_entity.get("í™•ì¸ë¨", True)},
                                session_id=session_id
                            )
                            if save_result.get("duplicate"):
                                # ì¤‘ë³µ ë°œê²¬ ì‹œ pending_questionì— ì €ì¥
                                self.pending_question[session_id] = save_result.get("pending_data", {})
                                return save_result["message"]
                
                # ê°ì • ì—”í‹°í‹° ì²˜ë¦¬
                if "user.ê±´ê°•ìƒíƒœ" in entities:
                    for emotion in entities["user.ê±´ê°•ìƒíƒœ"]:
                        emotion_state = emotion.get("ì¦ìƒ", "")
                        if emotion_state:
                            # ê°ì •ì„ VectorStoreì— JSON êµ¬ì¡°ë¡œ ì €ì¥ (ì •ì„œ íƒ€ì…ìœ¼ë¡œ í†µì¼)
                            # âœ… ê°ì •ì˜ ì›ì¸/ìƒí™©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½
                            from life_assist_dm.life_assist_dm.support_chains import _summarize_emotion_context_for_save
                            info_summary = _summarize_emotion_context_for_save(user_text, self.llm if hasattr(self, 'llm') else None)
                            
                            save_result = self.save_entity_to_vectorstore(
                                entity_type="ì •ì„œ",
                                data={
                                "ê°ì •": emotion_state,
                                "ì •ë³´": info_summary
                            },
                            session_id=session_id
                        )
                            if save_result.get("duplicate"):
                                # ì¤‘ë³µ ë°œê²¬ ì‹œ pending_questionì— ì €ì¥
                                self.pending_question[session_id] = save_result.get("pending_data", {})
                                return save_result["message"]
                            else:
                                print(f"[DEBUG] ì •ì„œ ì €ì¥ë¨: {emotion_state}")
            
            # LCEL historyë¥¼ ê³ ë ¤í•œ ê°ì •ì  ì‘ë‹µ ìƒì„±
            if conversation_history and len(conversation_history.strip()) > 0:
                # ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•œ ê°ì •ì  ì‘ë‹µ
                from .support_chains import build_emotional_reply
                user_name_confirmed = bool(self._get_confirmed_user_name(session_id))
                response = build_emotional_reply(user_text, llm=self.llm, user_name_confirmed=user_name_confirmed)
            else:
                # ê¸°ë³¸ ê°ì •ì  ì‘ë‹µ
                from .support_chains import build_emotional_reply
                user_name_confirmed = bool(self._get_confirmed_user_name(session_id))
                response = build_emotional_reply(user_text, llm=self.llm, user_name_confirmed=user_name_confirmed)
            
            # AIMessage ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            if hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)
            
            # ì‘ë‹µ ì €ì¥ (ì§ì ‘ message_storeì— ì €ì¥)
            self._save_message(session_id, "ai", response_text)
            return response_text
            
        except Exception as e:
            print(f"[ERROR] ì •ì„œì  ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•´ìš”, ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
    
    def _extract_appointment_info(self, user_text: str) -> str:
        """
        ì‚¬ìš©ìì˜ ë°œí™”ì—ì„œ ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ(ì¹˜ê³¼, ë³‘ì›, ë¯¸ìš©ì‹¤ ë“±)ë¥¼ ì¶”ì¶œ
        """
        try:
            import re
            from datetime import datetime, timedelta
            
            info = {"date": None, "time": None, "place": None}

            # ì¥ì†Œ
            place_match = re.search(r"(ì¹˜ê³¼|ë³‘ì›|ë¯¸ìš©ì‹¤|ì•½ì†|íšŒì˜|ë¯¸íŒ…|ì•½êµ­|ì€í–‰|ì¹´í˜|ì‹ë‹¹)", user_text)
            if place_match:
                info["place"] = place_match.group(1)

            # ìƒëŒ€ì  ë‚ ì§œ
            if "ë‚´ì¼" in user_text:
                info["date"] = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
            elif "ëª¨ë ˆ" in user_text:
                info["date"] = (datetime.now() + timedelta(days=2)).strftime("%Y-%m-%d")
            else:
                # "ë‹¤ìŒ ì£¼ í† ìš”ì¼" íŒ¨í„´
                dow_match = re.search(r"(ë‹¤ìŒ\s*ì£¼\s*)(ì›”|í™”|ìˆ˜|ëª©|ê¸ˆ|í† |ì¼)ìš”ì¼?", user_text)
                if dow_match:
                    weekday_map = {"ì›”": 0, "í™”": 1, "ìˆ˜": 2, "ëª©": 3, "ê¸ˆ": 4, "í† ": 5, "ì¼": 6}
                    target_weekday = weekday_map[dow_match.group(2)]
                    today = datetime.now()
                    days_ahead = (target_weekday - today.weekday() + 7) % 7
                    if days_ahead == 0:
                        days_ahead = 7
                    days_ahead += 7  # ë‹¤ìŒ ì£¼
                    target_date = today + timedelta(days=days_ahead)
                    info["date"] = target_date.strftime("%Y-%m-%d")

            # ì‹œê°„ (ì˜¤ì „/ì˜¤í›„ hhì‹œ)
            time_match = re.search(r"(ì˜¤ì „|ì˜¤í›„)?\s?(\d{1,2})ì‹œ", user_text)
            if time_match:
                hour = int(time_match.group(2))
                if time_match.group(1) == "ì˜¤í›„" and hour < 12:
                    hour += 12
                info["time"] = f"{hour:02d}:00"

            # ê²°ê³¼ ì¡°í•©
            if any(info.values()):
                parts = []
                if info["date"]:
                    parts.append(f"ë‚ ì§œ: {info['date']}")
                if info["time"]:
                    parts.append(f"ì‹œê°„: {info['time']}")
                if info["place"]:
                    parts.append(f"ì¥ì†Œ: {info['place']}")
                return " | ".join(parts)
            else:
                return "ì˜ˆì•½"
                
        except Exception as e:
            print(f"[ERROR] ì˜ˆì•½ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "ì˜ˆì•½"

    def _get_entities_by_type(self, session_id: str, entity_types: list) -> list:
        """Excel ìºì‹œ ê¸°ë°˜ ì—”í‹°í‹° ì¡°íšŒ"""
        if not hasattr(self, "excel_cache"):
            return []
        sess = self.excel_cache.get(session_id, {})
        entities = []
        for entity_type in entity_types:
            # entity_typesê°€ "user.ì•½" í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ "ì•½"ë§Œ ì¶”ì¶œ
            simple_type = entity_type.replace("user.", "").replace("_", "")
            if simple_type in sess:
                for item in sess[simple_type]:
                    entities.append({
                        "entity_key": entity_type,
                        "content": str(item),
                        "ì´ë¦„": item.get("ì´ë¦„", ""),
                        "metadata": {}
                    })
        return entities


    def _get_recent_messages(self, session_id: str, limit: int = 10) -> list:
        """ìµœê·¼ ëŒ€í™” ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import sqlite3
            conn = sqlite3.connect(self.sqlite_path)
            c = conn.cursor()
            c.execute("""
                SELECT role, message FROM message_store 
                WHERE session_id = ? 
                ORDER BY id DESC 
                LIMIT ?
            """, (session_id, limit))
            messages = c.fetchall()
            conn.close()
            return messages
        except Exception as e:
            print(f"[ERROR] ìµœê·¼ ë©”ì‹œì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _save_message(self, session_id: str, role: str, content: str):
        """message_storeì— ë©”ì‹œì§€ ì €ì¥ (SQLChatMessageHistory í˜¸í™˜ JSON í˜•ì‹)"""
        try:
            import sqlite3
            import json
            conn = sqlite3.connect(self.sqlite_path)
            c = conn.cursor()
            
            # content íƒ€ì… ë³€í™˜ (ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜)
            if not isinstance(content, str):
                if isinstance(content, (list, tuple)):
                    content = str(content)
                elif hasattr(content, '__str__'):
                    content = str(content)
                else:
                    content = repr(content)
            
            # SQLChatMessageHistory í˜¸í™˜ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
            message_data = {
                "type": "human" if role == "ì‚¬ìš©ì" else "ai",
                "data": {
                    "content": content,
                    "additional_kwargs": {}
                }
            }
            message_json = json.dumps(message_data, ensure_ascii=False)
            
            c.execute(
                "INSERT INTO message_store (session_id, role, message) VALUES (?, ?, ?)",
                (session_id, role, message_json)
            )
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"[ERROR] ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

    def generate(self, session_id: str, user_input: str) -> str:
        """ê¸°ì¡´ generate í•¨ìˆ˜ - process_user_input í˜¸ì¶œ"""
        # process_user_input í˜¸ì¶œ
        response = self.process_user_input(user_input, session_id)
        
        # ë©”ì‹œì§€ ì €ì¥ì€ process_user_inputì—ì„œ ì²˜ë¦¬ë¨
        
        return response
    
    def _update_existing_entity(self, session_id: str, entity_key: str, existing_entity: dict, new_entity: dict):
        """ê¸°ì¡´ ì—”í‹°í‹°ë¥¼ ìƒˆ ì—”í‹°í‹°ë¡œ êµì²´ (Excel ê¸°ë°˜)"""
        if False and self.vectorstore:
            # ê¸°ì¡´ ì—”í‹°í‹° ì‚­ì œ (ì„œë“œ íŒŒí‹° VectorStore ì½”ë“œ - ë¹„í™œì„±í™”ë¨)
            all_docs = self.vectorstore.get()
            for i, doc_id in enumerate(all_docs.get("ids", [])):
                if doc_id.startswith(f"{session_id}_{entity_key}"):
                    try:
                        doc_data = json.loads(all_docs["documents"][i])
                        if (doc_data.get("entity_key") == entity_key and 
                            doc_data.get("session_id") == session_id and
                            doc_data.get("ì´ë¦„") == existing_entity.get("ì´ë¦„")):
                            self.vectorstore.delete(ids=[doc_id])
                            break
                    except (json.JSONDecodeError, TypeError):
                        continue
        
        # ìƒˆ ì—”í‹°í‹° ì €ì¥ (Excel ê¸°ë°˜)
        entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
        user_name = self.user_names.get(session_id or "default")
        if user_name:
            self.excel_manager.save_entity_data(user_name, entity_type, new_entity)
            # ìºì‹œ ì—…ë°ì´íŠ¸
            if hasattr(self, "excel_cache"):
                sess = self.excel_cache.setdefault(session_id, {})
                entities = sess.setdefault(entity_type, [])
                # ê¸°ì¡´ ì—”í‹°í‹° ì°¾ì•„ì„œ êµì²´
                for i, ent in enumerate(entities):
                    if ent.get("ì´ë¦„") == existing_entity.get("ì´ë¦„"):
                        entities[i] = new_entity
                        break
                else:
                    entities.append(new_entity)
    
    def _add_new_entity(self, session_id: str, entity_key: str, new_entity: dict):
        """ìƒˆ ì—”í‹°í‹°ë¥¼ ì¶”ê°€ë¡œ ì €ì¥"""
        self._store_entity_direct(session_id, entity_key, new_entity)
    
    def _cancel_schedule(self, session_id: str, title: str):
        """ì¼ì • ì·¨ì†Œ ì²˜ë¦¬ - Excelì—ì„œ í•´ë‹¹ ì¼ì • ì‚­ì œ"""
        try:
            user_name = self.user_names.get(session_id or "default")
            if not user_name:
                return False
            df = self.excel_manager.load_sheet_data(user_name, "ì¼ì •")
            if df is None or df.empty:
                return False
            # ì œëª©ì´ ì¼ì¹˜í•˜ëŠ” í–‰ ì œê±°
            filtered_df = df[df["ì œëª©"] != title]
            if len(filtered_df) < len(df):
                # ì—‘ì…€ì— ì €ì¥ (ì‚­ì œ ë°˜ì˜) - ì¦‰ì‹œ ì €ì¥ í•„ìš”
                excel_path = self.excel_manager.get_user_excel_path(user_name)
                excel_file = self.excel_manager.load_user_excel(user_name)
                excel_data = {}
                if excel_file:
                    for sheet in excel_file.sheet_names:
                        if sheet == "ì¼ì •":
                            excel_data[sheet] = filtered_df
                        else:
                            excel_data[sheet] = pd.read_excel(excel_file, sheet_name=sheet)
                else:
                    excel_data["ì¼ì •"] = filtered_df
                with pd.ExcelWriter(excel_path, engine='openpyxl', mode='w') as writer:
                    for sheet_name, df_data in excel_data.items():
                        df_data.to_excel(writer, sheet_name=sheet_name, index=False)
                # ìºì‹œ ì—…ë°ì´íŠ¸
                if hasattr(self, "excel_cache"):
                    sess = self.excel_cache.setdefault(session_id, {})
                    if "ì¼ì •" in sess:
                        sess["ì¼ì •"] = [row for row in sess["ì¼ì •"] if row.get("ì œëª©") != title]
                print(f"[DEBUG] ì¼ì • ì·¨ì†Œ ì™„ë£Œ: {title}")
                return True
            else:
                print(f"[DEBUG] ì·¨ì†Œí•  ì¼ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {title}")
                return False
        except Exception as e:
            print(f"[ERROR] ì¼ì • ì·¨ì†Œ ì‹¤íŒ¨: {e}")
            return False
    
    def _store_entity_direct(self, session_id: str, entity_key: str, entity: dict):
        """ì—”í‹°í‹°ë¥¼ Excelì— ì§ì ‘ ì €ì¥"""
        try:
            entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
            user_name = self.user_names.get(session_id or "default")
            if not user_name:
                return False
            self.excel_manager.save_entity_data(user_name, entity_type, entity)
            # ìºì‹œ ì—…ë°ì´íŠ¸
            if hasattr(self, "excel_cache"):
                sess = self.excel_cache.setdefault(session_id, {})
                entities = sess.setdefault(entity_type, [])
                entities.append(entity)
            print(f"[DEBUG] ì—”í‹°í‹° ì €ì¥ ì™„ë£Œ: {entity_key} - {entity.get('ì´ë¦„', 'N/A')}")
            return True
        except Exception as e:
            print(f"[ERROR] ì—”í‹°í‹° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def _update_entity_in_vstore(self, session_id: str, entity_key: str, updated_entity: dict):
        """Excelì˜ ì—”í‹°í‹° ì—…ë°ì´íŠ¸"""
        try:
            entity_type = entity_key.replace("user.", "") if entity_key.startswith("user.") else entity_key
            user_name = self.user_names.get(session_id or "default")
            if not user_name:
                return False
            # ì‹œíŠ¸ ë§¤í•‘ í™•ì¸
            sheet_mapping = {
                "ë¬¼ê±´": "ë¬¼ê±´ìœ„ì¹˜",
                "ì•½": "ë³µì•½ì •ë³´",
                "ì¼ì •": "ì¼ì •",
                "ìŒì‹": "ìŒì‹ê¸°ë¡",
                "ì •ì„œ": "ê°ì •ê¸°ë¡",
                "ê°€ì¡±": "ê°€ì¡±ê´€ê³„",
            }
            sheet_name = sheet_mapping.get(entity_type, "ì‚¬ìš©ìì •ë³´KV")
            # Excelì—ì„œ ê¸°ì¡´ ì—”í‹°í‹° ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
            df = self.excel_manager.load_sheet_data(user_name, sheet_name)
            if df is not None and not df.empty:
                # ì´ë¦„ìœ¼ë¡œ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
                name = updated_entity.get("ì´ë¦„", "")
                if name and "ì´ë¦„" in df.columns:
                    idx = df[df["ì´ë¦„"] == name].index
                    if len(idx) > 0:
                        # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
                        for col in updated_entity.keys():
                            if col in df.columns:
                                df.loc[idx[0], col] = updated_entity[col]
                        # ì—‘ì…€ì— ì €ì¥
                        excel_path = self.excel_manager.get_user_excel_path(user_name)
                        excel_file = self.excel_manager.load_user_excel(user_name)
                        excel_data = {}
                        if excel_file:
                            for sheet in excel_file.sheet_names:
                                if sheet == sheet_name:
                                    excel_data[sheet] = df
                                else:
                                    excel_data[sheet] = pd.read_excel(excel_file, sheet_name=sheet)
                        else:
                            excel_data[sheet_name] = df
                        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                            for sname, sdata in excel_data.items():
                                sdata.to_excel(writer, sheet_name=sname, index=False)
                        # ìºì‹œ ì—…ë°ì´íŠ¸
                        if hasattr(self, "excel_cache"):
                            sess = self.excel_cache.setdefault(session_id, {})
                            entities = sess.setdefault(entity_type, [])
                            for i, ent in enumerate(entities):
                                if ent.get("ì´ë¦„") == name:
                                    entities[i] = updated_entity
                                    return True
            # ê¸°ì¡´ ì—”í‹°í‹°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ìƒˆë¡œ ì €ì¥
            self.excel_manager.save_entity_data(user_name, entity_type, updated_entity)
            # ìºì‹œ ì—…ë°ì´íŠ¸
            if hasattr(self, "excel_cache"):
                sess = self.excel_cache.setdefault(session_id, {})
                entities = sess.setdefault(entity_type, [])
                entities.append(updated_entity)
            return True
        except Exception as e:
            print(f"[ERROR] ì—”í‹°í‹° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def auto_export_conversation(self, session_id: str):
        """ëŒ€í™” ìë™ ì¶”ì¶œ (ì—‘ì…€ íŒŒì¼)"""
        if not self.cfg.auto_export_enabled:
            return None
        
        try:
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            excel_path = self.export_conversation_to_excel(session_id)
            if excel_path:
                print(f"âœ… ëŒ€í™” ê¸°ë¡ì´ ìë™ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤: {excel_path}")
                return excel_path
            else:
                print("âŒ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ ì‹¤íŒ¨")
                return None
        except Exception as e:
            print(f"[ERROR] ìë™ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def export_conversation_to_excel(self, session_id: str):
        """ëŒ€í™” ê¸°ë¡ì„ ì—‘ì…€ íŒŒì¼ë¡œ ì¶”ì¶œ (SQLite ì§ì ‘ ì¡°íšŒ)"""
        try:
            print(f"[DEBUG] export_conversation_to_excel ì‹œì‘: {session_id}")
            
            # SQLiteì—ì„œ ì§ì ‘ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
            import sqlite3
            import pandas as pd
            from datetime import datetime
            import os
            import json
            
            conn = sqlite3.connect(self.sqlite_path)
            cur = conn.cursor()
            
            # ë©”ì‹œì§€ ì¡°íšŒ (created_at ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ fallback)
            try:
                cur.execute(
                    "SELECT id, session_id, role, content, created_at FROM message_store WHERE session_id = ? ORDER BY id",
                    (session_id,)
                )
                rows = cur.fetchall()
            except sqlite3.OperationalError as e:
                if "no such column: created_at" in str(e):
                    # created_at ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ idë¥¼ ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©
                    cur.execute(
                        "SELECT id, session_id, role, content, id FROM message_store WHERE session_id = ? ORDER BY id",
                        (session_id,)
                    )
                    rows = cur.fetchall()
                else:
                    raise e
            conn.close()
            
            if not rows:
                print("ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ë°ì´í„° ì¤€ë¹„
            data = []
            print(f"[DEBUG] ë©”ì‹œì§€ ìˆ˜: {len(rows)}")
            for row in rows:
                msg_id, session_id, role, content, created_at = row
                content = content or ""  # None ì²˜ë¦¬
                print(f"[DEBUG] ë©”ì‹œì§€ {msg_id}: role={role}, content={content[:50]}...")
                
                # JSON íŒŒì‹±
                try:
                    if content.startswith('{"type":'):
                        msg_data = json.loads(content)
                        actual_type = msg_data.get("type", "unknown")
                        actual_content = msg_data.get("data", {}).get("content", content)
                        
                        # ë°œí™”ì ì„¤ì • (JSONì—ì„œ ì¶”ì¶œ)
                        if actual_type == "human":
                            display_role = "ì‚¬ìš©ì"
                        elif actual_type == "ai":
                            display_role = "AI"
                        else:
                            display_role = "unknown"
                    else:
                        actual_content = content
                        # ë°œí™”ì ì„¤ì • (role ì»¬ëŸ¼ì—ì„œ ì¶”ì¶œ)
                        if role == "human":
                            display_role = "ì‚¬ìš©ì"
                        elif role == "ai":
                            display_role = "AI"
                        else:
                            display_role = "unknown"
                except Exception:
                    actual_content = content
                    if role == "human":
                        display_role = "ì‚¬ìš©ì"
                    elif role == "ai":
                        display_role = "AI"
                    else:
                        display_role = "unknown"
                
                data.append({
                    "ì‹œê°„": created_at,
                    "ë°œí™”ì": display_role,
                    "ë‚´ìš©": actual_content
                })
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(data)
            
            # ì—‘ì…€ íŒŒì¼ ì €ì¥
            if not os.path.exists(self.cfg.export_dir):
                os.makedirs(self.cfg.export_dir)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            excel_filename = f"session_{session_id}_{timestamp}.xlsx"
            excel_path = os.path.join(self.cfg.export_dir, excel_filename)
            
            df.to_excel(excel_path, index=False, engine='openpyxl')
            
            print(f"ğŸ“Š ì´ {len(data)}ê°œ ë©”ì‹œì§€")
            print(f"âœ… ì—‘ì…€ íŒŒì¼ ìƒì„±ë¨: {excel_path}")
            return excel_path
            
        except Exception as e:
            import traceback
            print(f"[ERROR] ì—‘ì…€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            print(f"[ERROR] ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None

    # âœ… ëŒ€í™” ë‚´ìš© ê¸°ë¡ìš© add_dialog ë©”ì„œë“œ ì¶”ê°€
    def add_dialog(self, text: str, act_type: str):
        """
        ì‚¬ìš©ì ë°œí™”(text)ì™€ act_type(ì¸ì§€/ì •ì„œ/ë¬¼ë¦¬)ì„ ë©”ëª¨ë¦¬ì— ê¸°ë¡.
        """
        try:
            # ConversationBufferMemory ì‚¬ìš©
            self.conversation_memory.save_context({"input": text}, {"output": act_type})

            # SQLite ë˜ëŠ” summary memoryì—ë„ ë°˜ì˜
            if hasattr(self, "summary_memory"):
                self.summary_memory.save_context({"input": text}, {"output": act_type})

            print(f"[MEMORY] Added dialog: ({act_type}) {text}")

        except Exception as e:
            print(f"[MEMORY ERROR] add_dialog(): {e}")
    
    # -----------------------------
    # ğŸ§© flush ë©”ì„œë“œ (ë²„í¼ â†’ Excel ë°˜ì˜)
    # -----------------------------
    def flush_memory_to_excel(self, session_id: str):
        """ì„¸ì…˜ ìºì‹œ â†’ Excel ë°˜ì˜ (ë²„í¼ í”ŒëŸ¬ì‹œ)"""
        try:
            user_name = self.user_names.get(session_id or "default_session", "ì‚¬ìš©ì")
            if user_name and user_name != "ì‚¬ìš©ì":
                # ë²„í¼ ë¹„ì–´ìˆìœ¼ë©´ skip
                try:
                    buffered = getattr(self.excel_manager, "_buffered_changes", {})
                    has_user_buffers = any(k for k in buffered.keys() if k[0] == user_name)
                    if not has_user_buffers:
                        logger.info("[FLUSH] ë²„í¼ ë¹„ì–´ìˆìŒ - flush ìƒëµ")
                        return
                except Exception:
                    pass
                #  request_flush() ì‚¬ìš©í•˜ì—¬ ì§€ì—° ë³‘í•© ì²˜ë¦¬ (race condition ë°©ì§€)
                self.excel_manager.request_flush(user_name)
                logger.info(f"[FLUSH] ì„¸ì…˜({session_id}) ë°ì´í„° ì—‘ì…€ë¡œ ë™ê¸°í™” ì˜ˆì•½ ({user_name})")
            else:
                logger.warning(f"[FLUSH] ì‚¬ìš©ì ì´ë¦„ì´ ì—†ì–´ flush ê±´ë„ˆëœ€: {session_id}")
        except Exception as e:
            logger.error(f"[ERROR] flush_memory_to_excel ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
